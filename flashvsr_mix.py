#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ComfyUI FlashVSR-XZG é«˜çº§æ‰¹é‡è§†é¢‘å¤„ç†è„šæœ¬ï¼ˆæ··åˆç‰ˆï¼‰
ä¸“ä¸º api_flashvsr_mix.json å·¥ä½œæµæ¨¡æ¿è®¾è®¡
ç‰ˆæœ¬: 1.2
ä¿®å¤tiled_ditå˜é‡åé”™è¯¯é—®é¢˜
"""

import json
import requests
import os
import time
import sys
import math
import re
import subprocess
import threading
from glob import glob
from typing import List, Dict, Optional, Tuple, Union
from pathlib import Path
import traceback
import argparse
from datetime import datetime
import signal
import psutil

# å°è¯•å¯¼å…¥ pymediainfo
try:
    from pymediainfo import MediaInfo
    PYMEDIAINFO_AVAILABLE = True
except ImportError:
    PYMEDIAINFO_AVAILABLE = False
    print("âš ï¸  pymediainfo æœªå®‰è£…ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è·å–è§†é¢‘ä¿¡æ¯")

class FlashVSR_XZG_MIX_Processor:
    def __init__(self, comfyui_url: str = "http://127.0.0.1:8188", log_dir: str = "."):
        """
        åˆå§‹åŒ– ComfyUI FlashVSR-XZG MIX å¤„ç†å™¨
        
        å‚æ•°:
            comfyui_url: ComfyUI æœåŠ¡å™¨åœ°å€
            log_dir: æ—¥å¿—ç›®å½•
        """
        self.comfyui_url = comfyui_url.rstrip('/')
        self.api_prompt = f"{comfyui_url}/prompt"
        self.api_history = f"{comfyui_url}/history"
        self.api_view = f"{comfyui_url}/view"
        self.api_queue = f"{comfyui_url}/queue"
        
        # æ—¥å¿—è®¾ç½®
        self.log_dir = log_dir
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_file = os.path.join(self.log_dir, f"flashvsr_mix_{timestamp}.log")
        self.state_dir = os.path.join(self.log_dir, "states_mix")
        
        # åˆ›å»ºæ—¥å¿—å’ŒçŠ¶æ€ç›®å½•
        os.makedirs(self.log_dir, exist_ok=True)
        os.makedirs(self.state_dir, exist_ok=True)
        
        # åˆå§‹åŒ–æ—¥å¿—
        self._init_log_file()
        
        self.log("ğŸ“± åˆå§‹åŒ– FlashVSR-XZG MIX å¤„ç†å™¨ v1.2", "INFO")
        self.log(f"ğŸ”— ComfyUI åœ°å€: {self.comfyui_url}", "INFO")
        self.log(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {self.log_file}", "INFO")
        self.log(f"ğŸ’¾ çŠ¶æ€ç›®å½•: {self.state_dir}", "INFO")
        
        # çŠ¶æ€è·Ÿè¸ª
        self.processing_state = {}
    
    def _init_log_file(self):
        """åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶"""
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(f"{'='*80}\n")
            f.write(f"FlashVSR-XZG MIX å¤„ç†æ—¥å¿— v1.2\n")
            f.write(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å·¥ä½œæµæ¨¡æ¿: api_flashvsr_mix.json\n")
            f.write(f"{'='*80}\n\n")
    
    def log(self, message: str, level: str = "INFO"):
        """
        è®°å½•æ—¥å¿—ï¼ˆæ”¹è¿›æ ¼å¼ï¼Œä¸flashvsr_xzg.pyä¿æŒä¸€è‡´ï¼‰
        
        å‚æ•°:
            message: æ—¥å¿—æ¶ˆæ¯
            level: æ—¥å¿—çº§åˆ«
        """
        # ä½¿ç”¨ç»Ÿä¸€çš„æ—¶é—´æˆ³æ ¼å¼ [YYYY-MM-DD HH:MM:SS]
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] [{level}] {message}"
        
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        print(log_entry)
        
        # å†™å…¥æ—¥å¿—æ–‡ä»¶
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(log_entry + "\n")
        except Exception as e:
            print(f"å†™å…¥æ—¥å¿—å¤±è´¥: {e}")
    
    def save_processing_state(self, video_path: str, frames_processed: int, batches_processed: int, 
                            success: bool = True, error_msg: str = ""):
        """
        ä¿å­˜å¤„ç†çŠ¶æ€åˆ°æ–‡ä»¶
        
        å‚æ•°:
            video_path: è§†é¢‘è·¯å¾„
            frames_processed: å·²å¤„ç†å¸§æ•°
            batches_processed: å·²å¤„ç†æ‰¹æ¬¡
            success: æ˜¯å¦æˆåŠŸ
            error_msg: é”™è¯¯ä¿¡æ¯
        """
        try:
            video_name = os.path.basename(video_path)
            # å®‰å…¨æ–‡ä»¶åï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
            safe_video_name = re.sub(r'[^\w\-\.]', '_', video_name)
            state_file = os.path.join(self.state_dir, f"{safe_video_name}_state.json")
            
            state = {
                "video_path": video_path,
                "video_name": video_name,
                "frames_processed": frames_processed,
                "batches_processed": batches_processed,
                "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "success": success,
                "error_msg": error_msg
            }
            
            with open(state_file, 'w', encoding='utf-8') as f:
                json.dump(state, f, indent=2, ensure_ascii=False)
            
            self.log(f"ğŸ’¾ å·²ä¿å­˜çŠ¶æ€æ–‡ä»¶: {state_file}", "INFO")
            return True
        except Exception as e:
            self.log(f"ä¿å­˜çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}", "ERROR")
            return False
    
    def load_processing_state(self, video_path: str) -> Tuple[int, int, Dict]:
        """
        ä»æ–‡ä»¶åŠ è½½å¤„ç†çŠ¶æ€
        
        å‚æ•°:
            video_path: è§†é¢‘è·¯å¾„
            
        è¿”å›:
            (frames_processed: int, batches_processed: int, state: Dict)
        """
        try:
            video_name = os.path.basename(video_path)
            safe_video_name = re.sub(r'[^\w\-\.]', '_', video_name)
            
            # æŸ¥æ‰¾çŠ¶æ€æ–‡ä»¶
            state_files = [
                os.path.join(self.state_dir, f"{safe_video_name}_state.json"),
                os.path.join(self.state_dir, f"{video_name}_state.json"),
                os.path.join(self.log_dir, f"flashvsr_mix_state_{safe_video_name}.json"),
                os.path.join(self.log_dir, f"flashvsr_mix_state_{video_name}.json"),
            ]
            
            for state_file in state_files:
                if os.path.exists(state_file):
                    with open(state_file, 'r', encoding='utf-8') as f:
                        state = json.load(f)
                    
                    frames = state.get("frames_processed", 0)
                    batches = state.get("batches_processed", 0)
                    
                    self.log(f"ğŸ“‚ åŠ è½½çŠ¶æ€æ–‡ä»¶: {state_file}", "INFO")
                    self.log(f"  ğŸ“Š å·²å¤„ç†: {frames} å¸§, {batches} æ‰¹", "INFO")
                    
                    return frames, batches, state
            
            return 0, 0, {}
        except Exception as e:
            self.log(f"åŠ è½½çŠ¶æ€æ–‡ä»¶å¤±è´¥: {e}", "ERROR")
            return 0, 0, {}
    
    def check_comfyui_server(self, timeout: int = 10) -> bool:
        """æ£€æŸ¥ ComfyUI æœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.comfyui_url}/", timeout=timeout)
            return response.status_code == 200
        except requests.exceptions.RequestException as e:
            self.log(f"æ£€æŸ¥ ComfyUI æœåŠ¡å¤±è´¥: {e}", "WARN")
            return False
    
    def get_video_info(self, video_path: str) -> Tuple[float, int, int, int, str]:
        """
        è·å–è§†é¢‘ä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«å®½åº¦å’Œé«˜åº¦ï¼‰
        
        å‚æ•°:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        è¿”å›:
            (fps: float, total_frames: int, width: int, height: int, method: str)
        """
        try:
            if PYMEDIAINFO_AVAILABLE:
                self.log(f"ä½¿ç”¨ pymediainfo è·å–è§†é¢‘ä¿¡æ¯: {video_path}", "INFO")
                media_info = MediaInfo.parse(video_path)
                
                for track in media_info.tracks:
                    if track.track_type == 'Video':
                        # è·å–å¸§ç‡
                        fps = 25.0
                        if hasattr(track, 'frame_rate') and track.frame_rate:
                            try:
                                fps_str = str(track.frame_rate)
                                if '/' in fps_str:
                                    numerator, denominator = map(float, fps_str.split('/'))
                                    fps = numerator / denominator
                                else:
                                    fps = float(fps_str)
                            except:
                                self.log(f"è§£æå¸§ç‡å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼ 25.0", "WARN")
                        
                        # è·å–æ€»å¸§æ•°
                        total_frames = 0
                        if hasattr(track, 'frame_count') and track.frame_count:
                            total_frames = int(track.frame_count)
                        
                        # è·å–å®½åº¦å’Œé«˜åº¦
                        width = 0
                        height = 0
                        if hasattr(track, 'width') and track.width:
                            width = int(track.width)
                        if hasattr(track, 'height') and track.height:
                            height = int(track.height)
                        
                        if total_frames > 0 and width > 0 and height > 0:
                            self.log(f"è§†é¢‘ä¿¡æ¯: FPS={fps:.2f}, æ€»å¸§æ•°={total_frames}, åˆ†è¾¨ç‡={width}x{height}", "INFO")
                            return fps, total_frames, width, height, "pymediainfo"
            
            # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨ OpenCV
            try:
                import cv2
                self.log(f"ä½¿ç”¨ OpenCV è·å–è§†é¢‘ä¿¡æ¯: {video_path}", "INFO")
                cap = cv2.VideoCapture(video_path)
                
                if cap.isOpened():
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    cap.release()
                    
                    if fps > 0 and total_frames > 0 and width > 0 and height > 0:
                        self.log(f"è§†é¢‘ä¿¡æ¯: FPS={fps:.2f}, æ€»å¸§æ•°={total_frames}, åˆ†è¾¨ç‡={width}x{height}", "INFO")
                        return fps, total_frames, width, height, "OpenCV"
            except ImportError:
                self.log("OpenCV æœªå®‰è£…", "WARN")
            except Exception as e:
                self.log(f"OpenCV è·å–ä¿¡æ¯å¤±è´¥: {e}", "WARN")
            
            # é»˜è®¤å€¼
            self.log(f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼: FPS=25.0, æ€»å¸§æ•°=100, åˆ†è¾¨ç‡=1280x720", "WARN")
            return 25.0, 100, 1280, 720, "é»˜è®¤å€¼"
            
        except Exception as e:
            self.log(f"è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥: {e}", "ERROR")
            return 25.0, 100, 1280, 720, "é”™è¯¯-é»˜è®¤å€¼"
    
    def calculate_aligned_dimension(self, dimension: int, alignment: int = 128) -> int:
        """
        è®¡ç®—å¯¹é½åˆ°æŒ‡å®šå€æ•°çš„å°ºå¯¸
        ä¾‹å¦‚ï¼š720/128=5.625 â†’ å‘ä¸Šå–æ•´ä¸º6 â†’ 6 * 128=768
        
        å‚æ•°:
            dimension: åŸå§‹å°ºå¯¸
            alignment: å¯¹é½å€æ•°ï¼ˆé»˜è®¤128ï¼‰
            
        è¿”å›:
            å¯¹é½åçš„å°ºå¯¸
        """
        if dimension <= 0:
            return alignment
        
        # è®¡ç®—éœ€è¦å¤šå°‘ä¸ªå¯¹é½å•ä½
        units = math.ceil(dimension / alignment)
        
        # è¿”å›å¯¹é½åçš„å°ºå¯¸
        aligned_dimension = units * alignment
        self.log(f"  å°ºå¯¸å¯¹é½: {dimension} -> {aligned_dimension} (å•ä½: {alignment})", "INFO")
        
        return aligned_dimension
    
    def load_workflow_template(self, template_path: str) -> Dict:
        """åŠ è½½å·¥ä½œæµ JSON æ¨¡æ¿"""
        try:
            with open(template_path, 'r', encoding='utf-8') as f:
                workflow = json.load(f)
            
            self.log(f"å·²åŠ è½½å·¥ä½œæµæ¨¡æ¿: {template_path}", "INFO")
            return workflow
            
        except FileNotFoundError:
            self.log(f"æ‰¾ä¸åˆ°å·¥ä½œæµæ¨¡æ¿æ–‡ä»¶: {template_path}", "ERROR")
            raise
        except json.JSONDecodeError as e:
            self.log(f"JSON è§£æå¤±è´¥: {e}", "ERROR")
            raise
        except Exception as e:
            self.log(f"åŠ è½½å·¥ä½œæµæ¨¡æ¿å¤±è´¥: {e}", "ERROR")
            raise
    
    def update_workflow_parameters(
        self, 
        workflow: Dict, 
        video_path: str,
        video_fps: float,
        frames_per_batch: int,
        frames_skip: int,
        output_prefix: str,
        attn_mode: str = "block_sparse_attention",
        tiled_dit: bool = False,  # ä¿®å¤ï¼šæ”¹ä¸º bool ç±»å‹
        tile_size: int = 256,
        tile_overlap: int = 24,
        scale: int = 2,
        in_width: int = 768,
        out_width: int = 3072,
        batch_number: int = 1,
        total_batches: int = 1,
        frames_pre: int = 0,
        batch_pre: int = 0,
        gpu_device: str = "auto"
    ) -> Dict:
        """
        æ›´æ–°å·¥ä½œæµå‚æ•°ï¼ˆé’ˆå¯¹ api_flashvsr_mix.jsonï¼‰
        
        å‚æ•°:
            workflow: å·¥ä½œæµæ¨¡æ¿
            video_path: è§†é¢‘è·¯å¾„
            video_fps: è§†é¢‘å¸§ç‡
            frames_per_batch: æ¯æ‰¹å¸§æ•°
            frames_skip: è·³è¿‡å¸§æ•°
            output_prefix: è¾“å‡ºå‰ç¼€
            attn_mode: ç¨€ç–æ¨¡å¼ ("block_sparse_attention" æˆ– "sparse_sage_attention")
            tiled_dit: åˆ†å—å¼€å…³ (å¸ƒå°”å€¼)
            tile_size: åˆ†å—å¤§å°
            tile_overlap: åˆ†å—é‡å 
            scale: æ”¾å¤§å€æ•°
            in_width: è¾“å…¥å®½åº¦ï¼ˆ128å¯¹é½ï¼‰
            out_width: è¾“å‡ºå®½åº¦ï¼ˆ128å¯¹é½ï¼‰
            batch_number: å½“å‰ä»»åŠ¡æ‰¹æ¬¡å·
            total_batches: æ€»æ‰¹æ¬¡æ•°
            frames_pre: å·²è·‘å¸§æ•°
            batch_pre: å·²è·‘æ‰¹æ¬¡
            gpu_device: GPUè®¾å¤‡é€‰æ‹©
            
        è¿”å›:
            æ›´æ–°åçš„å·¥ä½œæµ
        """
        # åˆ›å»ºæ·±æ‹·è´
        modified_workflow = json.loads(json.dumps(workflow))
        
        self.log(f"æ›´æ–°å·¥ä½œæµå‚æ•° (æ‰¹æ¬¡ {batch_number}/{total_batches})", "INFO")
        if frames_pre > 0:
            self.log(f"  â­ï¸  å·²è·‘å¸§æ•°: {frames_pre} å¸§", "INFO")
        if batch_pre > 0:
            self.log(f"  ğŸ“¦ å·²è·‘æ‰¹æ¬¡: {batch_pre} æ‰¹", "INFO")
        
        # æ›´æ–°æ‰€æœ‰èŠ‚ç‚¹å‚æ•°
        for node_id, node_data in modified_workflow.items():
            node_class = node_data.get("class_type", "")
            inputs = node_data.get("inputs", {})
            
            # 1. VHS_LoadVideo èŠ‚ç‚¹ (ID 25)
            if node_class == "VHS_LoadVideo":
                # æ›´æ–°è§†é¢‘è·¯å¾„
                if isinstance(inputs.get("video"), str) and "{{VIDEO_PATH}}" in inputs["video"]:
                    inputs["video"] = video_path
                    self.log(f"  âœ… è®¾ç½®è§†é¢‘è·¯å¾„: {video_path}", "INFO")
                
                # æ›´æ–°å¸§ç‡
                if isinstance(inputs.get("force_rate"), str) and "{{VIDEO_FPS}}" in inputs["force_rate"]:
                    inputs["force_rate"] = str(video_fps)
                    self.log(f"  âœ… è®¾ç½®å¸§ç‡: {video_fps}", "INFO")
                
                # æ›´æ–°æ¯æ‰¹å¸§æ•°
                if isinstance(inputs.get("frame_load_cap"), str) and "{{FRAMES_PER_BATCH}}" in inputs["frame_load_cap"]:
                    inputs["frame_load_cap"] = str(frames_per_batch)
                    self.log(f"  âœ… è®¾ç½®æ¯æ‰¹å¸§æ•°: {frames_per_batch}", "INFO")
                
                # æ›´æ–°è·³è¿‡å¸§æ•°
                if isinstance(inputs.get("skip_first_frames"), str) and "{{FRAMES_SKIP}}" in inputs["skip_first_frames"]:
                    inputs["skip_first_frames"] = str(frames_skip)
                    self.log(f"  âœ… è®¾ç½®è·³è¿‡å¸§æ•°: {frames_skip}", "INFO")
            
            # 2. FlashVSRInitPipe èŠ‚ç‚¹ (ID 29)
            elif node_class == "FlashVSRInitPipe":
                # è®¾ç½®GPUè®¾å¤‡
                if isinstance(inputs.get("device"), str) and "{{gpu}}" in inputs["device"]:
                    if gpu_device == "auto":
                        device_value = "auto"
                    elif gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    inputs["device"] = device_value
                    self.log(f"  âœ… è®¾ç½®GPUè®¾å¤‡: {device_value}", "INFO")
                elif isinstance(inputs.get("device"), str):
                    if gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    inputs["device"] = device_value
                    self.log(f"  âœ… è®¾ç½®GPUè®¾å¤‡: {device_value} (ç›´æ¥èµ‹å€¼)", "INFO")
                
                # è®¾ç½®ç¨€ç–æ¨¡å¼
                if isinstance(inputs.get("attention_mode"), str) and "{{attn_mode}}" in inputs["attention_mode"]:
                    inputs["attention_mode"] = attn_mode
                    self.log(f"  âœ… è®¾ç½®ç¨€ç–æ¨¡å¼: {attn_mode}", "INFO")
                elif isinstance(inputs.get("attention_mode"), str):
                    inputs["attention_mode"] = attn_mode
                    self.log(f"  âœ… è®¾ç½®ç¨€ç–æ¨¡å¼: {attn_mode} (ç›´æ¥èµ‹å€¼)", "INFO")
            
            # 3. FlashVSRNodeAdv èŠ‚ç‚¹ (ID 28)
            elif node_class == "FlashVSRNodeAdv":
                # è®¾ç½®ç¼©æ”¾æ¯”ä¾‹
                if isinstance(inputs.get("scale"), str) and "{{scale}}" in inputs["scale"]:
                    inputs["scale"] = str(scale)
                    self.log(f"  âœ… è®¾ç½®ç¼©æ”¾æ¯”ä¾‹: {scale}", "INFO")
                elif isinstance(inputs.get("scale"), (int, float, str)):
                    try:
                        inputs["scale"] = int(scale)  # æ”¹ä¸º int ç±»å‹
                        self.log(f"  âœ… è®¾ç½®ç¼©æ”¾æ¯”ä¾‹: {scale} (ç›´æ¥èµ‹å€¼ï¼Œè½¬ä¸ºæ•´å‹)", "INFO")
                    except:
                        pass
                
                # è®¾ç½®åˆ†å—å¼€å…³ - ä¿®å¤ï¼šæ­£ç¡®å¤„ç†å¸ƒå°”å€¼
                if "tiled_dit" in inputs:
                    # ç›´æ¥èµ‹å¸ƒå°”å€¼
                    inputs["tiled_dit"] = tiled_dit  
                    self.log(f"  âœ… è®¾ç½®åˆ†å—å¼€å…³: {tiled_dit} (åŸå§‹å€¼: {tiled_dit})", "INFO")
                
                # è®¾ç½®åˆ†å—å¤§å°
                if isinstance(inputs.get("tile_size"), str) and "{{t_z}}" in inputs["tile_size"]:
                    inputs["tile_size"] = str(tile_size)
                    self.log(f"  âœ… è®¾ç½®åˆ†å—å¤§å°: {tile_size}", "INFO")
                elif isinstance(inputs.get("tile_size"), (int, float, str)):
                    try:
                        inputs["tile_size"] = int(tile_size)
                        self.log(f"  âœ… è®¾ç½®åˆ†å—å¤§å°: {tile_size} (ç›´æ¥èµ‹å€¼)", "INFO")
                    except:
                        pass
                
                # è®¾ç½®åˆ†å—é‡å 
                if isinstance(inputs.get("tile_overlap"), str) and "{{t_o}}" in inputs["tile_overlap"]:
                    inputs["tile_overlap"] = str(tile_overlap)
                    self.log(f"  âœ… è®¾ç½®åˆ†å—é‡å : {tile_overlap}", "INFO")
                elif isinstance(inputs.get("tile_overlap"), (int, float, str)):
                    try:
                        inputs["tile_overlap"] = int(tile_overlap)
                        self.log(f"  âœ… è®¾ç½®åˆ†å—é‡å : {tile_overlap} (ç›´æ¥èµ‹å€¼)", "INFO")
                    except:
                        pass
            
            # 4. å›¾åƒç¼©æ”¾èŠ‚ç‚¹ - è¾“å…¥ (ID 26)
            elif node_class == "LayerUtility: ImageScaleByAspectRatio V2" and node_id == "26":
                # è®¾ç½®è¾“å…¥å®½åº¦
                if isinstance(inputs.get("scale_to_length"), str) and "{{IN_WIDTH}}" in inputs["scale_to_length"]:
                    inputs["scale_to_length"] = str(in_width)
                    self.log(f"  âœ… è®¾ç½®è¾“å…¥å®½åº¦: {in_width}", "INFO")
                elif isinstance(inputs.get("scale_to_length"), (int, float, str)):
                    inputs["scale_to_length"] = str(in_width)
                    self.log(f"  âœ… è®¾ç½®è¾“å…¥å®½åº¦: {in_width} (ç›´æ¥èµ‹å€¼)", "INFO")
            
            # 5. å›¾åƒç¼©æ”¾èŠ‚ç‚¹ - è¾“å‡º (ID 19)
            elif node_class == "LayerUtility: ImageScaleByAspectRatio V2" and node_id == "19":
                # è®¾ç½®è¾“å‡ºå®½åº¦
                if isinstance(inputs.get("scale_to_length"), str) and "{{OUT_WIDTH}}" in inputs["scale_to_length"]:
                    inputs["scale_to_length"] = str(out_width)
                    self.log(f"  âœ… è®¾ç½®è¾“å‡ºå®½åº¦: {out_width}", "INFO")
                elif isinstance(inputs.get("scale_to_length"), (int, float, str)):
                    inputs["scale_to_length"] = str(out_width)
                    self.log(f"  âœ… è®¾ç½®è¾“å‡ºå®½åº¦: {out_width} (ç›´æ¥èµ‹å€¼)", "INFO")
            
            # 6. VHS_VideoCombine èŠ‚ç‚¹ (ID 34)
            elif node_class == "VHS_VideoCombine":
                # æ›´æ–°è¾“å‡ºå‰ç¼€
                if isinstance(inputs.get("filename_prefix"), str) and "{{OUTPUT_PREFIX}}" in inputs["filename_prefix"]:
                    inputs["filename_prefix"] = output_prefix
                    self.log(f"  âœ… è®¾ç½®è¾“å‡ºå‰ç¼€: {output_prefix}", "INFO")
                elif isinstance(inputs.get("filename_prefix"), str):
                    inputs["filename_prefix"] = output_prefix
                    self.log(f"  âœ… è®¾ç½®è¾“å‡ºå‰ç¼€: {output_prefix} (ç›´æ¥èµ‹å€¼)", "INFO")
                
                # è®¾ç½® trim_to_audio ä¸º false
                if "trim_to_audio" in inputs:
                    inputs["trim_to_audio"] = False
                    self.log("  âœ… è®¾ç½® trim_to_audio ä¸º false", "INFO")
        
        return modified_workflow
    
    def queue_prompt(self, workflow: Dict, timeout: int = 60) -> Optional[str]:
        """
        å°†å·¥ä½œæµå‘é€åˆ° ComfyUI æ‰§è¡Œ
        
        å‚æ•°:
            workflow: å·¥ä½œæµé…ç½®
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        è¿”å›:
            prompt_id: ä»»åŠ¡ID
        """
        if not self.check_comfyui_server():
            self.log("ComfyUI æœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•æäº¤ä»»åŠ¡", "ERROR")
            return None
        
        try:
            self.log(f"æäº¤ä»»åŠ¡åˆ° ComfyUI", "INFO")
            
            # éªŒè¯å…³é”®å‚æ•°
            self.log(f"=== å·¥ä½œæµå…³é”®å‚æ•°éªŒè¯ ===", "INFO")
            key_nodes = ["25", "28", "29", "34", "26", "19"]
            for node_id in key_nodes:
                if node_id in workflow:
                    node_data = workflow[node_id]
                    node_type = node_data.get("class_type", "Unknown")
                    inputs = node_data.get("inputs", {})
                    self.log(f"èŠ‚ç‚¹ {node_id} ({node_type}):", "INFO")
                    
                    for key in ["video", "force_rate", "frame_load_cap", "skip_first_frames", 
                               "device", "attention_mode", "scale", "tiled_dit", "tile_size", 
                               "tile_overlap", "filename_prefix", "scale_to_length"]:
                        if key in inputs:
                            self.log(f"  {key}: {inputs[key]}", "INFO")
            
            response = requests.post(
                self.api_prompt, 
                json={"prompt": workflow}, 
                timeout=timeout,
                headers={'Content-Type': 'application/json'}
            )
            
            self.log(f"å“åº”çŠ¶æ€ç : {response.status_code}", "INFO")
            
            if response.status_code == 200:
                data = response.json()
                prompt_id = data.get('prompt_id')
                
                if prompt_id:
                    self.log(f"ä»»åŠ¡å·²æäº¤ï¼ŒID: {prompt_id}", "INFO")
                    return prompt_id
                else:
                    self.log(f"æœªæ”¶åˆ°ä»»åŠ¡IDï¼Œå“åº”: {data}", "ERROR")
                    return None
            else:
                self.log(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}", "ERROR")
                self.log(f"é”™è¯¯è¯¦æƒ…: {response.text[:500]}", "ERROR")
                
                if response.status_code == 400:
                    self.log("åˆ†æ400é”™è¯¯å¯èƒ½çš„åŸå› :", "INFO")
                    self.log("  1. å·¥ä½œæµä¸­å­˜åœ¨æœªæ›¿æ¢çš„å ä½ç¬¦", "INFO")
                    self.log("  2. å·¥ä½œæµæ ¼å¼ä¸ç¬¦åˆComfyUIè¦æ±‚", "INFO")
                    self.log("  3. æŸäº›èŠ‚ç‚¹å‚æ•°ç±»å‹ä¸æ­£ç¡®", "INFO")
                
                return None
                
        except requests.exceptions.RequestException as e:
            self.log(f"è¯·æ±‚å¤±è´¥: {e}", "ERROR")
            return None
        except json.JSONDecodeError as e:
            self.log(f"JSON è§£æå¤±è´¥: {e}", "ERROR")
            return None
        except Exception as e:
            self.log(f"æäº¤ä»»åŠ¡å¤±è´¥: {e}", "ERROR")
            return None
    
    def wait_for_task_completion(self, prompt_id: str, timeout: int = 600) -> bool:
        """
        ç­‰å¾…ä»»åŠ¡å®Œæˆ
        
        å‚æ•°:
            prompt_id: ä»»åŠ¡ID
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        è¿”å›:
            æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        start_time = time.time()
        self.log(f"ç­‰å¾…ä»»åŠ¡ {prompt_id} å®Œæˆï¼Œè¶…æ—¶: {timeout}ç§’", "INFO")
        
        while time.time() - start_time < timeout:
            try:
                # æ£€æŸ¥å†å²è®°å½•
                response = requests.get(f"{self.api_history}?max_items=10", timeout=10)
                if response.status_code == 200:
                    history_data = response.json()
                    
                    # æŸ¥æ‰¾ç‰¹å®šä»»åŠ¡
                    if prompt_id in history_data:
                        task_info = history_data[prompt_id]
                        status_info = task_info.get("status", {})
                        
                        # æˆåŠŸå®Œæˆ
                        if status_info.get("status_str") == "success" and status_info.get("completed", False):
                            self.log(f"ä»»åŠ¡ {prompt_id} æˆåŠŸå®Œæˆ", "INFO")
                            return True
                        
                        # é”™è¯¯
                        if status_info.get("status_str") == "error":
                            self.log(f"ä»»åŠ¡ {prompt_id} æ‰§è¡Œé”™è¯¯", "ERROR")
                            return False
                
                # æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
                response = requests.get(self.api_queue, timeout=10)
                if response.status_code == 200:
                    queue_data = response.json()
                    
                    # æ£€æŸ¥æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
                    for task in queue_data.get("queue_running", []):
                        if len(task) > 1 and task[1] == prompt_id:
                            elapsed = time.time() - start_time
                            if elapsed > 60 and int(elapsed) % 30 == 0:
                                self.log(f"ä»»åŠ¡ä»åœ¨è¿è¡Œï¼Œå·²ç­‰å¾… {elapsed:.1f}ç§’", "INFO")
                            time.sleep(5)
                            continue
                
                time.sleep(2)
                
            except requests.exceptions.RequestException as e:
                self.log(f"æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}ï¼Œç»§ç»­ç­‰å¾…...", "WARN")
                time.sleep(5)
                continue
        
        self.log(f"ä»»åŠ¡ {prompt_id} ç­‰å¾…è¶…æ—¶ ({timeout}ç§’)", "ERROR")
        return False
    
    def process_single_video_batch(
        self,
        workflow_template: Dict,
        video_path: str,
        video_fps: float,
        video_width: int,
        video_height: int,
        frames_per_batch: int,
        batch_number: int,
        total_batches: int,
        base_output_prefix: str,
        attn_mode: str = "block_sparse_attention",
        tiled_dit: bool = False,  # ä¿®å¤ï¼šæ”¹ä¸º bool ç±»å‹
        tile_size: int = 256,
        tile_overlap: int = 24,
        scale: int = 2,
        frames_pre: int = 0,
        batch_pre: int = 0,
        gpu_device: str = "auto",
        timeout: int = 600,
        output_dir: str = "output"
    ) -> Tuple[bool, Optional[str], Optional[str]]:
        """
        å¤„ç†å•ä¸ªè§†é¢‘æ‰¹æ¬¡
        
        å‚æ•°:
            workflow_template: å·¥ä½œæµæ¨¡æ¿
            video_path: è§†é¢‘è·¯å¾„
            video_fps: è§†é¢‘å¸§ç‡
            video_width: è§†é¢‘å®½åº¦
            video_height: è§†é¢‘é«˜åº¦
            frames_per_batch: æ¯æ‰¹å¸§æ•°
            batch_number: å½“å‰ä»»åŠ¡æ‰¹æ¬¡å·
            total_batches: æ€»æ‰¹æ¬¡æ•°
            base_output_prefix: åŸºç¡€è¾“å‡ºå‰ç¼€
            attn_mode: ç¨€ç–æ¨¡å¼
            tiled_dit: åˆ†å—å¼€å…³ (å¸ƒå°”å€¼)
            tile_size: åˆ†å—å¤§å°
            tile_overlap: åˆ†å—é‡å 
            scale: æ”¾å¤§å€æ•°
            frames_pre: å·²è·‘å¸§æ•°
            batch_pre: å·²è·‘æ‰¹æ¬¡
            gpu_device: GPUè®¾å¤‡é€‰æ‹©
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            output_dir: è¾“å‡ºç›®å½•
            
        è¿”å›:
            (success: bool, prompt_id: str or None, output_file: str or None)
        """
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        
        # æ™ºèƒ½æ‰¹æ¬¡å¤§å°è°ƒæ•´
        actual_frames_per_batch = frames_per_batch
        if batch_number == total_batches and frames_pre > 0:
            # è®¡ç®—å‰©ä½™å¸§æ•°
            video_fps, total_frames, _, _, _ = self.get_video_info(video_path)
            remaining_frames = total_frames - frames_pre
            
            # è®¡ç®—æœ€åä¸€æ‰¹çš„å®é™…å¸§æ•°
            last_batch_frames = remaining_frames - (frames_per_batch * (batch_number - 1))
            if 0 < last_batch_frames < frames_per_batch:
                actual_frames_per_batch = last_batch_frames
                self.log(f"æœ€åä¸€æ‰¹æ™ºèƒ½è°ƒæ•´å¸§æ•°: {actual_frames_per_batch} å¸§ (åŸ: {frames_per_batch})", "INFO")
        
        # è®¡ç®—è·³è¿‡å¸§æ•°
        frames_skip = frames_pre + frames_per_batch * (batch_number - 1)
        
        # è®¡ç®—å½“å‰æ€»æ‰¹æ¬¡å·
        current_batch_number = batch_pre + batch_number
        
        # ç”Ÿæˆè¾“å‡ºå‰ç¼€
        output_prefix = f"{base_output_prefix}_{current_batch_number:03d}"
        
        # è®¡ç®—è¾“å…¥å’Œè¾“å‡ºå®½åº¦ï¼ˆå¯¹é½åˆ°128ï¼‰
        in_width_aligned = self.calculate_aligned_dimension(video_width, 128)
        out_width_aligned = self.calculate_aligned_dimension(int(video_width * scale), 128)
        
        # é¢„æœŸè¾“å‡ºæ–‡ä»¶è·¯å¾„
        expected_output_file = os.path.join(output_dir, f"{output_prefix}.mp4")
        
        self.log(f"å¤„ç†æ‰¹æ¬¡ {batch_number}/{total_batches} (æ€»æ‰¹æ¬¡: {current_batch_number})", "INFO")
        self.log(f"  ğŸ“‚ è§†é¢‘: {video_name}", "INFO")
        self.log(f"  ğŸ“ åˆ†è¾¨ç‡: {video_width}x{video_height}", "INFO")
        self.log(f"  â±ï¸  å¸§ç‡: {video_fps:.2f}", "INFO")
        self.log(f"  ğŸï¸  æ¯æ‰¹å¸§æ•°: {actual_frames_per_batch} (åŸ: {frames_per_batch})", "INFO")
        self.log(f"  â­ï¸  è·³è¿‡å¸§æ•°: {frames_skip} (å·²è·‘ {frames_pre} + å½“å‰è·³è¿‡ {frames_per_batch*(batch_number-1)})", "INFO")
        self.log(f"  ğŸ“ è¾“å‡ºå‰ç¼€: {output_prefix}", "INFO")
        self.log(f"  âš™ï¸  ç¨€ç–æ¨¡å¼: {attn_mode}", "INFO")
        self.log(f"  ğŸ§± åˆ†å—å¼€å…³: {'å¯ç”¨' if tiled_dit else 'ç¦ç”¨'}", "INFO")
        self.log(f"  ğŸ§© åˆ†å—å¤§å°: {tile_size}", "INFO")
        self.log(f"  ğŸ”— åˆ†å—é‡å : {tile_overlap}", "INFO")
        self.log(f"  ğŸ” ç¼©æ”¾å€æ•°: {scale}", "INFO")
        self.log(f"  ğŸ“ è¾“å…¥å®½åº¦: {video_width} -> {in_width_aligned} (128å¯¹é½)", "INFO")
        self.log(f"  ğŸ“ è¾“å‡ºå®½åº¦: {int(video_width * scale)} -> {out_width_aligned} (128å¯¹é½)", "INFO")
        self.log(f"  ğŸ“„ é¢„æœŸè¾“å‡º: {expected_output_file}", "INFO")
        if frames_pre > 0:
            self.log(f"  ğŸ“Š æ–­ç‚¹ç»­è·‘: å·²å¤„ç† {frames_pre} å¸§ ({batch_pre} æ‰¹)", "INFO")
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(expected_output_file):
            file_size_mb = os.path.getsize(expected_output_file) / (1024 * 1024)
            self.log(f"è¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨: {expected_output_file} ({file_size_mb:.1f}MB)", "WARN")
            response = input("æ˜¯å¦è¦†ç›–ï¼Ÿ(y/n/skip): ").lower()
            if response == 'n':
                self.log(f"è·³è¿‡å·²å­˜åœ¨æ‰¹æ¬¡ {batch_number}", "INFO")
                return True, None, expected_output_file
            elif response == 'skip':
                return False, None, None
        
        # æ›´æ–°å·¥ä½œæµå‚æ•°
        workflow = self.update_workflow_parameters(
            workflow_template,
            video_path,
            video_fps,
            actual_frames_per_batch,  # ä½¿ç”¨è°ƒæ•´åçš„å¸§æ•°
            frames_skip,
            output_prefix,
            attn_mode=attn_mode,
            tiled_dit=tiled_dit,
            tile_size=tile_size,
            tile_overlap=tile_overlap,
            scale=scale,
            in_width=in_width_aligned,
            out_width=out_width_aligned,
            batch_number=batch_number,
            total_batches=total_batches,
            frames_pre=frames_pre,
            batch_pre=batch_pre,
            gpu_device=gpu_device
        )
        
        # æäº¤ä»»åŠ¡
        prompt_id = self.queue_prompt(workflow, timeout=timeout)
        if not prompt_id:
            self.log(f"æäº¤æ‰¹æ¬¡ {batch_number} å¤±è´¥", "ERROR")
            return False, None, None
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        success = self.wait_for_task_completion(prompt_id, timeout=timeout)
        
        if success:
            self.log(f"æ‰¹æ¬¡ {batch_number} å¤„ç†å®Œæˆ (æ€»æ‰¹æ¬¡: {current_batch_number})", "INFO")
            
            # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
            if os.path.exists(expected_output_file):
                file_size_mb = os.path.getsize(expected_output_file) / (1024 * 1024)
                self.log(f"è¾“å‡ºæ–‡ä»¶ç”ŸæˆæˆåŠŸ: {expected_output_file} ({file_size_mb:.1f}MB)", "INFO")
                return success, prompt_id, expected_output_file
            else:
                # å°è¯•æŸ¥æ‰¾å®é™…è¾“å‡ºæ–‡ä»¶
                import glob
                output_files = glob.glob(os.path.join(output_dir, f"{output_prefix}*.mp4"))
                if output_files:
                    actual_output = output_files[0]
                    file_size_mb = os.path.getsize(actual_output) / (1024 * 1024)
                    self.log(f"æ‰¾åˆ°å®é™…è¾“å‡ºæ–‡ä»¶: {actual_output} ({file_size_mb:.1f}MB)", "INFO")
                    return success, prompt_id, actual_output
                else:
                    self.log(f"é¢„æœŸè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½†ä»»åŠ¡æ˜¾ç¤ºæˆåŠŸ", "WARN")
                    return success, prompt_id, None
        else:
            self.log(f"æ‰¹æ¬¡ {batch_number} å¤„ç†å¤±è´¥ (æ€»æ‰¹æ¬¡: {current_batch_number})", "ERROR")
            return False, prompt_id, None
    
    def process_video_file(
        self,
        workflow_template_path: str,
        video_path: str,
        frames_per_batch: int = 50,
        attn_mode: str = "block_sparse_attention",
        tiled_dit: bool = False,  # ä¿®å¤ï¼šæ”¹ä¸º bool ç±»å‹
        tile_size: int = 256,
        tile_overlap: int = 24,
        scale: int = 2,
        gpu_device: str = "auto",
        timeout_per_batch: int = 600,
        frames_pre: int = 0,
        batch_pre: int = 0,
        auto_load_state: bool = True,  # ä¿®å¤ï¼šæ”¹ä¸º bool ç±»å‹
        save_state: bool = True,  # ä¿®å¤ï¼šæ”¹ä¸º bool ç±»å‹
        max_workers: int = 1,
        output_dir: str = "output"
    ) -> Dict:
        """
        å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶
        
        å‚æ•°:
            workflow_template_path: å·¥ä½œæµæ¨¡æ¿è·¯å¾„
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            frames_per_batch: æ¯æ‰¹å¸§æ•°
            attn_mode: ç¨€ç–æ¨¡å¼
            tiled_dit: åˆ†å—å¼€å…³ (å¸ƒå°”å€¼)
            tile_size: åˆ†å—å¤§å°
            tile_overlap: åˆ†å—é‡å 
            scale: æ”¾å¤§å€æ•°
            gpu_device: GPUè®¾å¤‡é€‰æ‹©
            timeout_per_batch: æ¯æ‰¹è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            frames_pre: å·²è·‘å¸§æ•°
            batch_pre: å·²è·‘æ‰¹æ¬¡
            auto_load_state: è‡ªåŠ¨åŠ è½½çŠ¶æ€ (å¸ƒå°”å€¼)
            save_state: ä¿å­˜çŠ¶æ€ (å¸ƒå°”å€¼)
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œæ•°
            output_dir: è¾“å‡ºç›®å½•
            
        è¿”å›:
            å¤„ç†ç»“æœå­—å…¸
        """
        video_name = os.path.basename(video_path)
        self.log(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_name}", "INFO")
        self.log(f"è·¯å¾„: {video_path}", "INFO")
        
        # è‡ªåŠ¨åŠ è½½çŠ¶æ€
        if auto_load_state:
            loaded_frames_pre, loaded_batch_pre, state_info = self.load_processing_state(video_path)
            if loaded_frames_pre > 0 or loaded_batch_pre > 0:
                frames_pre = loaded_frames_pre
                batch_pre = loaded_batch_pre
                self.log(f"è‡ªåŠ¨åŠ è½½æ–­ç‚¹çŠ¶æ€: å·²å¤„ç† {frames_pre} å¸§, {batch_pre} æ‰¹", "INFO")
        
        # æ£€æŸ¥æ–­ç‚¹ç»­è·‘å‚æ•°
        if frames_pre > 0:
            self.log(f"æ–­ç‚¹ç»­è·‘æ¨¡å¼: å·²å¤„ç† {frames_pre} å¸§, {batch_pre} æ‰¹", "INFO")
        
        # åŠ è½½å·¥ä½œæµæ¨¡æ¿
        try:
            workflow_template = self.load_workflow_template(workflow_template_path)
        except Exception as e:
            error_msg = f"åŠ è½½å·¥ä½œæµæ¨¡æ¿å¤±è´¥: {e}"
            self.log(error_msg, "ERROR")
            if save_state:
                self.save_processing_state(video_path, frames_pre, batch_pre, False, error_msg)
            return {
                "video": video_name,
                "path": video_path,
                "success": False,
                "error": error_msg,
                "results": []
            }
        
        # è·å–è§†é¢‘ä¿¡æ¯ï¼ˆåŒ…å«åˆ†è¾¨ç‡ï¼‰
        video_fps, total_frames, video_width, video_height, method = self.get_video_info(video_path)
        self.log(f"è§†é¢‘ä¿¡æ¯: {total_frames} å¸§, {video_fps:.2f} FPS, åˆ†è¾¨ç‡: {video_width}x{video_height} (æ–¹æ³•: {method})", "INFO")
        
        # è®¡ç®—å¯¹é½åçš„è¾“å…¥è¾“å‡ºå®½åº¦
        in_width_aligned = self.calculate_aligned_dimension(video_width, 128)
        out_width_aligned = self.calculate_aligned_dimension(int(video_width * scale), 128)
        self.log(f"å°ºå¯¸å¯¹é½: è¾“å…¥ {video_width} -> {in_width_aligned}, è¾“å‡º {int(video_width * scale)} -> {out_width_aligned}", "INFO")
        
        # è®¡ç®—å‰©ä½™å¯å¤„ç†å¸§æ•°
        remaining_frames = total_frames - frames_pre
        if remaining_frames <= 0:
            self.log(f"è§†é¢‘å·²å…¨éƒ¨å¤„ç†å®Œæˆï¼Œæ— éœ€ç»§ç»­å¤„ç†", "INFO")
            result = {
                "video": video_name,
                "path": video_path,
                "success": True,
                "batches_processed": 0,
                "total_batches": 0,
                "video_fps": video_fps,
                "video_width": video_width,
                "video_height": video_height,
                "in_width_aligned": in_width_aligned,
                "out_width_aligned": out_width_aligned,
                "total_frames": total_frames,
                "remaining_frames": 0,
                "frames_pre": frames_pre,
                "batch_pre": batch_pre,
                "success_rate": "100%",
                "results": []
            }
            if save_state:
                self.save_processing_state(video_path, frames_pre, batch_pre, True)
            return result
        
        # è®¡ç®—æ‰¹æ¬¡æ•°ï¼ˆä¸flashvsr_xzg.pyä¿æŒä¸€è‡´çš„é€»è¾‘ï¼‰
        # (æ€»å¸§æ•° - {{FRAMS_PRE}}) / frames_per_batch
        total_batches = remaining_frames // frames_per_batch
        if remaining_frames % frames_per_batch > 0:
            total_batches += 1
        
        self.log(f"æ‰¹æ¬¡è®¡ç®—: {remaining_frames} å‰©ä½™å¸§ / {frames_per_batch} å¸§æ¯æ‰¹ = {total_batches} æ‰¹", "INFO")
        self.log(f"è¿›åº¦: {frames_pre}/{total_frames} å¸§ ({frames_pre/total_frames*100:.1f}%)", "INFO")
        self.log(f"å¹¶è¡Œå¤„ç†: {max_workers} ä¸ªå·¥ä½œçº¿ç¨‹", "INFO")
        
        # åŸºç¡€è¾“å‡ºå‰ç¼€
        video_base_name = os.path.splitext(video_name)[0]
        base_output_prefix = f"flashvsr_{video_base_name}"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        results = []
        success_count = 0
        output_files = []
        
        # å¹¶è¡Œå¤„ç†é€»è¾‘
        if max_workers > 1 and total_batches > 1:
            self.log(f"å¯åŠ¨å¹¶è¡Œå¤„ç†ï¼Œæœ€å¤§å·¥ä½œçº¿ç¨‹æ•°: {max_workers}", "INFO")
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            from concurrent.futures import ThreadPoolExecutor
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = []
                for batch_number in range(1, total_batches + 1):
                    future = executor.submit(
                        self.process_single_video_batch,
                        workflow_template,
                        video_path,
                        video_fps,
                        video_width,
                        video_height,
                        frames_per_batch,
                        batch_number,
                        total_batches,
                        base_output_prefix,
                        attn_mode,
                        tiled_dit,
                        tile_size,
                        tile_overlap,
                        scale,
                        frames_pre,
                        batch_pre,
                        gpu_device,
                        timeout_per_batch,
                        output_dir
                    )
                    futures.append((batch_number, future))
                
                # æ”¶é›†ç»“æœ
                for batch_number, future in futures:
                    try:
                        success, prompt_id, output_file = future.result(timeout=timeout_per_batch + 60)
                        
                        results.append({
                            "batch": batch_number,
                            "total_batch": batch_pre + batch_number,
                            "success": success,
                            "prompt_id": prompt_id,
                            "output_file": output_file,
                            "frames_skip": frames_pre + frames_per_batch * (batch_number - 1)
                        })
                        
                        if success:
                            success_count += 1
                            if output_file:
                                output_files.append(output_file)
                            # ä¿å­˜è¿›åº¦çŠ¶æ€
                            current_frames = frames_pre + batch_number * frames_per_batch
                            if save_state and batch_number % 3 == 0:
                                self.save_processing_state(video_path, min(current_frames, total_frames), 
                                                         batch_pre + batch_number, True)
                        else:
                            self.log(f"æ‰¹æ¬¡ {batch_number} å¤±è´¥", "WARN")
                            
                    except Exception as e:
                        self.log(f"æ‰¹æ¬¡ {batch_number} æ‰§è¡Œå¼‚å¸¸: {e}", "ERROR")
                        results.append({
                            "batch": batch_number,
                            "total_batch": batch_pre + batch_number,
                            "success": False,
                            "error": str(e),
                            "frames_skip": frames_pre + frames_per_batch * (batch_number - 1)
                        })
        else:
            # é¡ºåºå¤„ç†
            for batch_number in range(1, total_batches + 1):
                self.log(f"{'='*60}", "INFO")
                success, prompt_id, output_file = self.process_single_video_batch(
                    workflow_template,
                    video_path,
                    video_fps,
                    video_width,
                    video_height,
                    frames_per_batch,
                    batch_number,
                    total_batches,
                    base_output_prefix,
                    attn_mode,
                    tiled_dit,
                    tile_size,
                    tile_overlap,
                    scale,
                    frames_pre,
                    batch_pre,
                    gpu_device,
                    timeout_per_batch,
                    output_dir
                )
                
                results.append({
                    "batch": batch_number,
                    "total_batch": batch_pre + batch_number,
                    "success": success,
                    "prompt_id": prompt_id,
                    "output_file": output_file,
                    "frames_skip": frames_pre + frames_per_batch * (batch_number - 1)
                })
                
                if success:
                    success_count += 1
                    if output_file:
                        output_files.append(output_file)
                    # ä¿å­˜è¿›åº¦çŠ¶æ€
                    current_frames = frames_pre + batch_number * frames_per_batch
                    if save_state and batch_number % 3 == 0:
                        self.save_processing_state(video_path, min(current_frames, total_frames), 
                                                 batch_pre + batch_number, True)
                else:
                    self.log(f"æ‰¹æ¬¡ {batch_number} å¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­å¤„ç†åç»­æ‰¹æ¬¡ï¼Ÿ", "WARN")
                    # è¿™é‡Œå¯ä»¥æ·»åŠ ä¸­æ–­é€»è¾‘ï¼Œé»˜è®¤ç»§ç»­å¤„ç†
                    continue
        
        # æ±‡æ€»ç»“æœ
        all_success = success_count == total_batches
        processed_frames = frames_pre + success_count * frames_per_batch
        if processed_frames > total_frames:
            processed_frames = total_frames
        
        summary = {
            "video": video_name,
            "path": video_path,
            "success": all_success,
            "batches_processed": success_count,
            "total_batches": total_batches,
            "video_fps": video_fps,
            "video_width": video_width,
            "video_height": video_height,
            "in_width_aligned": in_width_aligned,
            "out_width_aligned": out_width_aligned,
            "total_frames": total_frames,
            "remaining_frames": remaining_frames,
            "processed_frames": processed_frames,
            "frames_per_batch": frames_per_batch,
            "frames_pre": frames_pre,
            "batch_pre": batch_pre,
            "total_batch_count": batch_pre + success_count,
            "success_rate": f"{success_count}/{total_batches} ({success_count/total_batches*100:.1f}%)",
            "progress": f"{processed_frames}/{total_frames} ({processed_frames/total_frames*100:.1f}%)",
            "output_files": output_files,
            "output_dir": output_dir,
            "results": results,
            "parameters": {
                "attn_mode": attn_mode,
                "tiled_dit": tiled_dit,
                "tile_size": tile_size,
                "tile_overlap": tile_overlap,
                "scale": scale,
                "gpu_device": gpu_device
            }
        }
        
        self.log(f"{'='*60}", "INFO")
        if all_success:
            self.log(f"è§†é¢‘ {video_name} å½“å‰é˜¶æ®µå¤„ç†å®Œæˆ", "INFO")
            self.log(f"ç´¯è®¡è¿›åº¦: {processed_frames}/{total_frames} å¸§ ({processed_frames/total_frames*100:.1f}%)", "INFO")
            self.log(f"ç´¯è®¡æ‰¹æ¬¡: {batch_pre + success_count} æ‰¹", "INFO")
            self.log(f"ç”Ÿæˆæ–‡ä»¶: {len(output_files)} ä¸ª", "INFO")
            for i, file_path in enumerate(output_files, 1):
                if os.path.exists(file_path):
                    size_mb = os.path.getsize(file_path) / (1024 * 1024)
                    self.log(f"  {i:2d}. {os.path.basename(file_path)} ({size_mb:.1f}MB)", "INFO")
        else:
            self.log(f"è§†é¢‘ {video_name} éƒ¨åˆ†æ‰¹æ¬¡å¤±è´¥ ({success_count}/{total_batches})", "WARN")
        
        # ä¿å­˜æœ€ç»ˆçŠ¶æ€
        if save_state:
            self.save_processing_state(
                video_path, 
                processed_frames, 
                batch_pre + success_count, 
                all_success,
                "" if all_success else f"{total_batches - success_count} batches failed"
            )
        
        return summary
    
    def process_directory(
        self,
        workflow_template_path: str,
        input_path: str,
        pattern: str = '*.mp4',
        frames_per_batch: int = 50,
        attn_mode: str = "block_sparse_attention",
        tiled_dit: bool = False,
        tile_size: int = 256,
        tile_overlap: int = 24,
        scale: int = 2,
        gpu_device: str = "auto",
        timeout_per_batch: int = 600,
        max_workers: int = 1,
        output_dir: str = "output",
        auto_load_state: bool = True,
        save_state: bool = True
    ) -> List[Dict]:
        """
        å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶
        
        å‚æ•°:
            workflow_template_path: å·¥ä½œæµæ¨¡æ¿è·¯å¾„
            input_path: è¾“å…¥ç›®å½•
            pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
            frames_per_batch: æ¯æ‰¹å¸§æ•°
            attn_mode: ç¨€ç–æ¨¡å¼
            tiled_dit: åˆ†å—å¼€å…³ (å¸ƒå°”å€¼)
            tile_size: åˆ†å—å¤§å°
            tile_overlap: åˆ†å—é‡å 
            scale: æ”¾å¤§å€æ•°
            gpu_device: GPUè®¾å¤‡é€‰æ‹©
            timeout_per_batch: æ¯æ‰¹è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_workers: æœ€å¤§å¹¶è¡Œå·¥ä½œæ•°
            output_dir: è¾“å‡ºç›®å½•
            auto_load_state: è‡ªåŠ¨åŠ è½½çŠ¶æ€ (å¸ƒå°”å€¼)
            save_state: ä¿å­˜çŠ¶æ€ (å¸ƒå°”å€¼)
            
        è¿”å›:
            æ‰€æœ‰è§†é¢‘çš„å¤„ç†ç»“æœåˆ—è¡¨
        """
        # æ”¶é›†è§†é¢‘æ–‡ä»¶
        video_files = self.collect_video_files(input_path, pattern)
        
        if not video_files:
            self.log(f"åœ¨ç›®å½• {input_path} ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶", "ERROR")
            return []
        
        self.log(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶", "INFO")
        for vf in video_files:
            self.log(f"  - {os.path.basename(vf)}", "INFO")
        
        all_results = []
        
        # å¤„ç†æ¯ä¸ªè§†é¢‘æ–‡ä»¶
        for i, video_path in enumerate(video_files, 1):
            self.log(f"\n{'#'*80}", "INFO")
            self.log(f"è¿›åº¦: {i}/{len(video_files)}", "INFO")
            
            # ä¸ºæ¯ä¸ªè§†é¢‘åˆ›å»ºå•ç‹¬çš„è¾“å‡ºå­ç›®å½•
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            video_output_dir = os.path.join(output_dir, video_name)
            
            result = self.process_video_file(
                workflow_template_path,
                video_path,
                frames_per_batch,
                attn_mode,
                tiled_dit,
                tile_size,
                tile_overlap,
                scale,
                gpu_device,
                timeout_per_batch,
                frames_pre=0,  # ä»çŠ¶æ€æ–‡ä»¶åŠ è½½
                batch_pre=0,   # ä»çŠ¶æ€æ–‡ä»¶åŠ è½½
                auto_load_state=auto_load_state,
                save_state=save_state,
                max_workers=max_workers,
                output_dir=video_output_dir
            )
            
            all_results.append(result)
            
            # è¾“å‡ºå½“å‰è§†é¢‘ç»“æœ
            if result["success"]:
                self.log(f"è§†é¢‘ {result['video']} å¤„ç†æˆåŠŸ ({result['success_rate']})", "INFO")
            else:
                self.log(f"è§†é¢‘ {result['video']} å¤„ç†å¤±è´¥ ({result['success_rate']})", "ERROR")
        
        return all_results
    
    def collect_video_files(self, input_path: str, pattern: str = '*.mp4') -> List[str]:
        """
        æ”¶é›†è§†é¢‘æ–‡ä»¶
        
        å‚æ•°:
            input_path: è¾“å…¥è·¯å¾„
            pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
            
        è¿”å›:
            è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        video_files = []
        supported_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', 
                               '.MP4', '.MOV', '.AVI', '.MKV', '.WEBM', '.FLV']
        
        if os.path.isfile(input_path):
            # å•ä¸ªæ–‡ä»¶
            file_ext = os.path.splitext(input_path)[1].lower()
            if file_ext in [ext.lower() for ext in supported_extensions]:
                video_files.append(input_path)
                self.log(f"æ·»åŠ å•ä¸ªæ–‡ä»¶: {input_path}", "INFO")
            else:
                self.log(f"æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ: {input_path}", "ERROR")
        
        elif os.path.isdir(input_path):
            # ç›®å½•
            self.log(f"æ‰«æç›®å½•: {input_path}", "INFO")
            
            # æ ¹æ®æ¨¡å¼æŸ¥æ‰¾æ–‡ä»¶
            search_pattern = os.path.join(input_path, pattern)
            found_files = glob(search_pattern, recursive=False)
            
            # æŸ¥æ‰¾å…¶ä»–å¸¸è§è§†é¢‘æ ¼å¼
            for ext in supported_extensions:
                if f"*{ext}" not in pattern:
                    additional_pattern = os.path.join(input_path, f"*{ext}")
                    additional_files = glob(additional_pattern, recursive=False)
                    found_files.extend(additional_files)
            
            # å»é‡å¹¶æ’åº
            video_files = sorted(list(set(found_files)))
            
            if not video_files:
                self.log(f"ç›®å½• {input_path} ä¸­æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶", "WARN")
            else:
                self.log(f"ä»ç›®å½•æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶", "INFO")
        
        else:
            self.log(f"è·¯å¾„ä¸å­˜åœ¨: {input_path}", "ERROR")
        
        return video_files

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ComfyUI FlashVSR-XZG MIX æ‰¹é‡è§†é¢‘å¤„ç†è„šæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶ï¼ˆä»å¤´å¼€å§‹ï¼‰
  python flashvsr_mix.py -i video.mp4 --template api_flashvsr_mix.json
  
  # æŒ‡å®šç¨€ç–æ¨¡å¼å’Œåˆ†å—å¼€å…³
  python flashvsr_mix.py -i video.mp4 --template api_flashvsr_mix.json --attn-mode sparse_sage_attention --tiled-dit
  
  # è‡ªå®šä¹‰åˆ†å—å‚æ•°å’Œæ”¾å¤§å€æ•°
  python flashvsr_mix.py -i video.mp4 --template api_flashvsr_mix.json --tile-size 512 --tile-overlap 32 --scale 2
  
  # æ–­ç‚¹ç»­è·‘ï¼Œè‡ªåŠ¨åŠ è½½çŠ¶æ€æ–‡ä»¶
  python flashvsr_mix.py -i video.mp4 --template api_flashvsr_mix.json --auto-load-state
  
  # æŒ‡å®šå·²å¤„ç†å¸§æ•°å’Œæ‰¹æ¬¡
  python flashvsr_mix.py -i video.mp4 --template api_flashvsr_mix.json --frames-pre 100 --batch-pre 3
  
  # æŒ‡å®šGPUè®¾å¤‡
  python flashvsr_mix.py -i video.mp4 --template api_flashvsr_mix.json --gpu 0
  
  # å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶
  python flashvsr_mix.py -i ./videos --template api_flashvsr_mix.json --max-workers 2

åŠŸèƒ½ç‰¹æ€§:
  1. è‡ªåŠ¨128å¯¹é½ï¼šè‡ªåŠ¨è®¡ç®—è¾“å…¥å’Œè¾“å‡ºå®½åº¦ï¼Œå¯¹é½åˆ°128çš„å€æ•°
  2. å¤šç§ç¨€ç–æ¨¡å¼ï¼šæ”¯æŒ block_sparse_attention å’Œ sparse_sage_attention
  3. åˆ†å—å¼€å…³ï¼šå¯æ§åˆ¶æ˜¯å¦å¯ç”¨åˆ†å—å¤„ç†
  4. æ–­ç‚¹ç»­è·‘ï¼šæ”¯æŒè‡ªåŠ¨åŠ è½½å’Œä¿å­˜å¤„ç†çŠ¶æ€
  5. å¹¶è¡Œå¤„ç†ï¼šæ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†

æ³¨æ„:
  1. è„šæœ¬ä½¿ç”¨ pymediainfo è·å–è§†é¢‘ä¿¡æ¯ï¼Œè¯·ç¡®ä¿å·²å®‰è£…
  2. è¾“å…¥è¾“å‡ºå®½åº¦ä¼šè‡ªåŠ¨å¯¹é½åˆ°128çš„å€æ•°
  3. çŠ¶æ€æ–‡ä»¶ä¿å­˜åœ¨ ./states_mix/ ç›®å½•ä¸‹
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('-i', '--input', type=str, required=True,
                       help='è¾“å…¥è·¯å¾„ï¼ˆå¯ä»¥æ˜¯è§†é¢‘æ–‡ä»¶æˆ–ç›®å½•ï¼‰')
    
    # å·¥ä½œæµå‚æ•°
    parser.add_argument('--template', type=str, default='api_flashvsr_mix.json',
                       help='å·¥ä½œæµæ¨¡æ¿ JSON æ–‡ä»¶è·¯å¾„ (é»˜è®¤: api_flashvsr_mix.json)')
    parser.add_argument('--frames-per-batch', type=int, default=50,
                       help='æ¯æ‰¹å¤„ç†çš„å¸§æ•° (é»˜è®¤: 50)')
    
    # FlashVSR å¤„ç†å‚æ•°
    parser.add_argument('--attn-mode', type=str, default='block_sparse_attention',
                       choices=['block_sparse_attention', 'sparse_sage_attention'],
                       help='ç¨€ç–æ¨¡å¼: block_sparse_attention (é»˜è®¤) æˆ– sparse_sage_attention')
    parser.add_argument('--tiled-dit', action='store_true',
                       help='å¯ç”¨åˆ†å—å¤„ç† (é»˜è®¤: ç¦ç”¨)')
    parser.add_argument('--tile-size', type=int, default=256,
                       help='åˆ†å—å¤§å° (é»˜è®¤: 256)')
    parser.add_argument('--tile-overlap', type=int, default=24,
                       help='åˆ†å—é‡å åƒç´  (é»˜è®¤: 24)')
    parser.add_argument('--scale', type=int, default=2,
                       help='æ”¾å¤§å€æ•° (é»˜è®¤: 2)')
    
    # GPUå‚æ•°
    parser.add_argument('--gpu', type=str, default='auto',
                       help='GPUè®¾å¤‡é€‰æ‹©: auto, 0, 1, 2, cuda:0, cuda:1ç­‰ (é»˜è®¤: auto)')
    
    # æ–­ç‚¹ç»­è·‘å‚æ•°
    parser.add_argument('--frames-pre', type=int, default=0,
                       help='å·²å¤„ç†çš„å¸§æ•°ï¼ˆæ‰‹åŠ¨æŒ‡å®šï¼‰(é»˜è®¤: 0)')
    parser.add_argument('--batch-pre', type=int, default=0,
                       help='å·²å¤„ç†çš„æ‰¹æ¬¡ï¼ˆæ‰‹åŠ¨æŒ‡å®šï¼‰(é»˜è®¤: 0)')
    parser.add_argument('--auto-load-state', action='store_true',
                       help='è‡ªåŠ¨ä»çŠ¶æ€æ–‡ä»¶åŠ è½½å¤„ç†è¿›åº¦')
    parser.add_argument('--save-state', action='store_true', default=True,
                       help='ä¿å­˜å¤„ç†çŠ¶æ€åˆ°æ–‡ä»¶ (é»˜è®¤: True)')
    parser.add_argument('--no-save-state', action='store_false', dest='save_state',
                       help='ä¸ä¿å­˜å¤„ç†çŠ¶æ€æ–‡ä»¶')
    
    # å¹¶è¡Œå¤„ç†å‚æ•°
    parser.add_argument('--max-workers', type=int, default=1,
                       help='æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•° (é»˜è®¤: 1)')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output-dir', type=str, default='output',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: output)')
    
    # å¤„ç†å‚æ•°
    parser.add_argument('--timeout', type=int, default=600,
                       help='æ¯æ‰¹å¤„ç†çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 600)')
    parser.add_argument('--pattern', type=str, default='*.mp4',
                       help='æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œå½“è¾“å…¥æ˜¯ç›®å½•æ—¶ä½¿ç”¨ (é»˜è®¤: *.mp4)')
    
    # æœåŠ¡å™¨å‚æ•°
    parser.add_argument('--server', type=str, default='http://127.0.0.1:8188',
                       help='ComfyUI æœåŠ¡å™¨åœ°å€ (é»˜è®¤: http://127.0.0.1:8188)')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--log-dir', type=str, default='.',
                       help='æ—¥å¿—ç›®å½• (é»˜è®¤: å½“å‰ç›®å½•)')
    parser.add_argument('--skip-pymedia-check', action='store_true',
                       help='è·³è¿‡ pymediainfo æ£€æŸ¥')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ pymediainfo
    if not PYMEDIAINFO_AVAILABLE and not args.skip_pymedia_check:
        print("âš ï¸  æœªæ£€æµ‹åˆ° pymediainfo åº“")
        response = input("æ˜¯å¦ç»§ç»­? (y/n): ")
        if response.lower() != 'y':
            print("é€€å‡ºç¨‹åº")
            return
    
    # æ£€æŸ¥è¾“å…¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input):
        print(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {args.input}")
        return
    
    # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.template):
        print(f"å·¥ä½œæµæ¨¡æ¿ä¸å­˜åœ¨: {args.template}")
        return
    
    # éªŒè¯æ–­ç‚¹å‚æ•°
    if args.frames_pre < 0:
        print(f"å·²å¤„ç†å¸§æ•°ä¸èƒ½ä¸ºè´Ÿæ•°: {args.frames_pre}")
        return
    if args.batch_pre < 0:
        print(f"å·²å¤„ç†æ‰¹æ¬¡ä¸èƒ½ä¸ºè´Ÿæ•°: {args.batch_pre}")
        return
    
    # éªŒè¯å¹¶è¡Œå¤„ç†å‚æ•°
    if args.max_workers < 1:
        print(f"æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°å¿…é¡»å¤§äº0: {args.max_workers}")
        return
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = FlashVSR_XZG_MIX_Processor(
        comfyui_url=args.server,
        log_dir=args.log_dir
    )
    
    # æ£€æŸ¥ ComfyUI æœåŠ¡
    if not processor.check_comfyui_server():
        processor.log("ComfyUI æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿ ComfyUI å·²å¯åŠ¨", "ERROR")
        return
    
    processor.log(f"FlashVSR-XZG MIX å¼€å§‹å¤„ç†", "INFO")
    processor.log(f"è¾“å…¥è·¯å¾„: {args.input}", "INFO")
    processor.log(f"å·¥ä½œæµæ¨¡æ¿: {args.template}", "INFO")
    processor.log(f"æ¯æ‰¹å¸§æ•°: {args.frames_per_batch}", "INFO")
    processor.log(f"ç¨€ç–æ¨¡å¼: {args.attn_mode}", "INFO")
    processor.log(f"åˆ†å—å¼€å…³: {'å¯ç”¨' if args.tiled_dit else 'ç¦ç”¨'}", "INFO")
    processor.log(f"åˆ†å—å¤§å°: {args.tile_size}", "INFO")
    processor.log(f"åˆ†å—é‡å : {args.tile_overlap}", "INFO")
    processor.log(f"ç¼©æ”¾å€æ•°: {args.scale}", "INFO")
    processor.log(f"è¶…æ—¶æ—¶é—´: {args.timeout}ç§’", "INFO")
    processor.log(f"è¾“å‡ºç›®å½•: {args.output_dir}", "INFO")
    processor.log(f"å¹¶è¡Œå¤„ç†: {args.max_workers} ä¸ªå·¥ä½œçº¿ç¨‹", "INFO")
    
    if args.auto_load_state:
        processor.log(f"è‡ªåŠ¨åŠ è½½çŠ¶æ€: å·²å¯ç”¨", "INFO")
    if args.frames_pre > 0 or args.batch_pre > 0:
        processor.log(f"æ‰‹åŠ¨æ–­ç‚¹: å·²å¤„ç† {args.frames_pre} å¸§, {args.batch_pre} æ‰¹", "INFO")
    if not args.save_state:
        processor.log(f"çŠ¶æ€ä¿å­˜: å·²ç¦ç”¨", "INFO")
    
    if args.gpu == "auto":
        processor.log(f"GPUè®¾å¤‡: auto (è‡ªåŠ¨é€‰æ‹©)", "INFO")
    elif args.gpu.isdigit():
        processor.log(f"GPUè®¾å¤‡: cuda:{args.gpu}", "INFO")
    else:
        processor.log(f"GPUè®¾å¤‡: {args.gpu}", "INFO")
    
    start_time = time.time()
    
    # åˆ¤æ–­è¾“å…¥ç±»å‹å¹¶å¤„ç†
    if os.path.isfile(args.input):
        # å•ä¸ªæ–‡ä»¶
        processor.log(f"å¤„ç†å•ä¸ªæ–‡ä»¶", "INFO")
        result = processor.process_video_file(
            args.template,
            args.input,
            args.frames_per_batch,
            args.attn_mode,
            args.tiled_dit,
            args.tile_size,
            args.tile_overlap,
            args.scale,
            args.gpu,
            args.timeout,
            args.frames_pre,
            args.batch_pre,
            args.auto_load_state,
            args.save_state,
            args.max_workers,
            args.output_dir
        )
        
        results = [result]
        
    elif os.path.isdir(args.input):
        # ç›®å½•
        processor.log(f"å¤„ç†ç›®å½•", "INFO")
        results = processor.process_directory(
            args.template,
            args.input,
            args.pattern,
            args.frames_per_batch,
            args.attn_mode,
            args.tiled_dit,
            args.tile_size,
            args.tile_overlap,
            args.scale,
            args.gpu,
            args.timeout,
            args.max_workers,
            args.output_dir,
            args.auto_load_state,
            args.save_state
        )
    
    else:
        processor.log(f"è¾“å…¥è·¯å¾„ç±»å‹æœªçŸ¥: {args.input}", "ERROR")
        return
    
    # è®¡ç®—æ€»è€—æ—¶
    total_time = time.time() - start_time
    
    # è¾“å‡ºæ±‡æ€»ç»“æœ
    processor.log(f"\n{'='*80}", "INFO")
    processor.log(f"FlashVSR-XZG MIX å¤„ç†å®Œæˆæ±‡æ€»", "INFO")
    processor.log(f"{'='*80}", "INFO")
    
    if not results:
        processor.log(f"æ²¡æœ‰å¤„ç†ä»»ä½•è§†é¢‘", "ERROR")
        return
    
    total_videos = len(results)
    success_videos = sum(1 for r in results if r["success"])
    failed_videos = total_videos - success_videos
    
    total_batches = sum(r["total_batches"] for r in results)
    success_batches = sum(r["batches_processed"] for r in results)
    
    # è®¡ç®—æ€»å¤„ç†å¸§æ•°
    total_frames_processed = sum(r.get("processed_frames", 0) for r in results)
    total_files_generated = sum(len(r.get("output_files", [])) for r in results)
    
    # è¾“å‡ºå‚æ•°æ‘˜è¦
    for i, result in enumerate(results, 1):
        if result.get("parameters"):
            params = result["parameters"]
            processor.log(f"è§†é¢‘ {i} å‚æ•°:", "INFO")
            processor.log(f"  ç¨€ç–æ¨¡å¼: {params.get('attn_mode')}", "INFO")
            processor.log(f"  åˆ†å—å¼€å…³: {params.get('tiled_dit')}", "INFO")
            processor.log(f"  åˆ†å—å¤§å°: {params.get('tile_size')}", "INFO")
            processor.log(f"  åˆ†å—é‡å : {params.get('tile_overlap')}", "INFO")
            processor.log(f"  ç¼©æ”¾å€æ•°: {params.get('scale')}", "INFO")
            processor.log(f"  è¾“å…¥å®½åº¦: {result.get('in_width_aligned', 'N/A')}", "INFO")
            processor.log(f"  è¾“å‡ºå®½åº¦: {result.get('out_width_aligned', 'N/A')}", "INFO")
    
    processor.log(f"æ€»è€—æ—¶: {total_time:.2f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)", "INFO")
    processor.log(f"æ€»è§†é¢‘æ•°: {total_videos}", "INFO")
    processor.log(f"æˆåŠŸè§†é¢‘: {success_videos}", "INFO")
    processor.log(f"å¤±è´¥è§†é¢‘: {failed_videos}", "INFO" if failed_videos == 0 else "ERROR")
    processor.log(f"æ€»æ‰¹æ¬¡: {total_batches}", "INFO")
    processor.log(f"æˆåŠŸæ‰¹æ¬¡: {success_batches} ({success_batches/total_batches*100:.1f}%)", "INFO")
    processor.log(f"æ€»å¤„ç†å¸§æ•°: {total_frames_processed}", "INFO")
    processor.log(f"æ€»ç”Ÿæˆæ–‡ä»¶: {total_files_generated}", "INFO")
    
    # è¾“å‡ºå¤±è´¥è¯¦æƒ…
    if failed_videos > 0:
        processor.log(f"\nå¤±è´¥è§†é¢‘è¯¦æƒ…:", "ERROR")
        for result in results:
            if not result["success"]:
                processor.log(f"  - {result['video']}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}", "ERROR")
    
    processor.log(f"\nçŠ¶æ€æ–‡ä»¶ç›®å½•: {processor.state_dir}", "INFO")
    processor.log(f"è¯¦ç»†æ—¥å¿—: {processor.log_file}", "INFO")
    processor.log(f"FlashVSR-XZG MIX å¤„ç†å®Œæˆ!", "INFO")

if __name__ == "__main__":
    main()