"""
ComfyUI FlashVSR æ‰¹é‡å¤„ç†å™¨ v22
åŠŸèƒ½ï¼šæ‰¹å¤„ç†è§†é¢‘è¶…åˆ†ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ ã€æ™ºèƒ½é‡å¯ã€çŠ¶æ€ç›‘æ§
ä½œè€…ï¼šæ™ºèƒ½è§†é¢‘å¤„ç†åŠ©æ‰‹
ç‰ˆæœ¬ï¼šv22 (2024-01-15)
ä¸»è¦æ”¹è¿›ï¼š
1. ç®€åŒ–è¶…æ—¶é€»è¾‘ï¼šåªä¿ç•™æ‰¹æ¬¡è¶…æ—¶ï¼Œå»é™¤è§†é¢‘æ€»è¶…æ—¶
2. å¢å¼ºçŠ¶æ€æ£€æŸ¥ï¼šå¢åŠ é‡è¯•æœºåˆ¶ï¼Œé¿å…å•æ¬¡æ£€æŸ¥å¤±è´¥
3. ä»»åŠ¡æäº¤é—´éš”ï¼šé¿å…é˜Ÿåˆ—å†²å‡»
4. è¯¦ç»†çŠ¶æ€è¿½è¸ªï¼šåŒºåˆ†è¿è¡Œé˜Ÿåˆ—å’Œç­‰å¾…é˜Ÿåˆ—
5. æ‰¹æ¬¡æ—¶é—´è¿½è¸ªï¼šè®°å½•æ¯ä¸ªæ‰¹æ¬¡å¤„ç†æ—¶é—´ç”¨äºæ™ºèƒ½åˆ¤æ–­
6. æ›´ç¨³å¥çš„ä»»åŠ¡æäº¤å’Œç›‘æ§
"""

import os
import json
import time
import logging
import requests
import glob
import shutil
import subprocess
import random
import string
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime
import atexit
import gc

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('comfyui_batch_processor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å¯é€‰ä¾èµ–
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    logger.warning("âš ï¸  torchä¸å¯ç”¨ï¼ŒGPUæ¸…ç†åŠŸèƒ½å°†å—é™")

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    logger.warning("âš ï¸  psutilä¸å¯ç”¨ï¼Œè¿›ç¨‹ç®¡ç†åŠŸèƒ½å°†å—é™")

try:
    from pymediainfo import MediaInfo
    PYMEDIAINFO_AVAILABLE = True
except ImportError:
    PYMEDIAINFO_AVAILABLE = False
    logger.warning("âš ï¸  pymediainfoä¸å¯ç”¨ï¼Œè§†é¢‘å¸§æ•°æ£€æµ‹å°†ä½¿ç”¨ä¼°è®¡å€¼")

def get_video_info(video_path: str) -> Dict[str, Any]:
    """è·å–è§†é¢‘ä¿¡æ¯"""
    video_info = {
        'total_frames': 0,
        'fps': 0.0,
        'duration': 0.0,
        'resolution': 'æœªçŸ¥',
        'file_size': os.path.getsize(video_path)
    }
    
    if PYMEDIAINFO_AVAILABLE:
        try:
            media_info = MediaInfo.parse(video_path)
            for track in media_info.tracks:
                if track.track_type == 'Video':
                    video_info['total_frames'] = int(track.frame_count) if hasattr(track, 'frame_count') else 0
                    video_info['fps'] = float(track.frame_rate) if hasattr(track, 'frame_rate') else 0.0
                    video_info['duration'] = float(track.duration) / 1000.0 if hasattr(track, 'duration') else 0.0
                    video_info['resolution'] = f"{track.width}x{track.height}" if hasattr(track, 'width') and hasattr(track, 'height') else 'æœªçŸ¥'
                    break
        except Exception as e:
            logger.warning(f"âš ï¸  æ— æ³•é€šè¿‡pymediainfoè·å–è§†é¢‘ä¿¡æ¯: {e}")
    
    # å¦‚æœæ— æ³•è·å–å¸§æ•°ï¼Œå°è¯•é€šè¿‡æ—¶é•¿å’Œå¸§ç‡ä¼°ç®—
    if video_info['total_frames'] <= 0 and video_info['duration'] > 0 and video_info['fps'] > 0:
        video_info['total_frames'] = int(video_info['duration'] * video_info['fps'])
        logger.info(f"ğŸ“Š é€šè¿‡æ—¶é•¿å’Œå¸§ç‡ä¼°ç®—æ€»å¸§æ•°: {video_info['total_frames']}")
    
    return video_info

class ComfyUI_Client:
    """ComfyUI APIå®¢æˆ·ç«¯ - å¢å¼ºç‰ˆ"""
    
    def __init__(self, server_address: str = "http://127.0.0.1:8188"):
        self.server_address = server_address
        self.session = requests.Session()
        self.client_id = self.generate_client_id()
        # æ·»åŠ é‡è¯•æœºåˆ¶
        self.max_retries = 3
        self.retry_delay = 2
    
    def generate_client_id(self) -> str:
        """ç”Ÿæˆå®¢æˆ·ç«¯ID"""
        random_str = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))
        return f"batch_processor_{random_str}"
    
    def is_server_running(self) -> bool:
        """æ£€æŸ¥ComfyUIæœåŠ¡å™¨æ˜¯å¦è¿è¡Œ"""
        for attempt in range(self.max_retries):
            try:
                response = self.session.get(f"{self.server_address}/system_stats", timeout=5)
                if response.status_code == 200:
                    return True
            except requests.exceptions.ConnectionError:
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                return False
            except:
                return False
        return False
    
    def get_queue(self, max_retries: int = 3) -> List[Dict]:
        """è·å–é˜Ÿåˆ—ä¿¡æ¯ï¼ˆå¸¦é‡è¯•ï¼‰"""
        for attempt in range(max_retries):
            try:
                response = self.session.get(f"{self.server_address}/queue", timeout=10)
                if response.status_code == 200:
                    queue_data = response.json()
                    # åˆå¹¶è¿è¡Œä¸­å’Œç­‰å¾…ä¸­çš„é˜Ÿåˆ—
                    queue_running = queue_data.get('queue_running', [])
                    queue_pending = queue_data.get('queue_pending', [])
                    return queue_running + queue_pending
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.debug(f"è·å–é˜Ÿåˆ—å¤±è´¥ï¼Œé‡è¯• {attempt+1}/{max_retries}: {e}")
                    time.sleep(self.retry_delay)
                else:
                    logger.debug(f"è·å–é˜Ÿåˆ—æœ€ç»ˆå¤±è´¥: {e}")
        return []
    
    def is_queue_empty(self) -> bool:
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦ä¸ºç©º"""
        return len(self.get_queue()) == 0
    
    def get_queue_load(self) -> Tuple[int, int]:
        """è·å–é˜Ÿåˆ—è´Ÿè½½ï¼ˆè¿è¡Œä¸­æ•°é‡ï¼Œç­‰å¾…ä¸­æ•°é‡ï¼‰"""
        try:
            queue_data = self.session.get(f"{self.server_address}/queue", timeout=10).json()
            running = len(queue_data.get('queue_running', []))
            pending = len(queue_data.get('queue_pending', []))
            return running, pending
        except:
            return 0, 0
    
    def wait_for_queue_available(self, max_retries: int = 10, delay: int = 5) -> bool:
        """ç­‰å¾…é˜Ÿåˆ—å¯ç”¨ï¼ˆä¸ç¹å¿™ï¼‰"""
        for attempt in range(max_retries):
            running, pending = self.get_queue_load()
            total = running + pending
            
            if total < 2:  # é˜Ÿåˆ—ä¸­ä»»åŠ¡å°‘äº2ä¸ªæ—¶è®¤ä¸ºå¯ç”¨
                logger.debug(f"âœ… é˜Ÿåˆ—å¯ç”¨: è¿è¡Œä¸­={running}, ç­‰å¾…ä¸­={pending}")
                return True
            
            logger.info(f"â³ é˜Ÿåˆ—ç¹å¿™: è¿è¡Œä¸­={running}, ç­‰å¾…ä¸­={pending}, ç­‰å¾…ä¸­... ({attempt+1}/{max_retries})")
            time.sleep(delay)
        
        logger.warning("âš ï¸  é˜Ÿåˆ—æŒç»­ç¹å¿™ï¼Œå°†ç»§ç»­æäº¤")
        return False
    
    def get_history(self, max_retries: int = 3) -> Dict[str, Dict]:
        """è·å–å†å²è®°å½•ï¼ˆå¸¦é‡è¯•ï¼‰"""
        for attempt in range(max_retries):
            try:
                response = self.session.get(f"{self.server_address}/history", timeout=10)
                if response.status_code == 200:
                    history_data = response.json()
                    if isinstance(history_data, dict):
                        return history_data
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.debug(f"è·å–å†å²è®°å½•å¤±è´¥ï¼Œé‡è¯• {attempt+1}/{max_retries}: {e}")
                    time.sleep(self.retry_delay)
                else:
                    logger.debug(f"è·å–å†å²è®°å½•æœ€ç»ˆå¤±è´¥: {e}")
        return {}
    
    def get_prompt_by_id(self, prompt_id: str) -> Optional[Dict]:
        """æ ¹æ®IDè·å–ç‰¹å®šä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯"""
        for attempt in range(3):
            try:
                history = self.get_history()
                if prompt_id in history:
                    return history[prompt_id]
            except Exception as e:
                if attempt < 2:
                    time.sleep(1)
                    continue
        return None
    
    def get_prompt_status(self, prompt_id: str, max_retries: int = 3) -> Optional[Dict]:
        """è·å–ä»»åŠ¡çŠ¶æ€ï¼ˆå¸¦é‡è¯•ï¼‰"""
        for attempt in range(max_retries):
            try:
                # 1. æ£€æŸ¥å†å²è®°å½•ï¼ˆå·²å®Œæˆçš„ä»»åŠ¡ï¼‰
                prompt_info = self.get_prompt_by_id(prompt_id)
                if prompt_info:
                    return {
                        'status': {
                            'completed': True,
                            'error': False
                        },
                        'outputs': prompt_info.get('outputs', {}),
                        'prompt_id': prompt_id
                    }
                
                # 2. æ£€æŸ¥é˜Ÿåˆ—ï¼ˆè¿è¡Œä¸­/ç­‰å¾…ä¸­çš„ä»»åŠ¡ï¼‰
                queue = self.get_queue()
                for item in queue:
                    if isinstance(item, dict) and item.get('prompt_id') == prompt_id:
                        # åˆ¤æ–­æ˜¯åœ¨è¿è¡Œé˜Ÿåˆ—è¿˜æ˜¯ç­‰å¾…é˜Ÿåˆ—
                        running_queue = self.session.get(f"{self.server_address}/queue", timeout=10).json().get('queue_running', [])
                        is_running = any(r_item.get('prompt_id') == prompt_id for r_item in running_queue)
                        
                        return {
                            'status': {
                                'completed': False,
                                'error': False,
                                'running': is_running,
                                'pending': not is_running
                            },
                            'outputs': {},
                            'prompt_id': prompt_id
                        }
                
                # 3. å¦‚æœä¸åœ¨å†å²å’Œé˜Ÿåˆ—ä¸­ï¼Œå¯èƒ½ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²å¤±è´¥
                return {
                    'status': {
                        'completed': False,
                        'error': True,
                        'error_message': 'ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—æˆ–å†å²ä¸­'
                    },
                    'outputs': {},
                    'prompt_id': prompt_id
                }
                
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.debug(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥ï¼Œé‡è¯• {attempt+1}/{max_retries}: {e}")
                    time.sleep(self.retry_delay)
                else:
                    logger.debug(f"è·å–ä»»åŠ¡çŠ¶æ€æœ€ç»ˆå¤±è´¥: {e}")
                    return {
                        'status': {
                            'completed': False,
                            'error': True,
                            'error_message': f'è·å–çŠ¶æ€å¼‚å¸¸: {str(e)}'
                        },
                        'outputs': {},
                        'prompt_id': prompt_id
                    }
    
    def is_prompt_completed(self, prompt_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ"""
        prompt_info = self.get_prompt_status(prompt_id)
        if prompt_info and 'status' in prompt_info:
            return prompt_info['status'].get('completed', False)
        return False
    
    def get_prompt_outputs(self, prompt_id: str) -> Dict:
        """è·å–ä»»åŠ¡çš„è¾“å‡ºä¿¡æ¯"""
        prompt_info = self.get_prompt_status(prompt_id)
        if prompt_info:
            return prompt_info.get('outputs', {})
        return {}
    
    def submit_prompt(self, workflow: Dict) -> Optional[str]:
        """æäº¤ä»»åŠ¡åˆ°ComfyUI"""
        for attempt in range(self.max_retries):
            try:
                # å…ˆç­‰å¾…é˜Ÿåˆ—å¯ç”¨
                self.wait_for_queue_available()
                
                # æ¸…é™¤å†å²è®°å½•
                self.clear_history()
                
                # æäº¤ä»»åŠ¡
                response = self.session.post(
                    f"{self.server_address}/prompt",
                    json={"prompt": workflow, "client_id": self.client_id},
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    prompt_id = data.get('prompt_id')
                    if prompt_id:
                        logger.info(f"âœ… ä»»åŠ¡æäº¤æˆåŠŸï¼ŒID: {prompt_id[:8]}...")
                        return prompt_id
                    else:
                        logger.error(f"âŒ æäº¤ä»»åŠ¡å¤±è´¥: è¿”å›æ•°æ®ä¸­æ— prompt_id")
                else:
                    logger.error(f"âŒ æäº¤ä»»åŠ¡å¤±è´¥: {response.status_code} - {response.text}")
                    
            except requests.exceptions.ConnectionError as e:
                logger.error(f"âŒ è¿æ¥ComfyUIæœåŠ¡å™¨å¤±è´¥: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay * 2)
                    continue
            except requests.exceptions.Timeout as e:
                logger.error(f"âŒ è¿æ¥ComfyUIæœåŠ¡å™¨è¶…æ—¶: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay * 2)
                    continue
            except Exception as e:
                logger.error(f"âŒ æäº¤ä»»åŠ¡å¼‚å¸¸: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
            
            # æ‰€æœ‰å¼‚å¸¸éƒ½èµ°åˆ°è¿™é‡Œ
            if attempt < self.max_retries - 1:
                logger.info(f"ğŸ”„ æäº¤ä»»åŠ¡å¤±è´¥ï¼Œ{self.retry_delay}ç§’åé‡è¯•...")
                time.sleep(self.retry_delay)
        
        return None
    
    def clear_history(self) -> bool:
        """æ¸…é™¤å†å²è®°å½•"""
        try:
            response = self.session.post(f"{self.server_address}/history", json={"clear": True})
            return response.status_code == 200
        except:
            return False
    
    def clear_queue(self) -> bool:
        """æ¸…é™¤é˜Ÿåˆ—"""
        try:
            response = self.session.post(f"{self.server_address}/queue", json={"clear": True})
            return response.status_code == 200
        except:
            return False
    
    def interrupt_queue(self) -> bool:
        """ä¸­æ–­å½“å‰ä»»åŠ¡"""
        try:
            response = self.session.post(f"{self.server_address}/interrupt")
            return response.status_code == 200
        except:
            return False

class BatchProgressTracker:
    """æ‰¹å¤„ç†è¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self, output_dir: str = None):
        self.output_dir = output_dir or self.get_default_output_dir()
        self.batch_progress_file = "batch_progress.json"
        self.batch_time_file = "batch_times.json"
    
    def get_default_output_dir(self) -> str:
        """è·å–é»˜è®¤è¾“å‡ºç›®å½•"""
        comfyui_output = r"F:\AI\ComfyUI_Mie_V7.0\ComfyUI\output"
        if os.path.exists(comfyui_output):
            return comfyui_output
        
        default_output = os.path.join(os.getcwd(), "output")
        os.makedirs(default_output, exist_ok=True)
        return default_output
    
    def get_existing_batches(self, video_path: str, workflow: Dict, total_batches: int) -> Tuple[List[str], Dict[str, Any]]:
        """è·å–å·²å­˜åœ¨çš„æ‰¹æ¬¡æ–‡ä»¶å’Œè¿›åº¦ä¿¡æ¯
        è¿”å›: (æ–‡ä»¶åˆ—è¡¨, è¿›åº¦ä¿¡æ¯)
        """
        base_name = os.path.splitext(os.path.basename(video_path))[0]
        output_files = []
        batch_status = {}
        
        # è·å–æ‰€æœ‰å¯èƒ½çš„è¾“å‡ºæ–‡ä»¶
        for ext in ['.mov', '.mp4', '.avi', '.mkv', '.webm']:
            # æœç´¢æ‰¹æ¬¡æ–‡ä»¶
            batch_files = glob.glob(os.path.join(self.output_dir, f"*{base_name}*_*%*{ext}"))
            output_files.extend(batch_files)
            
            # æœç´¢æ²¡æœ‰ç™¾åˆ†æ¯”çš„æ‰¹æ¬¡æ–‡ä»¶
            simple_files = glob.glob(os.path.join(self.output_dir, f"*{base_name}*{ext}"))
            for f in simple_files:
                if f not in output_files:
                    output_files.append(f)
        
        # åˆ†ææ‰¹æ¬¡çŠ¶æ€
        if output_files:
            logger.info(f"ğŸ“ å·²æ‰¾åˆ° {len(output_files)} ä¸ªæ‰¹æ¬¡æ–‡ä»¶:")
            for i, file_path in enumerate(output_files[:10]):
                file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
                file_size_mb = file_size / (1024 * 1024)
                batch_num = self.extract_batch_number(file_path)
                status = f"(æ‰¹å·: {batch_num})" if batch_num > 0 else ""
                logger.info(f"  {i+1}. {os.path.basename(file_path)} ({file_size_mb:.1f}MB) {status}")
            
            # åˆ†ææ‰¹æ¬¡è¿›åº¦
            completed_batches = len(output_files)
            batch_status = {
                'total_batches': total_batches,
                'completed_batches': completed_batches,
                'remaining_batches': max(0, total_batches - completed_batches),
                'percentage': (completed_batches / total_batches) * 100 if total_batches > 0 else 0,
                'files': output_files
            }
            
            logger.info(f"ğŸ“Š æ‰¹æ¬¡è¿›åº¦: {completed_batches}/{total_batches} ({batch_status['percentage']:.1f}%) å®Œæˆ")
        
        return output_files, batch_status
    
    def extract_batch_number(self, file_path: str) -> int:
        """ä»æ–‡ä»¶åä¸­æå–æ‰¹æ¬¡å·"""
        filename = os.path.basename(file_path)
        import re
        
        # å°è¯•åŒ¹é…æ‰¹æ¬¡å·
        patterns = [
            r'_batch_(\d+)',
            r'_(\d+)%',
            r'_(\d+)of',
            r'_batch(\d+)',
            r'%(\d+)%'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, filename)
            if match:
                try:
                    return int(match.group(1))
                except:
                    continue
        
        return -1
    
    def save_progress(self, video_path: str, progress_data: Dict):
        """ä¿å­˜å¤„ç†è¿›åº¦"""
        try:
            progress = {}
            if os.path.exists(self.batch_progress_file):
                with open(self.batch_progress_file, 'r', encoding='utf-8') as f:
                    progress = json.load(f)
            
            video_key = os.path.basename(video_path)
            progress[video_key] = {
                'video_path': video_path,
                'timestamp': datetime.now().isoformat(),
                'progress': progress_data
            }
            
            with open(self.batch_progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"âœ… è¿›åº¦å·²ä¿å­˜: {video_key}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
    
    def load_progress(self, video_path: str) -> Optional[Dict]:
        """åŠ è½½å¤„ç†è¿›åº¦"""
        try:
            if os.path.exists(self.batch_progress_file):
                with open(self.batch_progress_file, 'r', encoding='utf-8') as f:
                    progress = json.load(f)
                
                video_key = os.path.basename(video_path)
                if video_key in progress:
                    return progress[video_key]
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è¿›åº¦å¤±è´¥: {e}")
        return None
    
    def save_batch_time(self, video_path: str, batch_num: int, process_time: float):
        """ä¿å­˜æ‰¹æ¬¡å¤„ç†æ—¶é—´"""
        try:
            batch_times = {}
            if os.path.exists(self.batch_time_file):
                with open(self.batch_time_file, 'r', encoding='utf-8') as f:
                    batch_times = json.load(f)
            
            video_key = os.path.basename(video_path)
            if video_key not in batch_times:
                batch_times[video_key] = {}
            
            batch_times[video_key][str(batch_num)] = process_time
            
            with open(self.batch_time_file, 'w', encoding='utf-8') as f:
                json.dump(batch_times, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"â±ï¸  ä¿å­˜æ‰¹æ¬¡ {batch_num} å¤„ç†æ—¶é—´: {process_time:.1f}ç§’")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ‰¹æ¬¡æ—¶é—´å¤±è´¥: {e}")
    
    def load_batch_times(self, video_path: str) -> Dict[int, float]:
        """åŠ è½½è§†é¢‘çš„æ‰¹æ¬¡å¤„ç†æ—¶é—´"""
        try:
            if os.path.exists(self.batch_time_file):
                with open(self.batch_time_file, 'r', encoding='utf-8') as f:
                    batch_times = json.load(f)
                
                video_key = os.path.basename(video_path)
                if video_key in batch_times:
                    return {int(k): v for k, v in batch_times[video_key].items()}
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ‰¹æ¬¡æ—¶é—´å¤±è´¥: {e}")
        return {}
    
    def get_average_batch_time(self, video_path: str) -> float:
        """è·å–å¹³å‡æ‰¹æ¬¡å¤„ç†æ—¶é—´"""
        batch_times = self.load_batch_times(video_path)
        if not batch_times:
            return 0.0
        
        times = list(batch_times.values())
        return sum(times) / len(times) if times else 0.0

class BatchTimeoutManager:
    """æ‰¹å¤„ç†è¶…æ—¶ç®¡ç†å™¨ - ç®€åŒ–ç‰ˆ"""
    
    def __init__(self, timeout_per_batch: int = 300):
        """
        åˆå§‹åŒ–è¶…æ—¶ç®¡ç†å™¨
        timeout_per_batch: æ¯ä¸ªæ‰¹æ¬¡çš„æœ€å¤§å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.timeout_per_batch = timeout_per_batch
        self.batch_timers = {}  # è·Ÿè¸ªæ¯ä¸ªæ‰¹æ¬¡çš„å¼€å§‹æ—¶é—´
        self.batch_times = {}   # è®°å½•æ¯ä¸ªæ‰¹æ¬¡çš„å®é™…å¤„ç†æ—¶é—´
        self.timeout_counters = {}  # è¶…æ—¶è®¡æ•°å™¨
    
    def start_batch_timer(self, video_path: str, batch_num: int):
        """å¼€å§‹æ‰¹æ¬¡è®¡æ—¶å™¨"""
        video_key = os.path.basename(video_path)
        
        if video_key not in self.batch_timers:
            self.batch_timers[video_key] = {}
            self.batch_times[video_key] = {}
            self.timeout_counters[video_key] = 0
        
        self.batch_timers[video_key][batch_num] = time.time()
        logger.debug(f"â±ï¸  å¼€å§‹æ‰¹æ¬¡ {batch_num} è®¡æ—¶å™¨: {video_key}")
    
    def end_batch_timer(self, video_path: str, batch_num: int) -> float:
        """ç»“æŸæ‰¹æ¬¡è®¡æ—¶å™¨ï¼Œè¿”å›å¤„ç†æ—¶é—´"""
        video_key = os.path.basename(video_path)
        
        if (video_key in self.batch_timers and 
            batch_num in self.batch_timers[video_key]):
            
            start_time = self.batch_timers[video_key][batch_num]
            end_time = time.time()
            process_time = end_time - start_time
            
            # ä¿å­˜å¤„ç†æ—¶é—´
            self.batch_times[video_key][batch_num] = process_time
            
            # åˆ é™¤è®¡æ—¶å™¨
            del self.batch_timers[video_key][batch_num]
            
            logger.debug(f"â±ï¸  æ‰¹æ¬¡ {batch_num} å¤„ç†å®Œæˆï¼Œè€—æ—¶: {process_time:.1f}ç§’")
            return process_time
        
        return 0.0
    
    def check_batch_timeout(self, video_path: str, batch_num: int) -> Tuple[bool, float]:
        """æ£€æŸ¥å½“å‰æ‰¹æ¬¡æ˜¯å¦è¶…æ—¶
        è¿”å›: (æ˜¯å¦è¶…æ—¶, å·²è¿è¡Œæ—¶é—´)
        """
        video_key = os.path.basename(video_path)
        
        if (video_key not in self.batch_timers or 
            batch_num not in self.batch_timers[video_key]):
            return False, 0.0
        
        start_time = self.batch_timers[video_key][batch_num]
        elapsed = time.time() - start_time
        
        # å¦‚æœæ‰¹æ¬¡å¤„ç†æ—¶é—´è¶…è¿‡é˜ˆå€¼
        if elapsed > self.timeout_per_batch:
            self.timeout_counters[video_key] = self.timeout_counters.get(video_key, 0) + 1
            logger.warning(f"âš ï¸  æ‰¹æ¬¡ {batch_num} å¤„ç†è¶…æ—¶: å·²è¿è¡Œ {elapsed:.0f} ç§’ï¼Œè¶…è¿‡ {self.timeout_per_batch} ç§’")
            return True, elapsed
        
        return False, elapsed
    
    def get_expected_completion_time(self, video_path: str, current_batch: int, total_batches: int) -> float:
        """æ ¹æ®å†å²æ•°æ®é¢„æµ‹å®Œæˆæ—¶é—´"""
        video_key = os.path.basename(video_path)
        
        if video_key not in self.batch_times or not self.batch_times[video_key]:
            return 0.0
        
        # è®¡ç®—å·²å¤„ç†æ‰¹æ¬¡çš„å¹³å‡æ—¶é—´
        completed_times = list(self.batch_times[video_key].values())
        if not completed_times:
            return 0.0
        
        avg_time = sum(completed_times) / len(completed_times)
        
        # é¢„æµ‹å‰©ä½™æ—¶é—´
        remaining_batches = total_batches - current_batch
        return avg_time * remaining_batches
    
    def get_average_batch_time(self, video_path: str) -> float:
        """è·å–å¹³å‡æ‰¹æ¬¡å¤„ç†æ—¶é—´"""
        video_key = os.path.basename(video_path)
        
        if video_key in self.batch_times and self.batch_times[video_key]:
            times = list(self.batch_times[video_key].values())
            return sum(times) / len(times)
        
        return 0.0
    
    def reset_video_timer(self, video_path: str):
        """é‡ç½®è§†é¢‘è®¡æ—¶å™¨"""
        video_key = os.path.basename(video_path)
        if video_key in self.timeout_counters:
            self.timeout_counters[video_key] = 0
            logger.debug(f"ğŸ”„ é‡ç½®è§†é¢‘è®¡æ—¶å™¨: {video_key}")

class ComfyUI_FlashVSR_BatchProcessor:
    def __init__(self, 
                 comfyui_url: str = "http://127.0.0.1:8188", 
                 timeout_per_batch: int = 300,  # æ¯ä¸ªæ‰¹æ¬¡è¶…æ—¶æ—¶é—´
                 max_retries: int = 3,
                 restart_delay: int = 5,
                 startup_timeout: int = 300,
                 min_submit_interval: int = 2):  # æœ€å°æäº¤é—´éš”
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨ - æ™ºèƒ½ç®€åŒ–ç‰ˆ
        """
        # APIå®¢æˆ·ç«¯
        self.client = ComfyUI_Client(comfyui_url)
        
        # è¿›åº¦è·Ÿè¸ªå™¨
        self.progress_tracker = BatchProgressTracker()
        
        # è¶…æ—¶ç®¡ç†å™¨
        self.timeout_manager = BatchTimeoutManager(
            timeout_per_batch=timeout_per_batch
        )
        
        # é…ç½®å‚æ•°
        self.comfyui_url = comfyui_url
        self.timeout_per_batch = timeout_per_batch
        self.max_retries = max_retries
        self.restart_delay = restart_delay
        self.startup_timeout = startup_timeout
        self.min_submit_interval = min_submit_interval
        
        # çŠ¶æ€è·Ÿè¸ª
        self.processed_files = {}
        self.failed_files = {}
        self.restart_history = []
        self.current_retry_count = 0
        self.last_submit_time = 0
        
        # æ³¨å†Œæ¸…ç†å‡½æ•°
        atexit.register(self.cleanup)
        
        logger.info("=" * 60)
        logger.info("ComfyUI FlashVSR æ‰¹é‡å¤„ç†å™¨ v22 - æ™ºèƒ½ç®€åŒ–ç‰ˆ")
        logger.info(f"ComfyUIåœ°å€: {comfyui_url}")
        logger.info(f"æ‰¹æ¬¡è¶…æ—¶: {timeout_per_batch}ç§’")
        logger.info(f"æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}æ¬¡")
        logger.info(f"æäº¤é—´éš”: {min_submit_interval}ç§’")
        logger.info(f"è¾“å‡ºç›®å½•: {self.progress_tracker.output_dir}")
        logger.info("=" * 60)
    
    def ensure_comfyui_running(self) -> bool:
        """ç¡®ä¿ComfyUIåœ¨è¿è¡Œ"""
        if self.client.is_server_running():
            logger.info("âœ… ComfyUIæœåŠ¡å™¨æ­£å¸¸è¿è¡Œ")
            return True
        
        logger.error("âŒ ComfyUIæœåŠ¡å™¨æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨ComfyUI")
        return False
    
    def clear_cache(self) -> Dict[str, Any]:
        """æ¸…ç†ç¼“å­˜"""
        cleanup_results = {
            "system_memory_freed_mb": 0,
            "gpu_memory_freed_mb": 0,
            "success": False
        }
        
        logger.info("ğŸ§¹ æ¸…ç†ç¼“å­˜...")
        
        try:
            # æ¸…ç†GPUæ˜¾å­˜
            if TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                logger.info("âœ… GPUæ˜¾å­˜å·²æ¸…ç†")
                cleanup_results["gpu_memory_freed_mb"] = 1
                cleanup_results["success"] = True
            
            # æ¸…ç†Pythonå†…å­˜
            collected = gc.collect()
            logger.info(f"âœ… Pythonåƒåœ¾å›æ”¶: {collected} ä¸ªå¯¹è±¡")
            cleanup_results["success"] = True
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        
        return cleanup_results
    
    def load_workflow_template(self, template_path: str) -> Dict:
        """åŠ è½½å·¥ä½œæµæ¨¡æ¿"""
        with open(template_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def update_workflow_parameters(
        self, 
        workflow: Dict, 
        video_path: str, 
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 125,
        gpu_device: str = "auto"
    ) -> Dict:
        """æ›´æ–°å·¥ä½œæµå‚æ•°"""
        import copy
        modified_workflow = copy.deepcopy(workflow)
        
        # è®¾ç½®è¾“å…¥è§†é¢‘è·¯å¾„
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_LoadVideo":
                node_data["inputs"]["video"] = video_path
                logger.debug(f"è®¾ç½®è¾“å…¥è§†é¢‘: {os.path.basename(video_path)}")
        
        # è®¾ç½®FlashVSRå‚æ•°
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "FlashVSRNodeAdv":
                inputs = node_data.get("inputs", {})
                if "{{scale}}" in str(inputs.get("scale", "")):
                    inputs["scale"] = scale
                if "{{t_z}}" in str(inputs.get("tile_size", "")):
                    inputs["tile_size"] = tile_size
                if "{{t_o}}" in str(inputs.get("tile_overlap", "")):
                    inputs["tile_overlap"] = tile_overlap
        
        # è®¾ç½®GPUè®¾å¤‡
        for node_id, node_data in modified_workflow.items():
            if node_id == "5" and node_data.get("class_type") == "FlashVSRInitPipe":
                inputs = node_data.get("inputs", {})
                if isinstance(inputs.get("device"), str):
                    if gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    inputs["device"] = device_value
                    logger.debug(f"è®¾ç½®GPUè®¾å¤‡: {device_value}")
        
        # è®¾ç½®æ€»å¸§æ•°
        if total_frames is None or total_frames <= 0:
            video_info = get_video_info(video_path)
            total_frames = video_info.get('total_frames', 0)
            if total_frames <= 0:
                total_frames = 10000
                logger.warning(f"âš ï¸  æ— æ³•è·å–è§†é¢‘æ€»å¸§æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼: {total_frames}")
        
        for node_id, node_data in modified_workflow.items():
            if node_id == "50" and node_data.get("class_type") == "PrimitiveInt":
                node_data["inputs"]["value"] = total_frames
                logger.debug(f"è®¾ç½®æ€»å¸§æ•°: {total_frames}")
        
        # è®¾ç½®æ¯æ‰¹å¸§æ•°
        for node_id, node_data in modified_workflow.items():
            if node_id == "8" and node_data.get("class_type") == "PrimitiveInt":
                node_data["inputs"]["value"] = frames_per_batch
                logger.debug(f"è®¾ç½®æ¯æ‰¹å¸§æ•°: {frames_per_batch}")
        
        # è®¾ç½®è¾“å‡ºå‰ç¼€
        if output_prefix is None:
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            output_prefix = f"flashvsr_{base_name}"
        
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_VideoCombine":
                node_data["inputs"]["filename_prefix"] = output_prefix
                logger.debug(f"è®¾ç½®è¾“å‡ºå‰ç¼€: {output_prefix}")
        
        return modified_workflow
    
    def wait_for_task_completion_smart(
        self, 
        prompt_id: str, 
        video_path: str, 
        workflow: Dict,
        total_frames: int,
        frames_per_batch: int,
        total_batches: int
    ) -> Tuple[bool, str, List[str], Dict[str, Any]]:
        """
        æ™ºèƒ½ç­‰å¾…ä»»åŠ¡å®Œæˆ
        è¿”å›: (æ˜¯å¦æˆåŠŸ, çŠ¶æ€ä¿¡æ¯, è¾“å‡ºæ–‡ä»¶åˆ—è¡¨, è¿›åº¦ä¿¡æ¯)
        """
        logger.info(f"â³ ç­‰å¾…ä»»åŠ¡å®Œæˆ (æ‰¹æ¬¡è¶…æ—¶: {self.timeout_per_batch}ç§’)...")
        
        video_name = os.path.basename(video_path)
        start_time = time.time()
        last_status_check = 0
        status_check_interval = 5
        last_output_check = 0
        output_check_interval = 10
        queue_empty_count = 0
        max_queue_empty = 3
        output_files_found = []
        last_output_count = 0
        no_progress_count = 0
        max_no_progress = 3
        last_queue_length = 0
        consecutive_same_queue = 0
        max_consecutive_same_queue = 6  # 30ç§’å†…é˜Ÿåˆ—æ— å˜åŒ–
        
        # è·å–å†å²æ‰¹æ¬¡å¤„ç†æ—¶é—´
        historical_batch_time = self.progress_tracker.get_average_batch_time(video_path)
        if historical_batch_time > 0:
            logger.info(f"â±ï¸  å†å²å¹³å‡æ‰¹æ¬¡å¤„ç†æ—¶é—´: {historical_batch_time:.1f}ç§’")
        
        # è®¡ç®—é¢„æœŸæ‰¹æ¬¡æ•°
        expected_batches = total_batches
        
        while True:
            current_time = time.time()
            elapsed = current_time - start_time
            
            # 1. æ£€æŸ¥å½“å‰æ‰¹æ¬¡è¶…æ—¶
            current_batch = last_output_count + 1
            is_timeout, batch_elapsed = self.timeout_manager.check_batch_timeout(video_path, current_batch)
            
            if is_timeout:
                logger.warning(f"âš ï¸  æ‰¹æ¬¡ {current_batch} å¤„ç†è¶…æ—¶: {video_name} (å·²è¿è¡Œ {batch_elapsed:.0f}ç§’)")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºè¿›åº¦
                output_files, progress_info = self.progress_tracker.get_existing_batches(
                    video_path, workflow, expected_batches
                )
                
                completed = len(output_files)
                if completed > last_output_count:
                    # æœ‰æ–°çš„æ‰¹æ¬¡å®Œæˆï¼Œé‡ç½®è®¡æ•°å™¨
                    last_output_count = completed
                    no_progress_count = 0
                    logger.info(f"ğŸ“ˆ æ£€æµ‹åˆ°æ–°æ‰¹æ¬¡å®Œæˆ: {completed}/{expected_batches}")
                    
                    # è®°å½•æ‰¹æ¬¡å¤„ç†æ—¶é—´
                    if current_batch > 1:
                        batch_time = batch_elapsed
                        self.timeout_manager.end_batch_timer(video_path, current_batch - 1)
                        self.progress_tracker.save_batch_time(video_path, current_batch - 1, batch_time)
                        logger.info(f"â±ï¸  æ‰¹æ¬¡ {current_batch-1} å¤„ç†æ—¶é—´: {batch_time:.1f}ç§’")
                else:
                    no_progress_count += 1
                    logger.warning(f"âš ï¸  æ‰¹æ¬¡ {current_batch} æ— è¿›å±•: {no_progress_count}/{max_no_progress}")
                    
                    if no_progress_count >= max_no_progress:
                        logger.warning(f"âš ï¸  è¿ç»­ {max_no_progress} ä¸ªæ‰¹æ¬¡æ— è¿›å±•ï¼Œéœ€è¦é‡å¯")
                        
                        if completed > 0:
                            return True, f"æ‰¹æ¬¡æ— è¿›å±•ä½†æœ‰éƒ¨åˆ†å®Œæˆ({completed}/{expected_batches})", output_files, progress_info
                        else:
                            return False, f"è¿ç»­æ‰¹æ¬¡æ— è¿›å±•", [], {}
            
            # 2. å®šæœŸæ£€æŸ¥è¾“å‡ºæ–‡ä»¶
            if current_time - last_output_check >= output_check_interval:
                output_files, progress_info = self.progress_tracker.get_existing_batches(
                    video_path, workflow, expected_batches
                )
                last_output_check = current_time
                
                if output_files:
                    completed = len(output_files)
                    
                    # æ›´æ–°è¿›åº¦
                    if completed > last_output_count:
                        logger.info(f"ğŸ“ˆ è¿›åº¦æ›´æ–°: {completed}/{expected_batches} ({completed/expected_batches*100:.1f}%)")
                        
                        # è®°å½•å®Œæˆçš„æ‰¹æ¬¡å¤„ç†æ—¶é—´
                        for batch_num in range(last_output_count + 1, completed + 1):
                            if batch_num > 1:  # ç¬¬ä¸€ä¸ªæ‰¹æ¬¡ä»ä»»åŠ¡å¼€å§‹è®¡ç®—
                                batch_time = self.timeout_manager.end_batch_timer(video_path, batch_num - 1)
                                if batch_time > 0:
                                    self.progress_tracker.save_batch_time(video_path, batch_num - 1, batch_time)
                                    logger.debug(f"â±ï¸  è®°å½•æ‰¹æ¬¡ {batch_num-1} å¤„ç†æ—¶é—´: {batch_time:.1f}ç§’")
                        
                        # å¼€å§‹ä¸‹ä¸€ä¸ªæ‰¹æ¬¡çš„è®¡æ—¶
                        if completed < expected_batches:
                            self.timeout_manager.start_batch_timer(video_path, completed + 1)
                        
                        last_output_count = completed
                        no_progress_count = 0
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆæ‰€æœ‰æ‰¹æ¬¡
                    if completed >= expected_batches:
                        logger.info(f"âœ… æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ: {completed}/{expected_batches}")
                        return True, f"æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ", output_files, progress_info
            
            # 3. å®šæœŸæ£€æŸ¥ä»»åŠ¡çŠ¶æ€
            if current_time - last_status_check >= status_check_interval:
                try:
                    prompt_info = self.client.get_prompt_status(prompt_id)
                    last_status_check = current_time
                    
                    if prompt_info:
                        status = prompt_info.get('status', {})
                        
                        if status.get('completed', False):
                            logger.info(f"âœ… ä»»åŠ¡ {prompt_id[:8]}... çŠ¶æ€: å·²å®Œæˆ")
                            
                            # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
                            time.sleep(2)
                            output_files, progress_info = self.progress_tracker.get_existing_batches(
                                video_path, workflow, expected_batches
                            )
                            
                            if output_files:
                                completed = len(output_files)
                                logger.info(f"âœ… ä»»åŠ¡å®Œæˆï¼Œæ‰¾åˆ° {completed}/{expected_batches} ä¸ªè¾“å‡ºæ–‡ä»¶")
                                return True, f"ä»»åŠ¡å®Œæˆ", output_files, progress_info
                            else:
                                logger.warning("âš ï¸  ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆä½†æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶")
                                
                                # ç»™ç‚¹æ—¶é—´è®©æ–‡ä»¶å†™å…¥
                                time.sleep(5)
                                output_files, progress_info = self.progress_tracker.get_existing_batches(
                                    video_path, workflow, expected_batches
                                )
                                
                                if output_files:
                                    completed = len(output_files)
                                    logger.info(f"âœ… ç­‰å¾…åæ‰¾åˆ° {completed}/{expected_batches} ä¸ªè¾“å‡ºæ–‡ä»¶")
                                    return True, f"ä»»åŠ¡å®Œæˆ(å»¶è¿Ÿå‘ç°)", output_files, progress_info
                                
                                return False, "ä»»åŠ¡å®Œæˆä½†æ— è¾“å‡ºæ–‡ä»¶", [], {}
                        
                        if status.get('error', False):
                            error_msg = status.get('error_message', 'æœªçŸ¥é”™è¯¯')
                            logger.error(f"âŒ ä»»åŠ¡å‡ºé”™: {error_msg}")
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†è¾“å‡º
                            output_files, progress_info = self.progress_tracker.get_existing_batches(
                                video_path, workflow, expected_batches
                            )
                            
                            if output_files:
                                completed = len(output_files)
                                logger.info(f"âš ï¸  ä»»åŠ¡å‡ºé”™ä½†æœ‰éƒ¨åˆ†è¾“å‡º: {completed}/{expected_batches}")
                                return True, f"ä»»åŠ¡å‡ºé”™ä½†æœ‰è¾“å‡º({completed}/{expected_batches})", output_files, progress_info
                            
                            return False, f"ä»»åŠ¡å‡ºé”™: {error_msg}", [], {}
                        
                        # æ˜¾ç¤ºè¯¦ç»†çŠ¶æ€
                        if status.get('running', False):
                            logger.debug(f"â³ ä»»åŠ¡çŠ¶æ€: è¿è¡Œä¸­")
                        elif status.get('pending', False):
                            logger.debug(f"â³ ä»»åŠ¡çŠ¶æ€: ç­‰å¾…ä¸­")
                
                except Exception as e:
                    logger.debug(f"âš ï¸  æ£€æŸ¥ä»»åŠ¡çŠ¶æ€æ—¶å‡ºé”™: {e}")
            
            # 4. æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
            try:
                running, pending = self.client.get_queue_load()
                queue_length = running + pending
                
                if queue_length == 0:
                    queue_empty_count += 1
                    
                    if queue_empty_count >= max_queue_empty:
                        logger.info(f"ğŸ” é˜Ÿåˆ—è¿ç»­ {max_queue_empty} æ¬¡ä¸ºç©º")
                        
                        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
                        output_files, progress_info = self.progress_tracker.get_existing_batches(
                            video_path, workflow, expected_batches
                        )
                        
                        if output_files:
                            completed = len(output_files)
                            logger.info(f"ğŸ“Š é˜Ÿåˆ—ä¸ºç©ºï¼Œå·²æœ‰ {completed}/{expected_batches} ä¸ªæ‰¹æ¬¡å®Œæˆ")
                            
                            if completed >= expected_batches * 0.9:  # 90%å®Œæˆ
                                logger.info(f"âœ… é˜Ÿåˆ—ä¸ºç©ºä¸”å¤§éƒ¨åˆ†æ‰¹æ¬¡å·²å®Œæˆ({completed}/{expected_batches})")
                                return True, f"é˜Ÿåˆ—ä¸ºç©ºä½†å®Œæˆ{completed}/{expected_batches}", output_files, progress_info
                        
                        logger.warning(f"âš ï¸  é˜Ÿåˆ—æŒç»­ä¸ºç©ºä½†æ— è¾“å‡ºæ–‡ä»¶")
                        queue_empty_count = 0
                else:
                    queue_empty_count = 0
                    
                    # æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦åœæ»
                    if queue_length == last_queue_length:
                        consecutive_same_queue += 1
                        if consecutive_same_queue >= max_consecutive_same_queue:
                            logger.warning(f"âš ï¸  é˜Ÿåˆ—çŠ¶æ€è¿ç»­ {max_consecutive_same_queue} æ¬¡æ— å˜åŒ–ï¼Œå¯èƒ½åœæ»")
                            consecutive_same_queue = 0
                    else:
                        consecutive_same_queue = 0
                        last_queue_length = queue_length
                    
                    # æ¯30ç§’æ˜¾ç¤ºä¸€æ¬¡é˜Ÿåˆ—çŠ¶æ€
                    if elapsed % 30 == 0:
                        avg_batch_time = self.timeout_manager.get_average_batch_time(video_path)
                        if avg_batch_time > 0 and last_output_count > 0:
                            remaining_batches = expected_batches - last_output_count
                            estimated_time = avg_batch_time * remaining_batches
                            hours = int(estimated_time // 3600)
                            minutes = int((estimated_time % 3600) // 60)
                            logger.info(f"â³ å·²å¤„ç† {int(elapsed)} ç§’ï¼Œé˜Ÿåˆ—: è¿è¡Œä¸­={running}, ç­‰å¾…ä¸­={pending}")
                            logger.info(f"  è¿›åº¦: {last_output_count}/{expected_batches}ï¼Œé¢„è®¡å‰©ä½™: {hours}æ—¶{minutes}åˆ†")
                        else:
                            logger.info(f"â³ å·²å¤„ç† {int(elapsed)} ç§’ï¼Œé˜Ÿåˆ—: è¿è¡Œä¸­={running}, ç­‰å¾…ä¸­={pending}")
            
            except Exception as e:
                logger.debug(f"âš ï¸  æ£€æŸ¥é˜Ÿåˆ—æ—¶å‡ºé”™: {e}")
            
            time.sleep(2)
    
    def restart_comfyui(self, reason: str = "æœªçŸ¥åŸå› ") -> bool:
        """é‡å¯ComfyUI"""
        logger.info(f"ğŸ”„ å¼€å§‹é‡å¯ComfyUI (å°è¯• {self.current_retry_count + 1}/{self.max_retries})")
        logger.info(f"   é‡å¯åŸå› : {reason}")
        
        # è®°å½•é‡å¯
        self.record_restart(
            video_path="system",
            reason=reason,
            attempt=self.current_retry_count + 1
        )
        
        # 1. ç»“æŸç°æœ‰è¿›ç¨‹
        logger.info("1. ç»“æŸç°æœ‰ComfyUIè¿›ç¨‹...")
        try:
            if PSUTIL_AVAILABLE:
                killed_processes = self.kill_comfyui_processes()
                logger.info(f"   å·²ç»“æŸ {len(killed_processes)} ä¸ªè¿›ç¨‹")
            else:
                logger.warning("âš ï¸  psutilä¸å¯ç”¨ï¼Œæ— æ³•ç»“æŸè¿›ç¨‹")
        except Exception as e:
            logger.error(f"âŒ ç»“æŸè¿›ç¨‹å¤±è´¥: {e}")
        
        # 2. ç­‰å¾…è¿›ç¨‹ç»“æŸ
        logger.info("2. ç­‰å¾…è¿›ç¨‹ç»“æŸ...")
        time.sleep(3)
        
        # 3. å¯åŠ¨ComfyUI
        logger.info("3. å¯åŠ¨ComfyUI...")
        bat_path = r"F:\AI\ComfyUI_Mie_V7.0\run_nvidia_gpu_fast_fp16_accumulation_hf_mirror.bat"
        
        if not os.path.exists(bat_path):
            logger.error(f"âŒ å¯åŠ¨è„šæœ¬ä¸å­˜åœ¨: {bat_path}")
            return False
        
        try:
            # åœ¨æ–°çš„å‘½ä»¤çª—å£ä¸­å¯åŠ¨
            subprocess.Popen(
                f'start cmd /k "{bat_path}"',
                shell=True,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            logger.info(f"ğŸš€ å¯åŠ¨ComfyUI: {bat_path}")
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨ComfyUIå¤±è´¥: {e}")
            return False
        
        # 4. ç­‰å¾…ComfyUIå¯åŠ¨
        logger.info("4. ç­‰å¾…ComfyUIå¯åŠ¨...")
        wait_time = 0
        while wait_time < self.startup_timeout:
            if self.client.is_server_running():
                logger.info(f"âœ… ComfyUIå¯åŠ¨æˆåŠŸï¼Œç­‰å¾…äº† {wait_time} ç§’")
                return True
            
            time.sleep(5)
            wait_time += 5
            logger.debug(f"   ç­‰å¾…ComfyUIå¯åŠ¨... {wait_time}ç§’")
        
        logger.error(f"âŒ ComfyUIå¯åŠ¨è¶…æ—¶ ({self.startup_timeout}ç§’)")
        return False
    
    def kill_comfyui_processes(self) -> List[int]:
        """ç»“æŸComfyUIç›¸å…³è¿›ç¨‹"""
        killed_pids = []
        
        if not PSUTIL_AVAILABLE:
            return killed_pids
        
        try:
            comfyui_path = r"F:\AI\ComfyUI_Mie_V7.0"
            
            for proc in psutil.process_iter(['pid', 'name', 'exe', 'cmdline']):
                try:
                    # æ£€æŸ¥Pythonè¿›ç¨‹
                    if proc.info['name'] and 'python' in proc.info['name'].lower():
                        # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°æ˜¯å¦åŒ…å«ComfyUIè·¯å¾„
                        cmdline = proc.info.get('cmdline', [])
                        if cmdline and any(comfyui_path in str(arg) for arg in cmdline):
                            logger.info(f"   ğŸ”ª ç»“æŸè¿›ç¨‹: {proc.info['pid']} - {proc.info['name']}")
                            proc.terminate()
                            killed_pids.append(proc.info['pid'])
                    
                    # æ£€æŸ¥cmdè¿›ç¨‹
                    elif proc.info['name'] and 'cmd.exe' in proc.info['name'].lower():
                        # æ£€æŸ¥å‘½ä»¤è¡Œæ˜¯å¦åŒ…å«ComfyUIç›¸å…³
                        cmdline = proc.info.get('cmdline', [])
                        if cmdline and any(comfyui_path in str(arg) for arg in cmdline):
                            logger.info(f"   ğŸ”ª ç»“æŸè¿›ç¨‹: {proc.info['pid']} - {proc.info['name']}")
                            proc.terminate()
                            killed_pids.append(proc.info['pid'])
                
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    continue
            
            # ç­‰å¾…è¿›ç¨‹ç»“æŸ
            time.sleep(2)
            
            # å¼ºåˆ¶ç»“æŸæœªé€€å‡ºçš„è¿›ç¨‹
            for pid in killed_pids[:]:
                try:
                    proc = psutil.Process(pid)
                    if proc.is_running():
                        logger.info(f"   ğŸ”« å¼ºåˆ¶ç»“æŸè¿›ç¨‹ {pid}")
                        proc.kill()
                except:
                    pass
            
            # æ¸…ç†GPUæ˜¾å­˜
            if TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                logger.info("âœ… GPUæ˜¾å­˜å·²æ¸…ç†")
            
        except Exception as e:
            logger.error(f"âŒ ç»“æŸè¿›ç¨‹æ—¶å‡ºé”™: {e}")
        
        return killed_pids
    
    def wait_for_submit_interval(self):
        """ç­‰å¾…æäº¤é—´éš”"""
        current_time = time.time()
        time_since_last = current_time - self.last_submit_time
        
        if time_since_last < self.min_submit_interval:
            wait_time = self.min_submit_interval - time_since_last
            logger.debug(f"â³ ç­‰å¾…æäº¤é—´éš”: {wait_time:.1f}ç§’")
            time.sleep(wait_time)
        
        self.last_submit_time = time.time()
    
    def process_single_video(
        self,
        workflow_template: Dict,
        video_path: str,
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        frames_per_batch: int = 125,
        gpu_device: str = "auto"
    ) -> Tuple[bool, str, int, List[str]]:
        """å¤„ç†å•ä¸ªè§†é¢‘ - ç®€åŒ–ç‰ˆ"""
        video_name = os.path.basename(video_path)
        retry_count = 0
        success = False
        status_msg = "åˆå§‹çŠ¶æ€"
        output_files = []
        
        # ç¡®ä¿ComfyUIåœ¨è¿è¡Œ
        if not self.ensure_comfyui_running():
            return False, "ComfyUIæœªè¿è¡Œ", 0, []
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = get_video_info(video_path)
        total_frames = video_info.get('total_frames', 0)
        
        if total_frames <= 0:
            logger.warning(f"âš ï¸  æ— æ³•è·å–è§†é¢‘ '{video_name}' çš„æ€»å¸§æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            total_frames = 10000
        
        # è®¡ç®—é¢„æœŸæ‰¹æ¬¡æ•°
        if frames_per_batch <= 0:
            frames_per_batch = 125
        total_batches = (total_frames + frames_per_batch - 1) // frames_per_batch
        logger.info(f"ğŸ“Š è§†é¢‘ '{video_name}' éœ€è¦ {total_batches} ä¸ªæ‰¹æ¬¡ (æ€»å¸§æ•°: {total_frames}, æ¯æ‰¹: {frames_per_batch})")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¾“å‡ºæ–‡ä»¶
        logger.info("ğŸ” æ£€æŸ¥æ˜¯å¦å·²æœ‰è¾“å‡ºæ–‡ä»¶...")
        temp_workflow = self.update_workflow_parameters(
            workflow_template, video_path, output_prefix
        )
        
        # è·å–ç°æœ‰è¾“å‡ºæ–‡ä»¶
        existing_files, progress_info = self.progress_tracker.get_existing_batches(
            video_path, temp_workflow, total_batches
        )
        
        completed_batches = len(existing_files)
        if completed_batches >= total_batches:
            logger.info(f"âœ… è§†é¢‘ '{video_name}' å·²æœ‰å®Œæ•´è¾“å‡ºæ–‡ä»¶ ({completed_batches}/{total_batches})ï¼Œè·³è¿‡å¤„ç†")
            return True, f"å·²æœ‰å®Œæ•´è¾“å‡ºæ–‡ä»¶", 0, existing_files
        elif completed_batches > 0:
            logger.info(f"ğŸ“Š è§†é¢‘ '{video_name}' å·²æœ‰ {completed_batches}/{total_batches} ä¸ªæ‰¹æ¬¡å®Œæˆ")
            
            # å¦‚æœå¤§éƒ¨åˆ†å·²å®Œæˆï¼Œä»ç°æœ‰æ–‡ä»¶å¼€å§‹
            if completed_batches >= total_batches * 0.8:  # 80%å®Œæˆ
                logger.info(f"âœ… è§†é¢‘ '{video_name}' å·²æœ‰ {completed_batches}/{total_batches} å®Œæˆï¼Œè·³è¿‡å¤„ç†")
                return True, f"å¤§éƒ¨åˆ†å·²å¤„ç†({completed_batches}/{total_batches})", 0, existing_files
        
        # è·å–å†å²æ‰¹æ¬¡å¤„ç†æ—¶é—´
        historical_times = self.progress_tracker.load_batch_times(video_path)
        if historical_times:
            avg_time = sum(historical_times.values()) / len(historical_times)
            logger.info(f"â±ï¸  å†å²æ‰¹æ¬¡å¤„ç†æ—¶é—´: å¹³å‡ {avg_time:.1f}ç§’/æ‰¹æ¬¡")
        
        while retry_count < self.max_retries and not success:
            retry_count += 1
            logger.info(f"ğŸ”„ å°è¯• {retry_count}/{self.max_retries}")
            
            try:
                # ç­‰å¾…æäº¤é—´éš”
                self.wait_for_submit_interval()
                
                # æ¸…é™¤å†å²è®°å½•
                logger.debug("æ¸…é™¤ComfyUIå†å²è®°å½•...")
                self.client.clear_history()
                
                # æ›´æ–°å·¥ä½œæµå‚æ•°
                workflow = self.update_workflow_parameters(
                    workflow_template,
                    video_path,
                    output_prefix,
                    scale=scale,
                    tile_size=tile_size,
                    tile_overlap=tile_overlap,
                    total_frames=total_frames,
                    frames_per_batch=frames_per_batch,
                    gpu_device=gpu_device
                )
                
                # æäº¤ä»»åŠ¡
                logger.info(f"ğŸ“¤ æäº¤ä»»åŠ¡: {video_name}")
                prompt_id = self.client.submit_prompt(workflow)
                
                if not prompt_id:
                    status_msg = "æäº¤ä»»åŠ¡å¤±è´¥"
                    logger.error(f"âŒ {status_msg}")
                    time.sleep(self.restart_delay)
                    continue
                
                logger.info(f"   ä»»åŠ¡ID: {prompt_id}")
                
                # å¼€å§‹ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„è®¡æ—¶
                self.timeout_manager.start_batch_timer(video_path, completed_batches + 1)
                
                # æ™ºèƒ½ç­‰å¾…ä»»åŠ¡å®Œæˆ
                task_success, task_status, output_files, progress_info = self.wait_for_task_completion_smart(
                    prompt_id=prompt_id,
                    video_path=video_path,
                    workflow=workflow,
                    total_frames=total_frames,
                    frames_per_batch=frames_per_batch,
                    total_batches=total_batches
                )
                
                if task_success:
                    success = True
                    status_msg = task_status
                    
                    # è·å–æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
                    final_files, _ = self.progress_tracker.get_existing_batches(
                        video_path, workflow, total_batches
                    )
                    
                    if final_files:
                        completed = len(final_files)
                        logger.info(f"âœ… è§†é¢‘å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {completed}/{total_batches} ä¸ªè¾“å‡ºæ–‡ä»¶")
                        
                        for i, file_path in enumerate(final_files[:3]):
                            if os.path.exists(file_path):
                                file_size = os.path.getsize(file_path)
                                file_size_mb = file_size / (1024 * 1024)
                                logger.info(f"  {i+1}. {os.path.basename(file_path)} ({file_size_mb:.1f}MB)")
                            else:
                                logger.warning(f"  {i+1}. {os.path.basename(file_path)} (æ–‡ä»¶ä¸å­˜åœ¨!)")
                        
                        if len(final_files) > 3:
                            logger.info(f"  ... è¿˜æœ‰ {len(final_files)-3} ä¸ªæ–‡ä»¶")
                        
                        output_files = final_files
                    else:
                        logger.warning("âš ï¸  ä»»åŠ¡æˆåŠŸä½†æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶")
                        success = False
                        status_msg = "ä»»åŠ¡æˆåŠŸä½†æ— è¾“å‡ºæ–‡ä»¶"
                    
                    break
                
                else:
                    status_msg = task_status
                    logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {status_msg}")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†è¾“å‡ºæ–‡ä»¶
                    partial_files, _ = self.progress_tracker.get_existing_batches(
                        video_path, workflow, total_batches
                    )
                    
                    if partial_files:
                        completed = len(partial_files)
                        logger.info(f"ğŸ“Š æ‰¾åˆ° {completed}/{total_batches} ä¸ªéƒ¨åˆ†è¾“å‡ºæ–‡ä»¶")
                        
                        # å¦‚æœæœ‰éƒ¨åˆ†è¾“å‡ºï¼Œè®°å½•è¿›åº¦
                        if completed > 0:
                            self.progress_tracker.save_progress(video_path, {
                                'completed_batches': completed,
                                'total_batches': total_batches,
                                'output_files': [os.path.basename(f) for f in partial_files],
                                'status': 'partial_complete',
                                'last_update': datetime.now().isoformat()
                            })
                            
                            # è®°å½•æ‰¹æ¬¡å¤„ç†æ—¶é—´
                            for batch_num in range(1, completed + 1):
                                if batch_num in self.timeout_manager.batch_timers.get(video_name, {}):
                                    batch_time = self.timeout_manager.end_batch_timer(video_path, batch_num)
                                    if batch_time > 0:
                                        self.progress_tracker.save_batch_time(video_path, batch_num, batch_time)
                    
                    # è®°å½•é‡å¯
                    self.record_restart(
                        video_path=video_path,
                        reason=status_msg,
                        attempt=retry_count
                    )
                    
                    if retry_count < self.max_retries:
                        logger.info(f"ğŸ”„ å‡†å¤‡é‡è¯• ({retry_count}/{self.max_retries})...")
                        
                        # é‡å¯ComfyUI
                        restart_success = self.restart_comfyui(f"æ‰¹æ¬¡å¤„ç†è¶…æ—¶: {status_msg}")
                        
                        if restart_success:
                            time.sleep(self.restart_delay)
                            continue
                        else:
                            logger.error("âŒ é‡å¯ComfyUIå¤±è´¥")
                            break
                    else:
                        logger.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    
            except Exception as e:
                status_msg = f"å¤„ç†å¼‚å¸¸: {str(e)}"
                logger.error(f"âŒ {status_msg}", exc_info=True)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†è¾“å‡º
                partial_files, _ = self.progress_tracker.get_existing_batches(
                    video_path, temp_workflow, total_batches
                )
                
                if partial_files:
                    completed = len(partial_files)
                    logger.info(f"âš ï¸  å¼‚å¸¸ä½†å·²æœ‰ {completed}/{total_batches} ä¸ªè¾“å‡ºæ–‡ä»¶")
                
                # è®°å½•é‡å¯
                self.record_restart(
                    video_path=video_path,
                    reason=status_msg,
                    attempt=retry_count
                )
                
                if retry_count < self.max_retries:
                    logger.info(f"ğŸ”„ å¼‚å¸¸åå‡†å¤‡é‡è¯• ({retry_count}/{self.max_retries})...")
                    
                    # é‡å¯ComfyUI
                    restart_success = self.restart_comfyui(f"å¤„ç†å¼‚å¸¸: {str(e)}")
                    
                    if restart_success:
                        time.sleep(self.restart_delay)
                        continue
                else:
                    logger.error("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
        
        # æ¸…ç†è¿›åº¦
        if success:
            self.progress_tracker.delete_progress(video_path)
        
        return success, status_msg, retry_count, output_files
    
    def record_restart(self, video_path: str, reason: str, attempt: int = 1):
        """è®°å½•é‡å¯äº‹ä»¶"""
        restart_entry = {
            'timestamp': datetime.now().isoformat(),
            'video_path': video_path,
            'video_name': os.path.basename(video_path),
            'reason': reason,
            'attempt': attempt
        }
        self.restart_history.append(restart_entry)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open('restart_history.json', 'w', encoding='utf-8') as f:
                json.dump(self.restart_history, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… é‡å¯å†å²å·²ä¿å­˜: restart_history.json")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜é‡å¯å†å²å¤±è´¥: {e}")
    
    def move_to_done_directory(self, video_path: str) -> Optional[str]:
        """ç§»åŠ¨æ–‡ä»¶åˆ°doneç›®å½•"""
        try:
            if not os.path.exists(video_path):
                logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                return None
            
            # è·å–åŸæ–‡ä»¶æ‰€åœ¨ç›®å½•
            original_dir = os.path.dirname(video_path)
            file_name = os.path.basename(video_path)
            
            # åˆ›å»ºdoneç›®å½•
            done_dir = os.path.join(original_dir, "done")
            os.makedirs(done_dir, exist_ok=True)
            
            # ç”Ÿæˆç›®æ ‡è·¯å¾„
            done_path = os.path.join(done_dir, file_name)
            
            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
            if os.path.exists(done_path):
                base_name, ext = os.path.splitext(file_name)
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                new_name = f"{base_name}_{timestamp}{ext}"
                done_path = os.path.join(done_dir, new_name)
            
            # ç§»åŠ¨æ–‡ä»¶
            shutil.move(video_path, done_path)
            logger.info(f"âœ… æ–‡ä»¶å·²ç§»åŠ¨åˆ°doneç›®å½•")
            
            return done_path
            
        except Exception as e:
            logger.error(f"âŒ ç§»åŠ¨æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def batch_process(
        self,
        workflow_template_path: str,
        video_files: List[str],
        output_prefix_base: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        frames_per_batch: int = 125,
        gpu_device: str = "auto",
        move_to_done: bool = True,
        cleanup_after_each: bool = True
    ) -> Dict[str, Tuple[bool, str, int, List[str]]]:
        """æ‰¹é‡å¤„ç†è§†é¢‘"""
        logger.info(f"\n{'='*60}")
        logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(video_files)} ä¸ªè§†é¢‘")
        logger.info(f"âš™ï¸  å‚æ•°: scale={scale}, tile_size={tile_size}, tile_overlap={tile_overlap}")
        logger.info(f"ğŸ® GPUè®¾å¤‡: {gpu_device}")
        logger.info(f"â±ï¸  æ‰¹æ¬¡è¶…æ—¶: {self.timeout_per_batch}ç§’")
        logger.info(f"ğŸ”„ æœ€å¤§é‡è¯•: {self.max_retries}æ¬¡")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {self.progress_tracker.output_dir}")
        logger.info(f"{'='*60}")
        
        # åŠ è½½å·¥ä½œæµæ¨¡æ¿
        try:
            workflow_template = self.load_workflow_template(workflow_template_path)
            logger.info(f"âœ… åŠ è½½å·¥ä½œæµæ¨¡æ¿: {workflow_template_path}")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å·¥ä½œæµæ¨¡æ¿å¤±è´¥: {e}")
            return {}
        
        # ç¡®ä¿ComfyUIåœ¨è¿è¡Œ
        if not self.ensure_comfyui_running():
            logger.error("âŒ ComfyUIæœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨ComfyUI")
            return {}
        
        results = {}
        processed_count = 0
        failed_count = 0
        
        for i, video_path in enumerate(video_files, 1):
            video_name = os.path.basename(video_path)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_path):
                logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                self.failed_files[video_path] = {
                    'status': 'failed',
                    'message': 'æ–‡ä»¶ä¸å­˜åœ¨',
                    'timestamp': datetime.now().isoformat()
                }
                failed_count += 1
                continue
            
            logger.info(f"\nğŸ“Š [{i}/{len(video_files)}] å¤„ç†: {video_name}")
            logger.info("-" * 40)
            
            # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
            video_info = get_video_info(video_path)
            logger.info(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {video_name}")
            logger.info(f"   æ€»å¸§æ•°: {video_info['total_frames']}")
            logger.info(f"   å¸§ç‡: {video_info['fps']:.3f} fps")
            logger.info(f"   æ—¶é•¿: {video_info['duration']:.1f} ç§’")
            logger.info(f"   åˆ†è¾¨ç‡: {video_info['resolution']}")
            
            # è®¾ç½®è¾“å‡ºå‰ç¼€
            output_prefix = None
            if output_prefix_base:
                base_name = os.path.splitext(video_name)[0]
                output_prefix = f"{output_prefix_base}_{base_name}"
            
            # å¤„ç†å•ä¸ªè§†é¢‘
            success, status_msg, retry_count, output_files = self.process_single_video(
                workflow_template=workflow_template,
                video_path=video_path,
                output_prefix=output_prefix,
                scale=scale,
                tile_size=tile_size,
                tile_overlap=tile_overlap,
                frames_per_batch=frames_per_batch,
                gpu_device=gpu_device
            )
            
            # è®°å½•ç»“æœ
            results[video_path] = (success, status_msg, retry_count, output_files)
            
            if success:
                processed_count += 1
                self.processed_files[video_path] = {
                    'status': 'success',
                    'message': status_msg,
                    'retries': retry_count,
                    'output_files': [os.path.basename(f) for f in output_files] if output_files else [],
                    'timestamp': datetime.now().isoformat()
                }
                
                # ç§»åŠ¨æ–‡ä»¶åˆ°doneç›®å½•
                if move_to_done and "è·³è¿‡" not in status_msg:  # ä¸ç§»åŠ¨è·³è¿‡çš„æ–‡ä»¶
                    moved_path = self.move_to_done_directory(video_path)
                    if not moved_path:
                        logger.warning(f"âš ï¸  æ–‡ä»¶ç§»åŠ¨å¤±è´¥: {video_name}")
                
                # é‡ç½®é‡è¯•è®¡æ•°
                self.current_retry_count = 0
                
            else:
                failed_count += 1
                self.failed_files[video_path] = {
                    'status': 'failed',
                    'message': status_msg,
                    'retries': retry_count,
                    'output_files': [os.path.basename(f) for f in output_files] if output_files else [],
                    'timestamp': datetime.now().isoformat()
                }
                logger.error(f"âŒ å¤„ç†å¤±è´¥: {status_msg}")
            
            # æ¸…ç†ç¼“å­˜
            if cleanup_after_each and success:
                self.clear_cache()
            
            # çŸ­æš‚é—´éš”
            if i < len(video_files):
                wait_time = 2
                logger.info(f"â±ï¸  ç­‰å¾… {wait_time} ç§’...")
                time.sleep(wait_time)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info(f"\n{'='*60}")
        logger.info("æ‰¹é‡å¤„ç†å®Œæˆ")
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"  âœ… æˆåŠŸ: {processed_count}/{len(video_files)}")
        logger.info(f"  âŒ å¤±è´¥: {failed_count}/{len(video_files)}")
        
        if processed_count > 0:
            logger.info(f"âœ… æˆåŠŸæ–‡ä»¶åˆ—è¡¨:")
            for i, (video_path, (success, status, retries, files)) in enumerate(results.items()):
                if success and i < 10:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    logger.info(f"  {i+1}. {os.path.basename(video_path)} - {status} (é‡è¯•: {retries})")
            if processed_count > 10:
                logger.info(f"  ... è¿˜æœ‰ {processed_count-10} ä¸ªæˆåŠŸæ–‡ä»¶")
        
        if failed_count > 0:
            logger.info(f"âŒ å¤±è´¥æ–‡ä»¶åˆ—è¡¨:")
            for i, (video_path, (success, status, retries, files)) in enumerate(results.items()):
                if not success and i < 10:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    logger.info(f"  {i+1}. {os.path.basename(video_path)} - {status} (é‡è¯•: {retries})")
            if failed_count > 10:
                logger.info(f"  ... è¿˜æœ‰ {failed_count-10} ä¸ªå¤±è´¥æ–‡ä»¶")
        
        return results
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†èµ„æº...")
        try:
            self.client.session.close()
        except:
            pass
        logger.info("âœ… æ¸…ç†å®Œæˆ")

def collect_video_files(input_path: str, pattern: str = '*.mp4') -> List[str]:
    """æ”¶é›†è§†é¢‘æ–‡ä»¶"""
    video_files = []
    
    if os.path.isfile(input_path):
        if input_path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv')):
            video_files.append(input_path)
            logger.info(f"âœ… æ·»åŠ å•ä¸ªæ–‡ä»¶: {input_path}")
    elif os.path.isdir(input_path):
        # æœç´¢è§†é¢‘æ–‡ä»¶
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', '.MP4', '.MOV', '.AVI', '.MKV']
        
        for ext in video_extensions:
            search_pattern = os.path.join(input_path, f"*{ext}")
            found_files = glob.glob(search_pattern)
            video_files.extend(found_files)
        
        # å»é‡å¹¶æ’åº
        video_files = sorted(list(set(video_files)))
        
        if not video_files:
            logger.error(f"âŒ ç›®å½• {input_path} ä¸­æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        else:
            logger.info(f"âœ… ä»ç›®å½• {input_path} æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    else:
        logger.error(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    return video_files

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· v22 - æ™ºèƒ½ç®€åŒ–ç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘
  python batch_processor_v22.py --input ./videos --batch-timeout 300
  
  # è‡ªå®šä¹‰æ‰¹æ¬¡å¤§å°
  python batch_processor_v22.py --input ./videos --frames-per-batch 125
  
  # æŒ‡å®šGPUè®¾å¤‡
  python batch_processor_v22.py --input ./videos --gpu 0

ä¸»è¦æ”¹è¿›(v22):
  1. ç®€åŒ–è¶…æ—¶é€»è¾‘: åªä¿ç•™æ‰¹æ¬¡è¶…æ—¶ï¼Œå»é™¤è§†é¢‘æ€»è¶…æ—¶
  2. æ‰¹æ¬¡æ—¶é—´è¿½è¸ª: è®°å½•æ¯ä¸ªæ‰¹æ¬¡çš„å®é™…å¤„ç†æ—¶é—´ç”¨äºæ™ºèƒ½åˆ¤æ–­
  3. å¢å¼ºçŠ¶æ€æ£€æŸ¥: å¢åŠ é‡è¯•æœºåˆ¶ï¼Œé¿å…å•æ¬¡æ£€æŸ¥å¤±è´¥
  4. ä»»åŠ¡æäº¤é—´éš”: é¿å…çŸ­æ—¶é—´å¤§é‡ä»»åŠ¡å†²å‡»é˜Ÿåˆ—
  5. ç›‘æ§é˜Ÿåˆ—è´Ÿè½½: åœ¨æäº¤å‰æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
  6. è¯¦ç»†çŠ¶æ€è¿½è¸ª: åŒºåˆ†è¿è¡Œé˜Ÿåˆ—å’Œç­‰å¾…é˜Ÿåˆ—
  7. é¢„æµ‹å®Œæˆæ—¶é—´: åŸºäºå†å²æ‰¹æ¬¡å¤„ç†æ—¶é—´é¢„æµ‹å‰©ä½™æ—¶é—´
        """
    )
    
    # è¾“å…¥å‚æ•°
    parser.add_argument('--template', type=str, default='flashvsr_tile-no.json',
                       help='å·¥ä½œæµæ¨¡æ¿ JSON æ–‡ä»¶è·¯å¾„ (é»˜è®¤: flashvsr_tile-no.json)')
    parser.add_argument('--input', type=str, required=True,
                       help='è¾“å…¥è·¯å¾„ï¼ˆè§†é¢‘æ–‡ä»¶æˆ–ç›®å½•ï¼‰')
    parser.add_argument('--pattern', type=str, default='*.mp4',
                       help='è§†é¢‘æ–‡ä»¶åŒ¹é…æ¨¡å¼ (é»˜è®¤: *.mp4)')
    
    # å¤„ç†å‚æ•°
    parser.add_argument('--scale', type=float, default=4.0,
                       help='æ”¾å¤§å€æ•° (é»˜è®¤: 4.0)')
    parser.add_argument('--tile-size', type=int, default=256,
                       help='åˆ†å—å¤§å° (é»˜è®¤: 256)')
    parser.add_argument('--tile-overlap', type=int, default=24,
                       help='åˆ†å—é‡å åƒç´  (é»˜è®¤: 24)')
    parser.add_argument('--frames-per-batch', type=int, default=125,
                       help='æ¯æ‰¹å¤„ç†çš„å¸§æ•° (é»˜è®¤: 125)')
    parser.add_argument('--gpu', type=str, default='auto',
                       help='GPUè®¾å¤‡é€‰æ‹© (é»˜è®¤: auto)')
    
    # è¶…æ—¶å‚æ•°
    parser.add_argument('--batch-timeout', type=int, default=300,
                       help='æ¯ä¸ªæ‰¹æ¬¡çš„æœ€å¤§å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 300)')
    parser.add_argument('--max-retries', type=int, default=3,
                       help='æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)')
    parser.add_argument('--restart-delay', type=int, default=5,
                       help='é‡å¯åç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 5)')
    parser.add_argument('--submit-interval', type=int, default=2,
                       help='ä»»åŠ¡æäº¤æœ€å°é—´éš”ï¼ˆç§’ï¼‰(é»˜è®¤: 2)')
    
    # æ–‡ä»¶ç®¡ç†
    parser.add_argument('--no-move', action='store_true',
                       help='ä¸å°†å¤„ç†å®Œæˆçš„æ–‡ä»¶ç§»åŠ¨åˆ°doneç›®å½•')
    parser.add_argument('--no-cleanup', action='store_true',
                       help='ä¸æ¸…ç†ç¼“å­˜')
    
    # ç³»ç»Ÿå‚æ•°
    parser.add_argument('--server', type=str, default='http://127.0.0.1:8188',
                       help='ComfyUI æœåŠ¡å™¨åœ°å€ (é»˜è®¤: http://127.0.0.1:8188)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥pymediainfoæ˜¯å¦å®‰è£…
    if not PYMEDIAINFO_AVAILABLE:
        logger.warning("âš ï¸  pymediainfoæœªå®‰è£…ï¼Œå°†æ— æ³•è·å–è§†é¢‘çœŸå®å¸§æ•°")
        logger.info("è¯·è¿è¡Œ: pip install pymediainfo")
    
    # æ”¶é›†è§†é¢‘æ–‡ä»¶
    video_files = collect_video_files(args.input, args.pattern)
    
    if not video_files:
        logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        return
    
    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
    logger.info(f"ğŸ“ å‘ç° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶:")
    for i, video_path in enumerate(video_files[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
        file_size = os.path.getsize(video_path) if os.path.exists(video_path) else 0
        file_size_mb = file_size / (1024 * 1024)
        logger.info(f"  {i+1}. {os.path.basename(video_path)} ({file_size_mb:.1f}MB)")
    
    if len(video_files) > 10:
        logger.info(f"  ... è¿˜æœ‰ {len(video_files)-10} ä¸ªæ–‡ä»¶")
    
    # ç¡®è®¤å¤„ç†
    user_input = input(f"\nç¡®è®¤å¤„ç† {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶? (y/n): ").strip().lower()
    if user_input not in ['y', 'yes', 'æ˜¯']:
        logger.info("ğŸš« ç”¨æˆ·å–æ¶ˆå¤„ç†")
        return
    
    # åˆ›å»ºæ‰¹å¤„ç†å™¨å®ä¾‹
    processor = ComfyUI_FlashVSR_BatchProcessor(
        comfyui_url=args.server,
        timeout_per_batch=args.batch_timeout,
        max_retries=args.max_retries,
        restart_delay=args.restart_delay,
        min_submit_interval=args.submit_interval
    )
    
    try:
        # å¼€å§‹æ‰¹é‡å¤„ç†
        results = processor.batch_process(
            workflow_template_path=args.template,
            video_files=video_files,
            output_prefix_base=f"flashvsr_scale{args.scale}_tile{args.tile_size}",
            scale=args.scale,
            tile_size=args.tile_size,
            tile_overlap=args.tile_overlap,
            frames_per_batch=args.frames_per_batch,
            gpu_device=args.gpu,
            move_to_done=not args.no_move,
            cleanup_after_each=not args.no_cleanup
        )
        
        # è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
        logger.info(f"\n{'='*60}")
        logger.info("å¤„ç†ç»Ÿè®¡è¯¦æƒ…")
        logger.info(f"{'='*60}")
        
        success_count = 0
        fail_count = 0
        total_retries = 0
        
        for video_path, (success, status, retries, files) in results.items():
            if success:
                success_count += 1
                total_retries += retries
                logger.info(f"âœ… {os.path.basename(video_path)}: æˆåŠŸ (é‡è¯•: {retries})")
                logger.info(f"   çŠ¶æ€: {status}")
                if files:
                    logger.info(f"   è¾“å‡ºæ–‡ä»¶: {len(files)} ä¸ª")
            else:
                fail_count += 1
                total_retries += retries
                logger.info(f"âŒ {os.path.basename(video_path)}: å¤±è´¥ (é‡è¯•: {retries})")
                logger.info(f"   çŠ¶æ€: {status}")
        
        logger.info(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        logger.info(f"   âœ… æˆåŠŸ: {success_count}/{len(video_files)} ({success_count/len(video_files)*100:.1f}%)")
        logger.info(f"   âŒ å¤±è´¥: {fail_count}/{len(video_files)} ({fail_count/len(video_files)*100:.1f}%)")
        
        if success_count > 0:
            avg_retries = total_retries / success_count if success_count > 0 else 0
            logger.info(f"   ğŸ”„ å¹³å‡é‡è¯•æ¬¡æ•°: {avg_retries:.1f}")
        
        # é‡å¯å†å²
        if processor.restart_history:
            logger.info(f"\nğŸ”„ é‡å¯å†å² ({len(processor.restart_history)} æ¬¡):")
            for i, restart in enumerate(processor.restart_history[-5:]):  # æ˜¾ç¤ºæœ€è¿‘5æ¬¡
                logger.info(f"   {i+1}. {restart['timestamp'][11:19]} - {restart.get('video_name', 'ç³»ç»Ÿ')}: {restart['reason']}")
        
        # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
        report_path = f"batch_processing_report_{time.strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("ComfyUI FlashVSR æ‰¹é‡å¤„ç†æŠ¥å‘Š\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("ğŸ“Š å¤„ç†ç»Ÿè®¡:\n")
            f.write(f"  æ€»æ–‡ä»¶æ•°: {len(video_files)}\n")
            f.write(f"  æˆåŠŸæ–‡ä»¶: {success_count}\n")
            f.write(f"  å¤±è´¥æ–‡ä»¶: {fail_count}\n")
            f.write(f"  æˆåŠŸç‡: {success_count/len(video_files)*100:.1f}%\n\n")
            
            f.write("ğŸ“ æ–‡ä»¶è¯¦æƒ…:\n")
            for video_path, (success, status, retries, files) in results.items():
                f.write(f"\nğŸ“‚ {os.path.basename(video_path)}:\n")
                f.write(f"   çŠ¶æ€: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}\n")
                f.write(f"   é‡è¯•æ¬¡æ•°: {retries}\n")
                f.write(f"   çŠ¶æ€ä¿¡æ¯: {status}\n")
                if files:
                    f.write(f"   è¾“å‡ºæ–‡ä»¶ ({len(files)} ä¸ª):\n")
                    for file_path in files:
                        if os.path.exists(file_path):
                            file_size = os.path.getsize(file_path) / (1024 * 1024)
                            f.write(f"     - {os.path.basename(file_path)} ({file_size:.1f}MB)\n")
                        else:
                            f.write(f"     - {os.path.basename(file_path)} (æ–‡ä»¶ä¸å­˜åœ¨)\n")
            
            f.write("\n" + "=" * 60 + "\n")
            f.write("é‡å¯å†å²:\n")
            for i, restart in enumerate(processor.restart_history):
                f.write(f"\n{i+1}. æ—¶é—´: {restart['timestamp']}\n")
                f.write(f"   è§†é¢‘: {restart.get('video_name', 'ç³»ç»Ÿé‡å¯')}\n")
                f.write(f"   åŸå› : {restart['reason']}\n")
                f.write(f"   å°è¯•: {restart['attempt']}æ¬¡\n")
            
            f.write("\n" + "=" * 60 + "\n")
            f.write("å¤„ç†å‚æ•°:\n")
            f.write(f"   å·¥ä½œæµæ¨¡æ¿: {args.template}\n")
            f.write(f"   æ”¾å¤§å€æ•°: {args.scale}\n")
            f.write(f"   åˆ†å—å¤§å°: {args.tile_size}\n")
            f.write(f"   åˆ†å—é‡å : {args.tile_overlap}\n")
            f.write(f"   æ¯æ‰¹å¸§æ•°: {args.frames_per_batch}\n")
            f.write(f"   GPUè®¾å¤‡: {args.gpu}\n")
            f.write(f"   æ‰¹æ¬¡è¶…æ—¶: {args.batch_timeout}ç§’\n")
            f.write(f"   æœ€å¤§é‡è¯•: {args.max_retries}æ¬¡\n")
            f.write(f"   ComfyUIåœ°å€: {args.server}\n")
        
        logger.info(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
    except KeyboardInterrupt:
        logger.info("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­å¤„ç†")
    except Exception as e:
        logger.error(f"\nâŒ æ‰¹é‡å¤„ç†å¼‚å¸¸: {e}", exc_info=True)
    finally:
        processor.cleanup()

if __name__ == "__main__":
    main()
