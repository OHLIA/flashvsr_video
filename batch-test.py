"""
ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· - æ™ºèƒ½è¶…æ—¶ç‰ˆæœ¬
ä¿®å¤äº†ä»»åŠ¡è¶…æ—¶é€»è¾‘ï¼Œæ”¯æŒæ‰¹å¤„ç†ä¸­çš„éƒ¨åˆ†å®Œæˆå’Œæ¢å¤
"""

import os
import sys
import json
import time
import random
import string
import logging
import requests
import subprocess
import datetime
import shutil
import gc
import atexit
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Set
from glob import glob
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('comfyui_batch_processor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å¯é€‰ä¾èµ–
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    logger.warning("âš ï¸  torchä¸å¯ç”¨ï¼ŒGPUæ¸…ç†åŠŸèƒ½å°†å—é™")

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    logger.warning("âš ï¸  psutilä¸å¯ç”¨ï¼Œè¿›ç¨‹ç®¡ç†åŠŸèƒ½å°†å—é™")

try:
    from pymediainfo import MediaInfo
    PYMEDIAINFO_AVAILABLE = True
except ImportError:
    PYMEDIAINFO_AVAILABLE = False
    logger.warning("âš ï¸  pymediainfoä¸å¯ç”¨ï¼Œè§†é¢‘å¸§æ•°æ£€æµ‹å°†ä½¿ç”¨ä¼°è®¡å€¼")

def get_video_info(video_path: str) -> Dict[str, Any]:
    """è·å–è§†é¢‘ä¿¡æ¯"""
    video_info = {
        'total_frames': 0,
        'fps': 0.0,
        'duration': 0.0,
        'resolution': 'æœªçŸ¥',
        'file_size': os.path.getsize(video_path)
    }
    
    if PYMEDIAINFO_AVAILABLE:
        try:
            media_info = MediaInfo.parse(video_path)
            for track in media_info.tracks:
                if track.track_type == 'Video':
                    video_info['total_frames'] = int(track.frame_count) if hasattr(track, 'frame_count') else 0
                    video_info['fps'] = float(track.frame_rate) if hasattr(track, 'frame_rate') else 0.0
                    video_info['duration'] = float(track.duration) / 1000.0 if hasattr(track, 'duration') else 0.0
                    video_info['resolution'] = f"{track.width}x{track.height}" if hasattr(track, 'width') and hasattr(track, 'height') else 'æœªçŸ¥'
                    break
        except Exception as e:
            logger.warning(f"âš ï¸  æ— æ³•é€šè¿‡pymediainfoè·å–è§†é¢‘ä¿¡æ¯: {e}")
    
    # å¦‚æœæ— æ³•è·å–å¸§æ•°ï¼Œå°è¯•é€šè¿‡æ—¶é•¿å’Œå¸§ç‡ä¼°ç®—
    if video_info['total_frames'] <= 0 and video_info['duration'] > 0 and video_info['fps'] > 0:
        video_info['total_frames'] = int(video_info['duration'] * video_info['fps'])
        logger.info(f"ğŸ“Š é€šè¿‡æ—¶é•¿å’Œå¸§ç‡ä¼°ç®—æ€»å¸§æ•°: {video_info['total_frames']}")
    
    return video_info

class ComfyUI_Client:
    """ComfyUI APIå®¢æˆ·ç«¯ - ä¿®å¤ç‰ˆ"""
    
    def __init__(self, server_address: str = "http://127.0.0.1:8188"):
        self.server_address = server_address
        self.session = requests.Session()
        self.client_id = self.generate_client_id()
    
    def generate_client_id(self) -> str:
        """ç”Ÿæˆå®¢æˆ·ç«¯ID"""
        random_str = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))
        return f"batch_processor_{random_str}"
    
    def is_server_running(self) -> bool:
        """æ£€æŸ¥ComfyUIæœåŠ¡å™¨æ˜¯å¦è¿è¡Œ"""
        try:
            response = self.session.get(f"{self.server_address}/system_stats", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_queue(self) -> List[Dict]:
        """è·å–é˜Ÿåˆ—ä¿¡æ¯"""
        try:
            response = self.session.get(f"{self.server_address}/queue", timeout=10)
            if response.status_code == 200:
                queue_data = response.json()
                # åˆå¹¶è¿è¡Œä¸­å’Œç­‰å¾…ä¸­çš„é˜Ÿåˆ—
                queue_running = queue_data.get('queue_running', [])
                queue_pending = queue_data.get('queue_pending', [])
                return queue_running + queue_pending
        except Exception as e:
            logger.debug(f"è·å–é˜Ÿåˆ—å¤±è´¥: {e}")
        return []
    
    def is_queue_empty(self) -> bool:
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦ä¸ºç©º"""
        return len(self.get_queue()) == 0
    
    def get_history(self) -> Dict[str, Dict]:
        """è·å–å†å²è®°å½•"""
        try:
            response = self.session.get(f"{self.server_address}/history", timeout=10)
            if response.status_code == 200:
                history_data = response.json()
                # ç¡®ä¿è¿”å›çš„æ˜¯å­—å…¸
                if isinstance(history_data, dict):
                    return history_data
                elif isinstance(history_data, list):
                    logger.warning(f"âš ï¸  /historyè¿”å›äº†åˆ—è¡¨è€Œä¸æ˜¯å­—å…¸: {history_data[:5] if len(history_data) > 5 else history_data}")
                    return {}
                else:
                    logger.warning(f"âš ï¸  /historyè¿”å›äº†æœªçŸ¥ç±»å‹: {type(history_data)}")
                    return {}
        except Exception as e:
            logger.debug(f"è·å–å†å²è®°å½•å¤±è´¥: {e}")
        return {}
    
    def get_prompt_by_id(self, prompt_id: str) -> Optional[Dict]:
        """æ ¹æ®IDè·å–ç‰¹å®šä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            history = self.get_history()
            if prompt_id in history:
                return history[prompt_id]
        except Exception as e:
            logger.debug(f"è·å–ä»»åŠ¡ {prompt_id} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
        return None
    
    def get_prompt_status(self, prompt_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        try:
            # 1. é¦–å…ˆæ£€æŸ¥å†å²è®°å½•ï¼ˆå·²å®Œæˆçš„ä»»åŠ¡ï¼‰
            prompt_info = self.get_prompt_by_id(prompt_id)
            if prompt_info:
                return {
                    'status': {
                        'completed': True,
                        'error': False
                    },
                    'outputs': prompt_info.get('outputs', {}),
                    'prompt_id': prompt_id
                }
            
            # 2. æ£€æŸ¥é˜Ÿåˆ—ï¼ˆè¿è¡Œä¸­/ç­‰å¾…ä¸­çš„ä»»åŠ¡ï¼‰
            queue = self.get_queue()
            for item in queue:
                if isinstance(item, dict) and item.get('prompt_id') == prompt_id:
                    return {
                        'status': {
                            'completed': False,
                            'error': False
                        },
                        'outputs': {},
                        'prompt_id': prompt_id
                    }
            
            # 3. å¦‚æœä¸åœ¨å†å²å’Œé˜Ÿåˆ—ä¸­ï¼Œå¯èƒ½ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²å¤±è´¥
            return {
                'status': {
                    'completed': False,
                    'error': True,
                    'error_message': 'ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—æˆ–å†å²ä¸­'
                },
                'outputs': {},
                'prompt_id': prompt_id
            }
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
            return {
                'status': {
                    'completed': False,
                    'error': True,
                    'error_message': f'è·å–çŠ¶æ€å¼‚å¸¸: {str(e)}'
                },
                'outputs': {},
                'prompt_id': prompt_id
            }
    
    def is_prompt_completed(self, prompt_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ"""
        prompt_info = self.get_prompt_status(prompt_id)
        if prompt_info and 'status' in prompt_info:
            return prompt_info['status'].get('completed', False)
        return False
    
    def get_prompt_outputs(self, prompt_id: str) -> Dict:
        """è·å–ä»»åŠ¡çš„è¾“å‡ºä¿¡æ¯"""
        prompt_info = self.get_prompt_status(prompt_id)
        if prompt_info:
            return prompt_info.get('outputs', {})
        return {}
    
    def submit_prompt(self, workflow: Dict) -> Optional[str]:
        """æäº¤ä»»åŠ¡åˆ°ComfyUI"""
        try:
            # æ¸…é™¤å†å²è®°å½•
            self.clear_history()
            
            # æäº¤ä»»åŠ¡
            response = self.session.post(
                f"{self.server_address}/prompt",
                json={"prompt": workflow, "client_id": self.client_id},
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                prompt_id = data.get('prompt_id')
                if prompt_id:
                    logger.info(f"âœ… ä»»åŠ¡æäº¤æˆåŠŸï¼ŒID: {prompt_id[:8]}...")
                    return prompt_id
                else:
                    logger.error(f"âŒ æäº¤ä»»åŠ¡å¤±è´¥: è¿”å›æ•°æ®ä¸­æ— prompt_id")
                    return None
            else:
                logger.error(f"âŒ æäº¤ä»»åŠ¡å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except requests.exceptions.ConnectionError as e:
            logger.error(f"âŒ è¿æ¥ComfyUIæœåŠ¡å™¨å¤±è´¥: {e}")
            return None
        except requests.exceptions.Timeout as e:
            logger.error(f"âŒ è¿æ¥ComfyUIæœåŠ¡å™¨è¶…æ—¶: {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ æäº¤ä»»åŠ¡å¼‚å¸¸: {e}")
            return None
    
    def clear_history(self) -> bool:
        """æ¸…é™¤å†å²è®°å½•"""
        try:
            response = self.session.post(f"{self.server_address}/history", json={"clear": True})
            return response.status_code == 200
        except:
            return False
    
    def clear_queue(self) -> bool:
        """æ¸…é™¤é˜Ÿåˆ—"""
        try:
            response = self.session.post(f"{self.server_address}/queue", json={"clear": True})
            return response.status_code == 200
        except:
            return False
    
    def interrupt_queue(self) -> bool:
        """ä¸­æ–­å½“å‰ä»»åŠ¡"""
        try:
            response = self.session.post(f"{self.server_address}/interrupt")
            return response.status_code == 200
        except:
            return False

class BatchProgressTracker:
    """æ‰¹å¤„ç†è¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self, output_dir: str = None):
        self.output_dir = output_dir or self.get_default_output_dir()
        self.batch_progress_file = "batch_progress.json"
    
    def get_default_output_dir(self) -> str:
        """è·å–é»˜è®¤è¾“å‡ºç›®å½•"""
        comfyui_output = r"F:\AI\ComfyUI_Mie_V7.0\ComfyUI\output"
        if os.path.exists(comfyui_output):
            return comfyui_output
        
        default_output = os.path.join(os.getcwd(), "output")
        os.makedirs(default_output, exist_ok=True)
        return default_output
    
    def get_batch_output_pattern(self, video_path: str, workflow: Dict) -> List[str]:
        """è·å–æ‰¹æ¬¡è¾“å‡ºæ–‡ä»¶æ¨¡å¼"""
        # ä»å·¥ä½œæµä¸­æå–è¾“å‡ºå‰ç¼€
        output_prefix = self.extract_output_prefix(workflow)
        if not output_prefix:
            output_prefix = "flashvsr_"
        
        base_name = os.path.splitext(os.path.basename(video_path))[0]
        patterns = [
            os.path.join(self.output_dir, f"{output_prefix}_{base_name}_%*"),  # å¸¦ç™¾åˆ†æ¯”çš„æ¨¡å¼
            os.path.join(self.output_dir, f"{output_prefix}_{base_name}_*"),   # ä¸å¸¦ç™¾åˆ†æ¯”çš„æ¨¡å¼
            os.path.join(self.output_dir, f"ComfyUI_*.mov"),                    # é»˜è®¤ComfyUIè¾“å‡º
        ]
        return patterns
    
    def extract_output_prefix(self, workflow: Dict) -> str:
        """ä»å·¥ä½œæµä¸­æå–è¾“å‡ºå‰ç¼€"""
        for node_id, node_data in workflow.items():
            if node_data.get("class_type") == "VHS_VideoCombine":
                inputs = node_data.get("inputs", {})
                filename_prefix = inputs.get("filename_prefix", "")
                if filename_prefix:
                    return str(filename_prefix)
        return ""
    
    def get_existing_batches(self, video_path: str, workflow: Dict, total_batches: int) -> Tuple[List[str], Dict[str, Any]]:
        """è·å–å·²å­˜åœ¨çš„æ‰¹æ¬¡æ–‡ä»¶å’Œè¿›åº¦ä¿¡æ¯
        è¿”å›: (æ–‡ä»¶åˆ—è¡¨, è¿›åº¦ä¿¡æ¯)
        """
        base_name = os.path.splitext(os.path.basename(video_path))[0]
        output_files = []
        batch_status = {}
        
        # è·å–æ‰€æœ‰å¯èƒ½çš„è¾“å‡ºæ–‡ä»¶
        for ext in ['.mov', '.mp4', '.avi', '.mkv', '.webm']:
            # æœç´¢æ‰¹æ¬¡æ–‡ä»¶
            batch_files = glob(os.path.join(self.output_dir, f"*{base_name}*_*%*{ext}"))
            output_files.extend(batch_files)
            
            # æœç´¢æ²¡æœ‰ç™¾åˆ†æ¯”çš„æ‰¹æ¬¡æ–‡ä»¶
            simple_files = glob(os.path.join(self.output_dir, f"*{base_name}*{ext}"))
            for f in simple_files:
                if f not in output_files:
                    output_files.append(f)
        
        # åˆ†ææ‰¹æ¬¡çŠ¶æ€
        if output_files:
            logger.info(f"ğŸ“ å·²æ‰¾åˆ° {len(output_files)} ä¸ªæ‰¹æ¬¡æ–‡ä»¶:")
            for i, file_path in enumerate(output_files[:10]):
                file_size = os.path.getsize(file_path)
                file_size_mb = file_size / (1024 * 1024)
                batch_num = self.extract_batch_number(file_path)
                logger.info(f"  {i+1}. {os.path.basename(file_path)} ({file_size_mb:.1f}MB)")
            
            # åˆ†ææ‰¹æ¬¡è¿›åº¦
            completed_batches = len(output_files)
            batch_status = {
                'total_batches': total_batches,
                'completed_batches': completed_batches,
                'remaining_batches': max(0, total_batches - completed_batches),
                'percentage': (completed_batches / total_batches) * 100 if total_batches > 0 else 0,
                'files': output_files
            }
            
            logger.info(f"ğŸ“Š æ‰¹æ¬¡è¿›åº¦: {completed_batches}/{total_batches} ({batch_status['percentage']:.1f}%) å®Œæˆ")
        
        return output_files, batch_status
    
    def extract_batch_number(self, file_path: str) -> int:
        """ä»æ–‡ä»¶åä¸­æå–æ‰¹æ¬¡å·"""
        filename = os.path.basename(file_path)
        import re
        
        # å°è¯•åŒ¹é…æ‰¹æ¬¡å·
        patterns = [
            r'_batch_(\d+)',
            r'_(\d+)%',
            r'_(\d+)of',
            r'_batch(\d+)',
            r'%(\d+)%'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, filename)
            if match:
                try:
                    return int(match.group(1))
                except:
                    continue
        
        return -1
    
    def save_progress(self, video_path: str, progress_data: Dict):
        """ä¿å­˜å¤„ç†è¿›åº¦"""
        try:
            progress = {}
            if os.path.exists(self.batch_progress_file):
                with open(self.batch_progress_file, 'r', encoding='utf-8') as f:
                    progress = json.load(f)
            
            video_key = os.path.basename(video_path)
            progress[video_key] = {
                'video_path': video_path,
                'timestamp': datetime.now().isoformat(),
                'progress': progress_data
            }
            
            with open(self.batch_progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"âœ… è¿›åº¦å·²ä¿å­˜: {video_key}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è¿›åº¦å¤±è´¥: {e}")
    
    def load_progress(self, video_path: str) -> Optional[Dict]:
        """åŠ è½½å¤„ç†è¿›åº¦"""
        try:
            if os.path.exists(self.batch_progress_file):
                with open(self.batch_progress_file, 'r', encoding='utf-8') as f:
                    progress = json.load(f)
                
                video_key = os.path.basename(video_path)
                if video_key in progress:
                    return progress[video_key]
        except Exception as e:
            logger.error(f"âŒ åŠ è½½è¿›åº¦å¤±è´¥: {e}")
        return None
    
    def delete_progress(self, video_path: str):
        """åˆ é™¤å¤„ç†è¿›åº¦"""
        try:
            if os.path.exists(self.batch_progress_file):
                with open(self.batch_progress_file, 'r', encoding='utf-8') as f:
                    progress = json.load(f)
                
                video_key = os.path.basename(video_path)
                if video_key in progress:
                    del progress[video_key]
                    
                    with open(self.batch_progress_file, 'w', encoding='utf-8') as f:
                        json.dump(progress, f, ensure_ascii=False, indent=2)
                    
                    logger.debug(f"âœ… è¿›åº¦å·²åˆ é™¤: {video_key}")
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤è¿›åº¦å¤±è´¥: {e}")

class BatchTimeoutManager:
    """æ‰¹å¤„ç†è¶…æ—¶ç®¡ç†å™¨ - ä¿®å¤ç‰ˆ"""
    
    def __init__(self, timeout_per_batch: int = 300, timeout_per_video: int = 3600):
        """
        åˆå§‹åŒ–è¶…æ—¶ç®¡ç†å™¨
        timeout_per_batch: æ¯ä¸ªæ‰¹æ¬¡çš„æœ€å¤§å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
        timeout_per_video: æ•´ä¸ªè§†é¢‘çš„æœ€å¤§å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.timeout_per_batch = timeout_per_batch
        self.timeout_per_video = timeout_per_video
        self.video_timers = {}  # è·Ÿè¸ªæ¯ä¸ªè§†é¢‘çš„å¤„ç†æ—¶é—´
        self.batch_timers = {}  # è·Ÿè¸ªæ¯ä¸ªè§†é¢‘çš„æœ€æ–°æ‰¹æ¬¡å¼€å§‹æ—¶é—´
        self.progress_tracker = BatchProgressTracker()
    
    def start_video_timer(self, video_path: str):
        """å¼€å§‹è§†é¢‘è®¡æ—¶å™¨"""
        video_key = os.path.basename(video_path)
        self.video_timers[video_key] = {
            'start_time': time.time(),
            'last_batch_start': None,
            'completed_batches': 0,
            'timeout_count': 0
        }
        logger.debug(f"â±ï¸  å¼€å§‹è§†é¢‘è®¡æ—¶å™¨: {video_key}")
    
    def start_batch_timer(self, video_path: str, batch_num: int = None):
        """å¼€å§‹æ‰¹æ¬¡è®¡æ—¶å™¨"""
        video_key = os.path.basename(video_path)
        
        if video_key not in self.video_timers:
            self.start_video_timer(video_path)
        
        self.video_timers[video_key]['last_batch_start'] = time.time()
        
        if batch_num is not None:
            logger.debug(f"â±ï¸  å¼€å§‹æ‰¹æ¬¡ {batch_num} è®¡æ—¶å™¨: {video_key}")
    
    def check_batch_timeout(self, video_path: str) -> bool:
        """æ£€æŸ¥å½“å‰æ‰¹æ¬¡æ˜¯å¦è¶…æ—¶"""
        video_key = os.path.basename(video_path)
        
        if video_key not in self.video_timers:
            return False
        
        last_batch_start = self.video_timers[video_key].get('last_batch_start')
        if not last_batch_start:
            return False
        
        elapsed = time.time() - last_batch_start
        
        # å¦‚æœæ‰¹æ¬¡å¤„ç†æ—¶é—´è¶…è¿‡é˜ˆå€¼
        if elapsed > self.timeout_per_batch:
            logger.warning(f"âš ï¸  æ‰¹æ¬¡å¤„ç†è¶…æ—¶: å·²è¿è¡Œ {elapsed:.0f} ç§’ï¼Œè¶…è¿‡ {self.timeout_per_batch} ç§’")
            self.video_timers[video_key]['timeout_count'] += 1
            return True
        
        return False
    
    def check_video_timeout(self, video_path: str) -> bool:
        """æ£€æŸ¥æ•´ä¸ªè§†é¢‘å¤„ç†æ˜¯å¦è¶…æ—¶"""
        video_key = os.path.basename(video_path)
        
        if video_key not in self.video_timers:
            return False
        
        start_time = self.video_timers[video_key]['start_time']
        elapsed = time.time() - start_time
        
        # å¦‚æœæ•´ä¸ªè§†é¢‘å¤„ç†æ—¶é—´è¶…è¿‡é˜ˆå€¼
        if elapsed > self.timeout_per_video:
            logger.warning(f"âš ï¸  è§†é¢‘å¤„ç†æ€»æ—¶é•¿è¶…æ—¶: å·²è¿è¡Œ {elapsed:.0f} ç§’ï¼Œè¶…è¿‡ {self.timeout_per_video} ç§’")
            return True
        
        return False
    
    def should_restart(self, video_path: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å¯
        
        é‡å¯æ¡ä»¶ï¼š
        1. å½“å‰æ‰¹æ¬¡å¤„ç†è¶…æ—¶
        2. è¿ç»­å¤šä¸ªæ‰¹æ¬¡è¶…æ—¶
        3. æ•´ä¸ªè§†é¢‘å¤„ç†æ—¶é—´è¶…æ—¶
        """
        video_key = os.path.basename(video_path)
        
        if video_key not in self.video_timers:
            return False
        
        # æ£€æŸ¥æ‰¹æ¬¡è¶…æ—¶
        if self.check_batch_timeout(video_path):
            timeout_count = self.video_timers[video_key].get('timeout_count', 0)
            
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¶…æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¿›åº¦
            if timeout_count == 1:
                # è·å–å½“å‰è¿›åº¦
                progress = self.progress_tracker.load_progress(video_path)
                if progress and progress.get('progress', {}).get('completed_batches', 0) > 0:
                    logger.info(f"ğŸ” æ‰¹æ¬¡è¶…æ—¶ï¼Œä½†å·²æœ‰è¿›åº¦ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°æ‰¹æ¬¡å®Œæˆ...")
                    return False
            
            # è¿ç»­2æ¬¡è¶…æ—¶åˆ™é‡å¯
            if timeout_count >= 2:
                logger.warning(f"âš ï¸  è¿ç»­ {timeout_count} ä¸ªæ‰¹æ¬¡è¶…æ—¶ï¼Œéœ€è¦é‡å¯")
                return True
        
        # æ£€æŸ¥è§†é¢‘æ€»æ—¶é•¿è¶…æ—¶
        if self.check_video_timeout(video_path):
            return True
        
        return False
    
    def update_progress(self, video_path: str, completed_batches: int, total_batches: int):
        """æ›´æ–°å¤„ç†è¿›åº¦"""
        video_key = os.path.basename(video_path)
        
        if video_key in self.video_timers:
            self.video_timers[video_key]['completed_batches'] = completed_batches
            
            # é‡ç½®æ‰¹æ¬¡è®¡æ—¶å™¨
            self.start_batch_timer(video_path)
    
    def reset_video_timer(self, video_path: str):
        """é‡ç½®è§†é¢‘è®¡æ—¶å™¨"""
        video_key = os.path.basename(video_path)
        if video_key in self.video_timers:
            self.video_timers[video_key]['timeout_count'] = 0
            self.video_timers[video_key]['last_batch_start'] = time.time()
            logger.debug(f"ğŸ”„ é‡ç½®è§†é¢‘è®¡æ—¶å™¨: {video_key}")
    
    def get_elapsed_time(self, video_path: str) -> float:
        """è·å–å·²å¤„ç†æ—¶é—´"""
        video_key = os.path.basename(video_path)
        
        if video_key in self.video_timers:
            start_time = self.video_timers[video_key]['start_time']
            return time.time() - start_time
        
        return 0.0

class ComfyUI_FlashVSR_BatchProcessor:
    def __init__(self, 
                 comfyui_url: str = "http://127.0.0.1:8188", 
                 timeout_per_batch: int = 300,  # æ¯ä¸ªæ‰¹æ¬¡è¶…æ—¶æ—¶é—´
                 timeout_per_video: int = 3600,  # æ•´ä¸ªè§†é¢‘è¶…æ—¶æ—¶é—´
                 max_retries: int = 3,
                 restart_delay: int = 5,
                 startup_timeout: int = 300):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨ - æ™ºèƒ½è¶…æ—¶ç‰ˆæœ¬
        """
        # APIå®¢æˆ·ç«¯
        self.client = ComfyUI_Client(comfyui_url)
        
        # è¿›åº¦è·Ÿè¸ªå™¨
        self.progress_tracker = BatchProgressTracker()
        
        # è¶…æ—¶ç®¡ç†å™¨
        self.timeout_manager = BatchTimeoutManager(
            timeout_per_batch=timeout_per_batch,
            timeout_per_video=timeout_per_video
        )
        
        # é…ç½®å‚æ•°
        self.comfyui_url = comfyui_url
        self.timeout_per_batch = timeout_per_batch
        self.timeout_per_video = timeout_per_video
        self.max_retries = max_retries
        self.restart_delay = restart_delay
        self.startup_timeout = startup_timeout
        
        # çŠ¶æ€è·Ÿè¸ª
        self.processed_files = {}
        self.failed_files = {}
        self.restart_history = []
        self.current_retry_count = 0
        
        # æ³¨å†Œæ¸…ç†å‡½æ•°
        atexit.register(self.cleanup)
        
        logger.info("=" * 60)
        logger.info("ComfyUI FlashVSR æ‰¹é‡å¤„ç†å™¨ - æ™ºèƒ½è¶…æ—¶ç‰ˆæœ¬")
        logger.info(f"ComfyUIåœ°å€: {comfyui_url}")
        logger.info(f"æ‰¹æ¬¡è¶…æ—¶: {timeout_per_batch}ç§’")
        logger.info(f"è§†é¢‘è¶…æ—¶: {timeout_per_video}ç§’")
        logger.info(f"æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}æ¬¡")
        logger.info(f"è¾“å‡ºç›®å½•: {self.progress_tracker.output_dir}")
        logger.info("=" * 60)
    
    def ensure_comfyui_running(self) -> bool:
        """ç¡®ä¿ComfyUIåœ¨è¿è¡Œ"""
        if self.client.is_server_running():
            logger.info("âœ… ComfyUIæœåŠ¡å™¨æ­£å¸¸è¿è¡Œ")
            return True
        
        logger.error("âŒ ComfyUIæœåŠ¡å™¨æœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨ComfyUI")
        return False
    
    def clear_cache(self) -> Dict[str, Any]:
        """æ¸…ç†ç¼“å­˜"""
        cleanup_results = {
            "system_memory_freed_mb": 0,
            "gpu_memory_freed_mb": 0,
            "success": False
        }
        
        logger.info("ğŸ§¹ æ¸…ç†ç¼“å­˜...")
        
        try:
            # æ¸…ç†GPUæ˜¾å­˜
            if TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                logger.info("âœ… GPUæ˜¾å­˜å·²æ¸…ç†")
                cleanup_results["gpu_memory_freed_mb"] = 1
                cleanup_results["success"] = True
            
            # æ¸…ç†Pythonå†…å­˜
            collected = gc.collect()
            logger.info(f"âœ… Pythonåƒåœ¾å›æ”¶: {collected} ä¸ªå¯¹è±¡")
            cleanup_results["success"] = True
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        
        return cleanup_results
    
    def load_workflow_template(self, template_path: str) -> Dict:
        """åŠ è½½å·¥ä½œæµæ¨¡æ¿"""
        with open(template_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def update_workflow_parameters(
        self, 
        workflow: Dict, 
        video_path: str, 
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 201,
        gpu_device: str = "auto"
    ) -> Dict:
        """æ›´æ–°å·¥ä½œæµå‚æ•°"""
        import copy
        modified_workflow = copy.deepcopy(workflow)
        
        # è®¾ç½®è¾“å…¥è§†é¢‘è·¯å¾„
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_LoadVideo":
                node_data["inputs"]["video"] = video_path
                logger.debug(f"è®¾ç½®è¾“å…¥è§†é¢‘: {os.path.basename(video_path)}")
        
        # è®¾ç½®FlashVSRå‚æ•°
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "FlashVSRNodeAdv":
                inputs = node_data.get("inputs", {})
                if "{{scale}}" in str(inputs.get("scale", "")):
                    inputs["scale"] = scale
                if "{{t_z}}" in str(inputs.get("tile_size", "")):
                    inputs["tile_size"] = tile_size
                if "{{t_o}}" in str(inputs.get("tile_overlap", "")):
                    inputs["tile_overlap"] = tile_overlap
        
        # è®¾ç½®GPUè®¾å¤‡
        for node_id, node_data in modified_workflow.items():
            if node_id == "5" and node_data.get("class_type") == "FlashVSRInitPipe":
                inputs = node_data.get("inputs", {})
                if isinstance(inputs.get("device"), str):
                    if gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    inputs["device"] = device_value
                    logger.debug(f"è®¾ç½®GPUè®¾å¤‡: {device_value}")
        
        # è®¾ç½®æ€»å¸§æ•°
        if total_frames is None or total_frames <= 0:
            video_info = get_video_info(video_path)
            total_frames = video_info.get('total_frames', 0)
            if total_frames <= 0:
                total_frames = 10000
                logger.warning(f"âš ï¸  æ— æ³•è·å–è§†é¢‘æ€»å¸§æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼: {total_frames}")
        
        for node_id, node_data in modified_workflow.items():
            if node_id == "50" and node_data.get("class_type") == "PrimitiveInt":
                node_data["inputs"]["value"] = total_frames
                logger.debug(f"è®¾ç½®æ€»å¸§æ•°: {total_frames}")
        
        # è®¾ç½®æ¯æ‰¹å¸§æ•°
        for node_id, node_data in modified_workflow.items():
            if node_id == "8" and node_data.get("class_type") == "PrimitiveInt":
                node_data["inputs"]["value"] = frames_per_batch
                logger.debug(f"è®¾ç½®æ¯æ‰¹å¸§æ•°: {frames_per_batch}")
        
        # è®¾ç½®è¾“å‡ºå‰ç¼€
        if output_prefix is None:
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            output_prefix = f"flashvsr_{base_name}"
        
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_VideoCombine":
                node_data["inputs"]["filename_prefix"] = output_prefix
                logger.debug(f"è®¾ç½®è¾“å‡ºå‰ç¼€: {output_prefix}")
        
        return modified_workflow
    
    def wait_for_task_completion_smart(
        self, 
        prompt_id: str, 
        video_path: str, 
        workflow: Dict,
        total_frames: int,
        frames_per_batch: int,
        total_batches: int
    ) -> Tuple[bool, str, List[str], Dict[str, Any]]:
        """
        æ™ºèƒ½ç­‰å¾…ä»»åŠ¡å®Œæˆ
        è¿”å›: (æ˜¯å¦æˆåŠŸ, çŠ¶æ€ä¿¡æ¯, è¾“å‡ºæ–‡ä»¶åˆ—è¡¨, è¿›åº¦ä¿¡æ¯)
        """
        logger.info(f"â³ ç­‰å¾…ä»»åŠ¡å®Œæˆ (æ‰¹æ¬¡è¶…æ—¶: {self.timeout_per_batch}ç§’, è§†é¢‘æ€»è¶…æ—¶: {self.timeout_per_video}ç§’)...")
        
        video_name = os.path.basename(video_path)
        start_time = time.time()
        last_status_check = 0
        status_check_interval = 5
        last_progress_check = 0
        progress_check_interval = 10
        last_output_check = 0
        output_check_interval = 15
        queue_empty_count = 0
        max_queue_empty = 3
        output_files_found = []
        last_output_count = 0
        no_progress_count = 0
        max_no_progress = 3
        
        # è®¡ç®—é¢„æœŸæ‰¹æ¬¡æ•°
        expected_batches = total_batches
        
        while True:
            current_time = time.time()
            elapsed = current_time - start_time
            
            # 1. æ£€æŸ¥è§†é¢‘æ€»è¶…æ—¶
            if elapsed > self.timeout_per_video:
                logger.warning(f"âš ï¸  è§†é¢‘ {video_name} å¤„ç†æ€»æ—¶é•¿è¶…æ—¶: {elapsed:.0f}ç§’")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºæ–‡ä»¶
                output_files, progress_info = self.progress_tracker.get_existing_batches(
                    video_path, workflow, expected_batches
                )
                
                if output_files:
                    completed = len(output_files)
                    logger.info(f"ğŸ“Š å·²å¤„ç† {completed}/{expected_batches} ä¸ªæ‰¹æ¬¡")
                    
                    if completed > 0:
                        return True, f"è§†é¢‘æ€»æ—¶é•¿è¶…æ—¶ä½†æœ‰éƒ¨åˆ†å®Œæˆ({completed}/{expected_batches})", output_files, progress_info
                
                return False, f"è§†é¢‘æ€»æ—¶é•¿è¶…æ—¶({elapsed:.0f}ç§’)", [], {}
            
            # 2. æ£€æŸ¥æ‰¹æ¬¡è¶…æ—¶
            if self.timeout_manager.check_batch_timeout(video_path):
                logger.warning(f"âš ï¸  æ‰¹æ¬¡å¤„ç†è¶…æ—¶: {video_name}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºè¿›åº¦
                output_files, progress_info = self.progress_tracker.get_existing_batches(
                    video_path, workflow, expected_batches
                )
                
                completed = len(output_files)
                if completed > last_output_count:
                    # æœ‰æ–°çš„æ‰¹æ¬¡å®Œæˆï¼Œé‡ç½®è®¡æ•°å™¨
                    last_output_count = completed
                    no_progress_count = 0
                    logger.info(f"ğŸ“ˆ æ£€æµ‹åˆ°æ–°æ‰¹æ¬¡å®Œæˆ: {completed}/{expected_batches}")
                    self.timeout_manager.reset_video_timer(video_path)
                else:
                    no_progress_count += 1
                    logger.warning(f"âš ï¸  æ‰¹æ¬¡æ— è¿›å±•: {no_progress_count}/{max_no_progress}")
                    
                    if no_progress_count >= max_no_progress:
                        logger.warning(f"âš ï¸  è¿ç»­ {max_no_progress} ä¸ªæ‰¹æ¬¡æ— è¿›å±•ï¼Œéœ€è¦é‡å¯")
                        
                        if completed > 0:
                            return True, f"æ‰¹æ¬¡æ— è¿›å±•ä½†æœ‰éƒ¨åˆ†å®Œæˆ({completed}/{expected_batches})", output_files, progress_info
                        else:
                            return False, f"è¿ç»­æ‰¹æ¬¡æ— è¿›å±•", [], {}
            
            # 3. å®šæœŸæ£€æŸ¥è¾“å‡ºæ–‡ä»¶
            if current_time - last_output_check >= output_check_interval:
                output_files, progress_info = self.progress_tracker.get_existing_batches(
                    video_path, workflow, expected_batches
                )
                last_output_check = current_time
                
                if output_files:
                    completed = len(output_files)
                    
                    # æ›´æ–°è¿›åº¦
                    if completed > last_output_count:
                        logger.info(f"ğŸ“ˆ è¿›åº¦æ›´æ–°: {completed}/{expected_batches} ({completed/expected_batches*100:.1f}%)")
                        last_output_count = completed
                        no_progress_count = 0
                        
                        # æ›´æ–°è¶…æ—¶ç®¡ç†å™¨
                        self.timeout_manager.update_progress(video_path, completed, expected_batches)
                        
                        # ä¿å­˜è¿›åº¦
                        self.progress_tracker.save_progress(video_path, {
                            'completed_batches': completed,
                            'total_batches': expected_batches,
                            'output_files': [os.path.basename(f) for f in output_files],
                            'last_update': datetime.now().isoformat()
                        })
                    
                    # æ£€æŸ¥æ˜¯å¦å®Œæˆæ‰€æœ‰æ‰¹æ¬¡
                    if completed >= expected_batches:
                        logger.info(f"âœ… æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ: {completed}/{expected_batches}")
                        return True, f"æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ", output_files, progress_info
            
            # 4. å®šæœŸæ£€æŸ¥ä»»åŠ¡çŠ¶æ€
            if current_time - last_status_check >= status_check_interval:
                try:
                    prompt_info = self.client.get_prompt_status(prompt_id)
                    last_status_check = current_time
                    
                    if prompt_info:
                        status = prompt_info.get('status', {})
                        
                        if status.get('completed', False):
                            logger.info(f"âœ… ä»»åŠ¡ {prompt_id[:8]}... çŠ¶æ€: å·²å®Œæˆ")
                            
                            # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
                            time.sleep(2)
                            output_files, progress_info = self.progress_tracker.get_existing_batches(
                                video_path, workflow, expected_batches
                            )
                            
                            if output_files:
                                completed = len(output_files)
                                logger.info(f"âœ… ä»»åŠ¡å®Œæˆï¼Œæ‰¾åˆ° {completed}/{expected_batches} ä¸ªè¾“å‡ºæ–‡ä»¶")
                                return True, f"ä»»åŠ¡å®Œæˆ", output_files, progress_info
                            else:
                                logger.warning("âš ï¸  ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆä½†æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶")
                                
                                # ç»™ç‚¹æ—¶é—´è®©æ–‡ä»¶å†™å…¥
                                time.sleep(5)
                                output_files, progress_info = self.progress_tracker.get_existing_batches(
                                    video_path, workflow, expected_batches
                                )
                                
                                if output_files:
                                    completed = len(output_files)
                                    logger.info(f"âœ… ç­‰å¾…åæ‰¾åˆ° {completed}/{expected_batches} ä¸ªè¾“å‡ºæ–‡ä»¶")
                                    return True, f"ä»»åŠ¡å®Œæˆ(å»¶è¿Ÿå‘ç°)", output_files, progress_info
                                
                                return False, "ä»»åŠ¡å®Œæˆä½†æ— è¾“å‡ºæ–‡ä»¶", [], {}
                        
                        if status.get('error', False):
                            error_msg = status.get('error_message', 'æœªçŸ¥é”™è¯¯')
                            logger.error(f"âŒ ä»»åŠ¡å‡ºé”™: {error_msg}")
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†è¾“å‡º
                            output_files, progress_info = self.progress_tracker.get_existing_batches(
                                video_path, workflow, expected_batches
                            )
                            
                            if output_files:
                                completed = len(output_files)
                                logger.info(f"âš ï¸  ä»»åŠ¡å‡ºé”™ä½†æœ‰éƒ¨åˆ†è¾“å‡º: {completed}/{expected_batches}")
                                return True, f"ä»»åŠ¡å‡ºé”™ä½†æœ‰è¾“å‡º({completed}/{expected_batches})", output_files, progress_info
                            
                            return False, f"ä»»åŠ¡å‡ºé”™: {error_msg}", [], {}
                
                except Exception as e:
                    logger.warning(f"âš ï¸  æ£€æŸ¥ä»»åŠ¡çŠ¶æ€æ—¶å‡ºé”™: {e}")
            
            # 5. æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
            if current_time - last_progress_check >= progress_check_interval:
                try:
                    queue = self.client.get_queue()
                    queue_length = len(queue)
                    last_progress_check = current_time
                    
                    if queue_length == 0:
                        queue_empty_count += 1
                        
                        if queue_empty_count >= max_queue_empty:
                            logger.info(f"ğŸ” é˜Ÿåˆ—è¿ç»­ {max_queue_empty} æ¬¡ä¸ºç©º")
                            
                            # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
                            output_files, progress_info = self.progress_tracker.get_existing_batches(
                                video_path, workflow, expected_batches
                            )
                            
                            if output_files:
                                completed = len(output_files)
                                logger.info(f"ğŸ“Š é˜Ÿåˆ—ä¸ºç©ºï¼Œå·²æœ‰ {completed}/{expected_batches} ä¸ªæ‰¹æ¬¡å®Œæˆ")
                                
                                if completed >= expected_batches * 0.9:  # 90%å®Œæˆ
                                    logger.info(f"âœ… é˜Ÿåˆ—ä¸ºç©ºä¸”å¤§éƒ¨åˆ†æ‰¹æ¬¡å·²å®Œæˆ({completed}/{expected_batches})")
                                    return True, f"é˜Ÿåˆ—ä¸ºç©ºä½†å®Œæˆ{completed}/{expected_batches}", output_files, progress_info
                            
                            logger.warning(f"âš ï¸  é˜Ÿåˆ—æŒç»­ä¸ºç©ºä½†æ— è¾“å‡ºæ–‡ä»¶")
                            queue_empty_count = 0
                    else:
                        queue_empty_count = 0
                        # æ˜¾ç¤ºé˜Ÿåˆ—ä¿¡æ¯
                        if elapsed % 30 == 0:  # æ¯30ç§’æ˜¾ç¤ºä¸€æ¬¡
                            logger.info(f"â³ å·²è¿è¡Œ {int(elapsed)} ç§’ï¼Œé˜Ÿåˆ—: {queue_length} ä¸ªä»»åŠ¡")
                
                except Exception as e:
                    logger.warning(f"âš ï¸  æ£€æŸ¥é˜Ÿåˆ—æ—¶å‡ºé”™: {e}")
            
            # 6. æ˜¾ç¤ºè¿›åº¦
            if elapsed % 30 == 0:  # æ¯30ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                elapsed_mins = int(elapsed // 60)
                elapsed_secs = int(elapsed % 60)
                
                # è·å–å½“å‰è¾“å‡ºæ–‡ä»¶
                output_files, _ = self.progress_tracker.get_existing_batches(
                    video_path, workflow, expected_batches
                )
                completed = len(output_files)
                
                logger.info(f"â³ å·²å¤„ç† {elapsed_mins:02d}:{elapsed_secs:02d}ï¼Œè¿›åº¦: {completed}/{expected_batches} ({completed/expected_batches*100:.1f}%)")
            
            time.sleep(2)
    
    def restart_comfyui(self, reason: str = "æœªçŸ¥åŸå› ") -> bool:
        """é‡å¯ComfyUI"""
        logger.info(f"ğŸ”„ å¼€å§‹é‡å¯ComfyUI (å°è¯• {self.current_retry_count + 1}/{self.max_retries})")
        logger.info(f"   é‡å¯åŸå› : {reason}")
        
        # è®°å½•é‡å¯
        self.record_restart(
            video_path="system",
            reason=reason,
            attempt=self.current_retry_count + 1
        )
        
        # 1. ç»“æŸç°æœ‰è¿›ç¨‹
        logger.info("1. ç»“æŸç°æœ‰ComfyUIè¿›ç¨‹...")
        try:
            if PSUTIL_AVAILABLE:
                killed_processes = self.kill_comfyui_processes()
                logger.info(f"   å·²ç»“æŸ {len(killed_processes)} ä¸ªè¿›ç¨‹")
            else:
                logger.warning("âš ï¸  psutilä¸å¯ç”¨ï¼Œæ— æ³•ç»“æŸè¿›ç¨‹")
        except Exception as e:
            logger.error(f"âŒ ç»“æŸè¿›ç¨‹å¤±è´¥: {e}")
        
        # 2. ç­‰å¾…è¿›ç¨‹ç»“æŸ
        logger.info("2. ç­‰å¾…è¿›ç¨‹ç»“æŸ...")
        time.sleep(3)
        
        # 3. å¯åŠ¨ComfyUI
        logger.info("3. å¯åŠ¨ComfyUI...")
        bat_path = r"F:\AI\ComfyUI_Mie_V7.0\run_nvidia_gpu_fast_fp16_accumulation_hf_mirror.bat"
        
        if not os.path.exists(bat_path):
            logger.error(f"âŒ å¯åŠ¨è„šæœ¬ä¸å­˜åœ¨: {bat_path}")
            return False
        
        try:
            # åœ¨æ–°çš„å‘½ä»¤çª—å£ä¸­å¯åŠ¨
            subprocess.Popen(
                f'start cmd /k "{bat_path}"',
                shell=True,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL
            )
            logger.info(f"ğŸš€ å¯åŠ¨ComfyUI: {bat_path}")
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨ComfyUIå¤±è´¥: {e}")
            return False
        
        # 4. ç­‰å¾…ComfyUIå¯åŠ¨
        logger.info("4. ç­‰å¾…ComfyUIå¯åŠ¨...")
        wait_time = 0
        while wait_time < self.startup_timeout:
            if self.client.is_server_running():
                logger.info(f"âœ… ComfyUIå¯åŠ¨æˆåŠŸï¼Œç­‰å¾…äº† {wait_time} ç§’")
                return True
            
            time.sleep(5)
            wait_time += 5
            logger.debug(f"   ç­‰å¾…ComfyUIå¯åŠ¨... {wait_time}ç§’")
        
        logger.error(f"âŒ ComfyUIå¯åŠ¨è¶…æ—¶ ({self.startup_timeout}ç§’)")
        return False
    
    def kill_comfyui_processes(self) -> List[int]:
        """ç»“æŸComfyUIç›¸å…³è¿›ç¨‹"""
        killed_pids = []
        
        if not PSUTIL_AVAILABLE:
            return killed_pids
        
        try:
            comfyui_path = r"F:\AI\ComfyUI_Mie_V7.0"
            
            for proc in psutil.process_iter(['pid', 'name', 'exe', 'cmdline']):
                try:
                    # æ£€æŸ¥Pythonè¿›ç¨‹
                    if proc.info['name'] and 'python' in proc.info['name'].lower():
                        # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°æ˜¯å¦åŒ…å«ComfyUIè·¯å¾„
                        cmdline = proc.info.get('cmdline', [])
                        if cmdline and any(comfyui_path in str(arg) for arg in cmdline):
                            logger.info(f"   ğŸ”ª ç»“æŸè¿›ç¨‹: {proc.info['pid']} - {proc.info['name']}")
                            proc.terminate()
                            killed_pids.append(proc.info['pid'])
                    
                    # æ£€æŸ¥cmdè¿›ç¨‹
                    elif proc.info['name'] and 'cmd.exe' in proc.info['name'].lower():
                        # æ£€æŸ¥å‘½ä»¤è¡Œæ˜¯å¦åŒ…å«ComfyUIç›¸å…³
                        cmdline = proc.info.get('cmdline', [])
                        if cmdline and any(comfyui_path in str(arg) for arg in cmdline):
                            logger.info(f"   ğŸ”ª ç»“æŸè¿›ç¨‹: {proc.info['pid']} - {proc.info['name']}")
                            proc.terminate()
                            killed_pids.append(proc.info['pid'])
                
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    continue
            
            # ç­‰å¾…è¿›ç¨‹ç»“æŸ
            time.sleep(2)
            
            # å¼ºåˆ¶ç»“æŸæœªé€€å‡ºçš„è¿›ç¨‹
            for pid in killed_pids[:]:
                try:
                    proc = psutil.Process(pid)
                    if proc.is_running():
                        logger.info(f"   ğŸ”« å¼ºåˆ¶ç»“æŸè¿›ç¨‹ {pid}")
                        proc.kill()
                except:
                    pass
            
            # æ¸…ç†GPUæ˜¾å­˜
            if TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                logger.info("âœ… GPUæ˜¾å­˜å·²æ¸…ç†")
            
        except Exception as e:
            logger.error(f"âŒ ç»“æŸè¿›ç¨‹æ—¶å‡ºé”™: {e}")
        
        return killed_pids
    
    def process_single_video(
        self,
        workflow_template: Dict,
        video_path: str,
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        frames_per_batch: int = 201,
        gpu_device: str = "auto"
    ) -> Tuple[bool, str, int, List[str]]:
        """å¤„ç†å•ä¸ªè§†é¢‘ - æ™ºèƒ½è¶…æ—¶ç‰ˆæœ¬"""
        video_name = os.path.basename(video_path)
        retry_count = 0
        success = False
        status_msg = "åˆå§‹çŠ¶æ€"
        output_files = []
        
        # ç¡®ä¿ComfyUIåœ¨è¿è¡Œ
        if not self.ensure_comfyui_running():
            return False, "ComfyUIæœªè¿è¡Œ", 0, []
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = get_video_info(video_path)
        total_frames = video_info.get('total_frames', 0)
        
        if total_frames <= 0:
            logger.warning(f"âš ï¸  æ— æ³•è·å–è§†é¢‘ '{video_name}' çš„æ€»å¸§æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            total_frames = 10000
        
        # è®¡ç®—é¢„æœŸæ‰¹æ¬¡æ•°
        if frames_per_batch <= 0:
            frames_per_batch = 125
        total_batches = (total_frames + frames_per_batch - 1) // frames_per_batch
        logger.info(f"ğŸ“Š è§†é¢‘ '{video_name}' éœ€è¦ {total_batches} ä¸ªæ‰¹æ¬¡ (æ€»å¸§æ•°: {total_frames}, æ¯æ‰¹: {frames_per_batch})")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¾“å‡ºæ–‡ä»¶
        logger.info("ğŸ” æ£€æŸ¥æ˜¯å¦å·²æœ‰è¾“å‡ºæ–‡ä»¶...")
        temp_workflow = self.update_workflow_parameters(
            workflow_template, video_path, output_prefix
        )
        
        # è·å–ç°æœ‰è¾“å‡ºæ–‡ä»¶
        existing_files, progress_info = self.progress_tracker.get_existing_batches(
            video_path, temp_workflow, total_batches
        )
        
        completed_batches = len(existing_files)
        if completed_batches >= total_batches:
            logger.info(f"âœ… è§†é¢‘ '{video_name}' å·²æœ‰å®Œæ•´è¾“å‡ºæ–‡ä»¶ ({completed_batches}/{total_batches})ï¼Œè·³è¿‡å¤„ç†")
            return True, f"å·²æœ‰å®Œæ•´è¾“å‡ºæ–‡ä»¶", 0, existing_files
        elif completed_batches > 0:
            logger.info(f"ğŸ“Š è§†é¢‘ '{video_name}' å·²æœ‰ {completed_batches}/{total_batches} ä¸ªæ‰¹æ¬¡å®Œæˆ")
            
            # å¦‚æœå¤§éƒ¨åˆ†å·²å®Œæˆï¼Œä»ç°æœ‰æ–‡ä»¶å¼€å§‹
            if completed_batches >= total_batches * 0.8:  # 80%å®Œæˆ
                logger.info(f"âœ… è§†é¢‘ '{video_name}' å·²æœ‰ {completed_batches}/{total_batches} å®Œæˆï¼Œè·³è¿‡å¤„ç†")
                return True, f"å¤§éƒ¨åˆ†å·²å¤„ç†({completed_batches}/{total_batches})", 0, existing_files
        
        # å¼€å§‹å¤„ç†
        self.timeout_manager.start_video_timer(video_path)
        
        while retry_count < self.max_retries and not success:
            retry_count += 1
            logger.info(f"ğŸ”„ å°è¯• {retry_count}/{self.max_retries}")
            
            try:
                # æ¸…é™¤å†å²è®°å½•
                logger.debug("æ¸…é™¤ComfyUIå†å²è®°å½•...")
                self.client.clear_history()
                
                # æ›´æ–°å·¥ä½œæµå‚æ•°
                workflow = self.update_workflow_parameters(
                    workflow_template,
                    video_path,
                    output_prefix,
                    scale=scale,
                    tile_size=tile_size,
                    tile_overlap=tile_overlap,
                    total_frames=total_frames,
                    frames_per_batch=frames_per_batch,
                    gpu_device=gpu_device
                )
                
                # æäº¤ä»»åŠ¡
                logger.info(f"âœ… ä»»åŠ¡å·²æäº¤: {video_name}")
                prompt_id = self.client.submit_prompt(workflow)
                
                if not prompt_id:
                    status_msg = "æäº¤ä»»åŠ¡å¤±è´¥"
                    logger.error(f"âŒ {status_msg}")
                    time.sleep(self.restart_delay)
                    continue
                
                logger.info(f"   ä»»åŠ¡ID: {prompt_id}")
                
                # å¼€å§‹æ‰¹æ¬¡è®¡æ—¶
                self.timeout_manager.start_batch_timer(video_path, completed_batches + 1)
                
                # æ™ºèƒ½ç­‰å¾…ä»»åŠ¡å®Œæˆ
                task_success, task_status, output_files, progress_info = self.wait_for_task_completion_smart(
                    prompt_id=prompt_id,
                    video_path=video_path,
                    workflow=workflow,
                    total_frames=total_frames,
                    frames_per_batch=frames_per_batch,
                    total_batches=total_batches
                )
                
                if task_success:
                    success = True
                    status_msg = task_status
                    
                    # è·å–æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
                    final_files, _ = self.progress_tracker.get_existing_batches(
                        video_path, workflow, total_batches
                    )
                    
                    if final_files:
                        completed = len(final_files)
                        logger.info(f"âœ… è§†é¢‘å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {completed}/{total_batches} ä¸ªè¾“å‡ºæ–‡ä»¶")
                        
                        for i, file_path in enumerate(final_files[:3]):
                            if os.path.exists(file_path):
                                file_size = os.path.getsize(file_path)
                                file_size_mb = file_size / (1024 * 1024)
                                logger.info(f"  {i+1}. {os.path.basename(file_path)} ({file_size_mb:.1f}MB)")
                            else:
                                logger.warning(f"  {i+1}. {os.path.basename(file_path)} (æ–‡ä»¶ä¸å­˜åœ¨!)")
                        
                        if len(final_files) > 3:
                            logger.info(f"  ... è¿˜æœ‰ {len(final_files)-3} ä¸ªæ–‡ä»¶")
                        
                        output_files = final_files
                    else:
                        logger.warning("âš ï¸  ä»»åŠ¡æˆåŠŸä½†æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶")
                        success = False
                        status_msg = "ä»»åŠ¡æˆåŠŸä½†æ— è¾“å‡ºæ–‡ä»¶"
                    
                    break
                
                else:
                    status_msg = task_status
                    logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {status_msg}")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†è¾“å‡ºæ–‡ä»¶
                    partial_files, _ = self.progress_tracker.get_existing_batches(
                        video_path, workflow, total_batches
                    )
                    
                    if partial_files:
                        completed = len(partial_files)
                        logger.info(f"ğŸ“Š æ‰¾åˆ° {completed}/{total_batches} ä¸ªéƒ¨åˆ†è¾“å‡ºæ–‡ä»¶")
                        
                        # åˆ¤æ–­æ˜¯å¦éœ€è¦é‡å¯
                        if completed > 0 and self.timeout_manager.should_restart(video_path):
                            logger.warning(f"âš ï¸  éœ€è¦é‡å¯ï¼Œå½“å‰å®Œæˆ {completed}/{total_batches}")
                            
                            if completed >= total_batches * 0.5:  # 50%å®Œæˆ
                                logger.info(f"âœ… è¶…è¿‡50%å®Œæˆï¼Œä¿å­˜è¿›åº¦åé‡å¯")
                                self.progress_tracker.save_progress(video_path, {
                                    'completed_batches': completed,
                                    'total_batches': total_batches,
                                    'output_files': [os.path.basename(f) for f in partial_files],
                                    'status': 'partial_complete',
                                    'last_update': datetime.now().isoformat()
                                })
                            
                            # æ‰§è¡Œé‡å¯
                            restart_success = self.restart_comfyui(f"æ‰¹æ¬¡å¤„ç†è¶…æ—¶: {status_msg}")
                            
                            if restart_success:
                                logger.info("ğŸ”„ é‡å¯åç»§ç»­å¤„ç†...")
                                time.sleep(self.restart_delay)
                                continue
                    
                    # è®°å½•é‡å¯
                    self.record_restart(
                        video_path=video_path,
                        reason=status_msg,
                        attempt=retry_count
                    )
                    
                    if retry_count < self.max_retries:
                        logger.info(f"ğŸ”„ å‡†å¤‡é‡è¯• ({retry_count}/{self.max_retries})...")
                        time.sleep(self.restart_delay)
                    else:
                        logger.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    
            except Exception as e:
                status_msg = f"å¤„ç†å¼‚å¸¸: {str(e)}"
                logger.error(f"âŒ {status_msg}", exc_info=True)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†è¾“å‡º
                partial_files, _ = self.progress_tracker.get_existing_batches(
                    video_path, temp_workflow, total_batches
                )
                
                if partial_files:
                    completed = len(partial_files)
                    logger.info(f"âš ï¸  å¼‚å¸¸ä½†å·²æœ‰ {completed}/{total_batches} ä¸ªè¾“å‡ºæ–‡ä»¶")
                
                # è®°å½•é‡å¯
                self.record_restart(
                    video_path=video_path,
                    reason=status_msg,
                    attempt=retry_count
                )
                
                if retry_count < self.max_retries:
                    logger.info(f"ğŸ”„ å¼‚å¸¸åå‡†å¤‡é‡è¯• ({retry_count}/{self.max_retries})...")
                    time.sleep(self.restart_delay)
                else:
                    logger.error("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
        
        # æ¸…ç†è¿›åº¦
        if success:
            self.progress_tracker.delete_progress(video_path)
        
        return success, status_msg, retry_count, output_files
    
    def record_restart(self, video_path: str, reason: str, attempt: int = 1):
        """è®°å½•é‡å¯äº‹ä»¶"""
        restart_entry = {
            'timestamp': datetime.now().isoformat(),
            'video_path': video_path,
            'video_name': os.path.basename(video_path),
            'reason': reason,
            'attempt': attempt
        }
        self.restart_history.append(restart_entry)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open('restart_history.json', 'w', encoding='utf-8') as f:
                json.dump(self.restart_history, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… é‡å¯å†å²å·²ä¿å­˜: restart_history.json")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜é‡å¯å†å²å¤±è´¥: {e}")
    
    def move_to_done_directory(self, video_path: str) -> Optional[str]:
        """ç§»åŠ¨æ–‡ä»¶åˆ°doneç›®å½•"""
        try:
            if not os.path.exists(video_path):
                logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                return None
            
            # è·å–åŸæ–‡ä»¶æ‰€åœ¨ç›®å½•
            original_dir = os.path.dirname(video_path)
            file_name = os.path.basename(video_path)
            
            # åˆ›å»ºdoneç›®å½•
            done_dir = os.path.join(original_dir, "done")
            os.makedirs(done_dir, exist_ok=True)
            
            # ç”Ÿæˆç›®æ ‡è·¯å¾„
            done_path = os.path.join(done_dir, file_name)
            
            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
            if os.path.exists(done_path):
                base_name, ext = os.path.splitext(file_name)
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                new_name = f"{base_name}_{timestamp}{ext}"
                done_path = os.path.join(done_dir, new_name)
            
            # ç§»åŠ¨æ–‡ä»¶
            shutil.move(video_path, done_path)
            logger.info(f"âœ… æ–‡ä»¶å·²ç§»åŠ¨åˆ°doneç›®å½•")
            
            return done_path
            
        except Exception as e:
            logger.error(f"âŒ ç§»åŠ¨æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def batch_process(
        self,
        workflow_template_path: str,
        video_files: List[str],
        output_prefix_base: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        frames_per_batch: int = 201,
        gpu_device: str = "auto",
        move_to_done: bool = True,
        cleanup_after_each: bool = True
    ) -> Dict[str, Tuple[bool, str, int, List[str]]]:
        """æ‰¹é‡å¤„ç†è§†é¢‘"""
        logger.info(f"\n{'='*60}")
        logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(video_files)} ä¸ªè§†é¢‘")
        logger.info(f"âš™ï¸  å‚æ•°: scale={scale}, tile_size={tile_size}, tile_overlap={tile_overlap}")
        logger.info(f"ğŸ® GPUè®¾å¤‡: {gpu_device}")
        logger.info(f"â±ï¸  æ‰¹æ¬¡è¶…æ—¶: {self.timeout_per_batch}ç§’")
        logger.info(f"â±ï¸  è§†é¢‘æ€»è¶…æ—¶: {self.timeout_per_video}ç§’")
        logger.info(f"ğŸ”„ æœ€å¤§é‡è¯•: {self.max_retries}æ¬¡")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {self.progress_tracker.output_dir}")
        logger.info(f"{'='*60}")
        
        # åŠ è½½å·¥ä½œæµæ¨¡æ¿
        try:
            workflow_template = self.load_workflow_template(workflow_template_path)
            logger.info(f"âœ… åŠ è½½å·¥ä½œæµæ¨¡æ¿: {workflow_template_path}")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å·¥ä½œæµæ¨¡æ¿å¤±è´¥: {e}")
            return {}
        
        # ç¡®ä¿ComfyUIåœ¨è¿è¡Œ
        if not self.ensure_comfyui_running():
            logger.error("âŒ ComfyUIæœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨ComfyUI")
            return {}
        
        results = {}
        processed_count = 0
        failed_count = 0
        
        for i, video_path in enumerate(video_files, 1):
            video_name = os.path.basename(video_path)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_path):
                logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                self.failed_files[video_path] = {
                    'status': 'failed',
                    'message': 'æ–‡ä»¶ä¸å­˜åœ¨',
                    'timestamp': datetime.now().isoformat()
                }
                failed_count += 1
                continue
            
            logger.info(f"\nğŸ“Š [{i}/{len(video_files)}] å¤„ç†: {video_name}")
            
            # è®¾ç½®è¾“å‡ºå‰ç¼€
            output_prefix = None
            if output_prefix_base:
                base_name = os.path.splitext(video_name)[0]
                output_prefix = f"{output_prefix_base}_{base_name}"
            
            # å¤„ç†å•ä¸ªè§†é¢‘
            success, status_msg, retry_count, output_files = self.process_single_video(
                workflow_template=workflow_template,
                video_path=video_path,
                output_prefix=output_prefix,
                scale=scale,
                tile_size=tile_size,
                tile_overlap=tile_overlap,
                frames_per_batch=frames_per_batch,
                gpu_device=gpu_device
            )
            
            # è®°å½•ç»“æœ
            results[video_path] = (success, status_msg, retry_count, output_files)
            
            if success:
                processed_count += 1
                self.processed_files[video_path] = {
                    'status': 'success',
                    'message': status_msg,
                    'retries': retry_count,
                    'output_files': [os.path.basename(f) for f in output_files] if output_files else [],
                    'timestamp': datetime.now().isoformat()
                }
                
                # ç§»åŠ¨æ–‡ä»¶åˆ°doneç›®å½•
                if move_to_done and "è·³è¿‡" not in status_msg:  # ä¸ç§»åŠ¨è·³è¿‡çš„æ–‡ä»¶
                    moved_path = self.move_to_done_directory(video_path)
                    if not moved_path:
                        logger.warning(f"âš ï¸  æ–‡ä»¶ç§»åŠ¨å¤±è´¥: {video_name}")
                
                # é‡ç½®é‡è¯•è®¡æ•°
                self.current_retry_count = 0
                
            else:
                failed_count += 1
                self.failed_files[video_path] = {
                    'status': 'failed',
                    'message': status_msg,
                    'retries': retry_count,
                    'output_files': [os.path.basename(f) for f in output_files] if output_files else [],
                    'timestamp': datetime.now().isoformat()
                }
                logger.error(f"âŒ å¤„ç†å¤±è´¥: {status_msg}")
            
            # æ¸…ç†ç¼“å­˜
            if cleanup_after_each and success:
                self.clear_cache()
            
            # çŸ­æš‚é—´éš”
            if i < len(video_files):
                wait_time = 2
                logger.info(f"â±ï¸  ç­‰å¾… {wait_time} ç§’...")
                time.sleep(wait_time)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info(f"\n{'='*60}")
        logger.info("æ‰¹é‡å¤„ç†å®Œæˆ")
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"  âœ… æˆåŠŸ: {processed_count}/{len(video_files)}")
        logger.info(f"  âŒ å¤±è´¥: {failed_count}/{len(video_files)}")
        
        if processed_count > 0:
            logger.info(f"âœ… æˆåŠŸæ–‡ä»¶åˆ—è¡¨:")
            for i, (video_path, (success, status, retries, files)) in enumerate(results.items()):
                if success and i < 10:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    logger.info(f"  {i+1}. {os.path.basename(video_path)} - {status} (é‡è¯•: {retries})")
            if processed_count > 10:
                logger.info(f"  ... è¿˜æœ‰ {processed_count-10} ä¸ªæˆåŠŸæ–‡ä»¶")
        
        if failed_count > 0:
            logger.info(f"âŒ å¤±è´¥æ–‡ä»¶åˆ—è¡¨:")
            for i, (video_path, (success, status, retries, files)) in enumerate(results.items()):
                if not success and i < 10:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    logger.info(f"  {i+1}. {os.path.basename(video_path)} - {status} (é‡è¯•: {retries})")
            if failed_count > 10:
                logger.info(f"  ... è¿˜æœ‰ {failed_count-10} ä¸ªå¤±è´¥æ–‡ä»¶")
        
        return results
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†èµ„æº...")
        try:
            self.client.session.close()
        except:
            pass
        logger.info("âœ… æ¸…ç†å®Œæˆ")

def collect_video_files(input_path: str, pattern: str = '*.mp4') -> List[str]:
    """æ”¶é›†è§†é¢‘æ–‡ä»¶"""
    video_files = []
    
    if os.path.isfile(input_path):
        if input_path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv')):
            video_files.append(input_path)
            logger.info(f"âœ… æ·»åŠ å•ä¸ªæ–‡ä»¶: {input_path}")
    elif os.path.isdir(input_path):
        # æœç´¢è§†é¢‘æ–‡ä»¶
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', '.MP4', '.MOV', '.AVI', '.MKV']
        
        for ext in video_extensions:
            search_pattern = os.path.join(input_path, f"*{ext}")
            found_files = glob(search_pattern)
            video_files.extend(found_files)
        
        # å»é‡å¹¶æ’åº
        video_files = sorted(list(set(video_files)))
        
        if not video_files:
            logger.error(f"âŒ ç›®å½• {input_path} ä¸­æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        else:
            logger.info(f"âœ… ä»ç›®å½• {input_path} æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    else:
        logger.error(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    return video_files

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· - æ™ºèƒ½è¶…æ—¶ç‰ˆæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘
  python batch_processor_smart_timeout.py --input ./videos --batch-timeout 300 --video-timeout 3600
  
  # è‡ªå®šä¹‰æ‰¹æ¬¡å¤§å°
  python batch_processor_smart_timeout.py --input ./videos --frames-per-batch 125
  
  # æŒ‡å®šGPUè®¾å¤‡
  python batch_processor_smart_timeout.py --input ./videos --gpu 0

ä¸»è¦æ”¹è¿›:
  1. æ™ºèƒ½è¶…æ—¶: åŸºäºæ‰¹æ¬¡è€Œéæ•´ä¸ªè§†é¢‘çš„è¶…æ—¶åˆ¤æ–­
  2. è¿›åº¦è·Ÿè¸ª: å®æ—¶è·Ÿè¸ªæ¯ä¸ªæ‰¹æ¬¡çš„å®Œæˆæƒ…å†µ
  3. æ–­ç‚¹ç»­ä¼ : é‡å¯åä»å·²æœ‰è¿›åº¦ç»§ç»­å¤„ç†
  4. éƒ¨åˆ†å®Œæˆ: å³ä½¿æœªå®Œæˆæ‰€æœ‰æ‰¹æ¬¡ï¼Œä¹Ÿèƒ½ä¿å­˜å·²å¤„ç†çš„éƒ¨åˆ†
        """
    )
    
    # è¾“å…¥å‚æ•°
    parser.add_argument('--template', type=str, default='flashvsr_tile-no.json',
                       help='å·¥ä½œæµæ¨¡æ¿ JSON æ–‡ä»¶è·¯å¾„ (é»˜è®¤: flashvsr_tile-no.json)')
    parser.add_argument('--input', type=str, required=True,
                       help='è¾“å…¥è·¯å¾„ï¼ˆè§†é¢‘æ–‡ä»¶æˆ–ç›®å½•ï¼‰')
    parser.add_argument('--pattern', type=str, default='*.mp4',
                       help='è§†é¢‘æ–‡ä»¶åŒ¹é…æ¨¡å¼ (é»˜è®¤: *.mp4)')
    
    # å¤„ç†å‚æ•°
    parser.add_argument('--scale', type=float, default=4.0,
                       help='æ”¾å¤§å€æ•° (é»˜è®¤: 4.0)')
    parser.add_argument('--tile-size', type=int, default=256,
                       help='åˆ†å—å¤§å° (é»˜è®¤: 256)')
    parser.add_argument('--tile-overlap', type=int, default=24,
                       help='åˆ†å—é‡å åƒç´  (é»˜è®¤: 24)')
    parser.add_argument('--frames-per-batch', type=int, default=125,
                       help='æ¯æ‰¹å¤„ç†çš„å¸§æ•° (é»˜è®¤: 125)')
    parser.add_argument('--gpu', type=str, default='auto',
                       help='GPUè®¾å¤‡é€‰æ‹© (é»˜è®¤: auto)')
    
    # è¶…æ—¶å‚æ•°
    parser.add_argument('--batch-timeout', type=int, default=300,
                       help='æ¯ä¸ªæ‰¹æ¬¡çš„æœ€å¤§å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 300)')
    parser.add_argument('--video-timeout', type=int, default=3600,
                       help='æ•´ä¸ªè§†é¢‘çš„æœ€å¤§å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 3600)')
    parser.add_argument('--max-retries', type=int, default=3,
                       help='æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)')
    parser.add_argument('--restart-delay', type=int, default=5,
                       help='é‡å¯åç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 5)')
    
    # æ–‡ä»¶ç®¡ç†
    parser.add_argument('--no-move', action='store_true',
                       help='ä¸å°†å¤„ç†å®Œæˆçš„æ–‡ä»¶ç§»åŠ¨åˆ°doneç›®å½•')
    parser.add_argument('--no-cleanup', action='store_true',
                       help='ä¸æ¸…ç†ç¼“å­˜')
    
    # ç³»ç»Ÿå‚æ•°
    parser.add_argument('--server', type=str, default='http://127.0.0.1:8188',
                       help='ComfyUI æœåŠ¡å™¨åœ°å€ (é»˜è®¤: http://127.0.0.1:8188)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥pymediainfoæ˜¯å¦å®‰è£…
    if not PYMEDIAINFO_AVAILABLE:
        logger.warning("âš ï¸  pymediainfoæœªå®‰è£…ï¼Œå°†æ— æ³•è·å–è§†é¢‘çœŸå®å¸§æ•°")
        logger.info("è¯·è¿è¡Œ: pip install pymediainfo")
    
    # æ”¶é›†è§†é¢‘æ–‡ä»¶
    video_files = collect_video_files(args.input, args.pattern)
    
    if not video_files:
        logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        return
    
    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
    logger.info(f"\nğŸ“ æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶:")
    for i, vf in enumerate(video_files[:5], 1):
        logger.info(f"  {i}. {os.path.basename(vf)}")
    if len(video_files) > 5:
        logger.info(f"  ... è¿˜æœ‰ {len(video_files)-5} ä¸ªæ–‡ä»¶")
    
    # æ˜¾ç¤ºå¤„ç†å‚æ•°
    logger.info(f"\nâš™ï¸  å¤„ç†å‚æ•°:")
    logger.info(f"  scale: {args.scale}")
    logger.info(f"  tile_size: {args.tile_size}")
    logger.info(f"  tile_overlap: {args.tile_overlap}")
    logger.info(f"  frames_per_batch: {args.frames_per_batch}")
    logger.info(f"  GPU: {args.gpu}")
    logger.info(f"  æ‰¹æ¬¡è¶…æ—¶: {args.batch_timeout}ç§’")
    logger.info(f"  è§†é¢‘æ€»è¶…æ—¶: {args.video_timeout}ç§’")
    logger.info(f"  æœ€å¤§é‡è¯•: {args.max_retries}æ¬¡")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = ComfyUI_FlashVSR_BatchProcessor(
        comfyui_url=args.server,
        timeout_per_batch=args.batch_timeout,
        timeout_per_video=args.video_timeout,
        max_retries=args.max_retries,
        restart_delay=args.restart_delay
    )
    
    # æ‰¹é‡å¤„ç†
    start_time = time.time()
    
    try:
        results = processor.batch_process(
            workflow_template_path=args.template,
            video_files=video_files,
            output_prefix_base=None,
            scale=args.scale,
            tile_size=args.tile_size,
            tile_overlap=args.tile_overlap,
            frames_per_batch=args.frames_per_batch,
            gpu_device=args.gpu,
            move_to_done=not args.no_move,
            cleanup_after_each=not args.no_cleanup
        )
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = time.time() - start_time
        hours, remainder = divmod(total_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        
        logger.info(f"\nâ±ï¸  æ€»è€—æ—¶: {int(hours)}æ—¶{int(minutes)}åˆ†{seconds:.0f}ç§’")
        
    except KeyboardInterrupt:
        logger.info("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­å¤„ç†")
        logger.info("å·²ä¿å­˜å½“å‰è¿›åº¦")
    except Exception as e:
        logger.error(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
