"""
ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· - ä¿®å¤ç‰ˆ
ä¿®å¤æ‰¹æ¬¡æ£€æµ‹å’Œæ–‡ä»¶éªŒè¯é—®é¢˜
"""

import os
import sys
import json
import time
import random
import string
import logging
import requests
import subprocess
import datetime
import shutil
import gc
import atexit
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Set
from glob import glob
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('comfyui_batch_processor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å¯é€‰ä¾èµ–
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    logger.warning("âš ï¸  torchä¸å¯ç”¨ï¼ŒGPUæ¸…ç†åŠŸèƒ½å°†å—é™")

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    logger.warning("âš ï¸  psutilä¸å¯ç”¨ï¼Œè¿›ç¨‹ç®¡ç†åŠŸèƒ½å°†å—é™")

try:
    from pymediainfo import MediaInfo
    PYMEDIAINFO_AVAILABLE = True
except ImportError:
    PYMEDIAINFO_AVAILABLE = False
    logger.warning("âš ï¸  pymediainfoä¸å¯ç”¨ï¼Œè§†é¢‘å¸§æ•°æ£€æµ‹å°†ä½¿ç”¨ä¼°è®¡å€¼")

def get_video_info(video_path: str) -> Dict[str, Any]:
    """è·å–è§†é¢‘ä¿¡æ¯"""
    video_info = {
        'total_frames': 0,
        'fps': 0.0,
        'duration': 0.0,
        'resolution': 'æœªçŸ¥',
        'file_size': os.path.getsize(video_path)
    }
    
    if PYMEDIAINFO_AVAILABLE:
        try:
            media_info = MediaInfo.parse(video_path)
            for track in media_info.tracks:
                if track.track_type == 'Video':
                    video_info['total_frames'] = int(track.frame_count) if hasattr(track, 'frame_count') else 0
                    video_info['fps'] = float(track.frame_rate) if hasattr(track, 'frame_rate') else 0.0
                    video_info['duration'] = float(track.duration) / 1000.0 if hasattr(track, 'duration') else 0.0
                    video_info['resolution'] = f"{track.width}x{track.height}" if hasattr(track, 'width') and hasattr(track, 'height') else 'æœªçŸ¥'
                    break
        except Exception as e:
            logger.warning(f"âš ï¸  æ— æ³•é€šè¿‡pymediainfoè·å–è§†é¢‘ä¿¡æ¯: {e}")
    
    # å¦‚æœæ— æ³•è·å–å¸§æ•°ï¼Œå°è¯•é€šè¿‡æ—¶é•¿å’Œå¸§ç‡ä¼°ç®—
    if video_info['total_frames'] <= 0 and video_info['duration'] > 0 and video_info['fps'] > 0:
        video_info['total_frames'] = int(video_info['duration'] * video_info['fps'])
        logger.info(f"ğŸ“Š é€šè¿‡æ—¶é•¿å’Œå¸§ç‡ä¼°ç®—æ€»å¸§æ•°: {video_info['total_frames']}")
    
    return video_info

class ComfyUI_Client:
    """ComfyUI APIå®¢æˆ·ç«¯"""
    
    def __init__(self, server_address: str = "http://127.0.0.1:8188"):
        self.server_address = server_address
        self.session = requests.Session()
        self.client_id = self.generate_client_id()
    
    def generate_client_id(self) -> str:
        """ç”Ÿæˆå®¢æˆ·ç«¯ID"""
        random_str = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))
        return f"batch_processor_{random_str}"
    
    def is_server_running(self) -> bool:
        """æ£€æŸ¥ComfyUIæœåŠ¡å™¨æ˜¯å¦è¿è¡Œ"""
        try:
            response = self.session.get(f"{self.server_address}/system_stats", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def get_queue(self) -> List[Dict]:
        """è·å–é˜Ÿåˆ—ä¿¡æ¯"""
        try:
            response = self.session.get(f"{self.server_address}/queue", timeout=10)
            if response.status_code == 200:
                queue_data = response.json()
                return queue_data.get('queue_running', []) + queue_data.get('queue_pending', [])
        except Exception as e:
            logger.debug(f"è·å–é˜Ÿåˆ—å¤±è´¥: {e}")
        return []
    
    def is_queue_empty(self) -> bool:
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦ä¸ºç©º"""
        return len(self.get_queue()) == 0
    
    def get_history(self, prompt_id: str = None) -> Dict:
        """è·å–å†å²è®°å½•"""
        try:
            response = self.session.get(f"{self.server_address}/history", timeout=10)
            if response.status_code == 200:
                history_data = response.json()
                if prompt_id:
                    return history_data.get(prompt_id, {})
                return history_data
        except Exception as e:
            logger.debug(f"è·å–å†å²è®°å½•å¤±è´¥: {e}")
        return {}
    
    def get_prompt_status(self, prompt_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        try:
            # é¦–å…ˆæ£€æŸ¥å†å²è®°å½•
            history = self.get_history()
            if prompt_id in history:
                return {
                    'status': {
                        'completed': True,
                        'error': False
                    },
                    'outputs': history[prompt_id].get('outputs', {})
                }
            
            # æ£€æŸ¥é˜Ÿåˆ—
            queue = self.get_queue()
            for item in queue:
                if item.get('prompt_id') == prompt_id:
                    return {
                        'status': {
                            'completed': False,
                            'error': False
                        },
                        'outputs': {}
                    }
            
            # å¦‚æœä¸åœ¨å†å²å’Œé˜Ÿåˆ—ä¸­ï¼Œå¯èƒ½ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²å¤±è´¥
            return {
                'status': {
                    'completed': False,
                    'error': True,
                    'error_message': 'ä»»åŠ¡ä¸åœ¨é˜Ÿåˆ—æˆ–å†å²ä¸­'
                }
            }
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
            return None
    
    def is_prompt_completed(self, prompt_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ"""
        prompt_info = self.get_prompt_status(prompt_id)
        if prompt_info and 'status' in prompt_info:
            return prompt_info['status'].get('completed', False)
        return False
    
    def submit_prompt(self, workflow: Dict) -> Optional[str]:
        """æäº¤ä»»åŠ¡åˆ°ComfyUI"""
        try:
            # æ¸…é™¤å†å²è®°å½•
            self.clear_history()
            
            # æäº¤ä»»åŠ¡
            response = self.session.post(
                f"{self.server_address}/prompt",
                json={"prompt": workflow, "client_id": self.client_id},
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                prompt_id = data.get('prompt_id')
                logger.debug(f"ä»»åŠ¡æäº¤æˆåŠŸï¼ŒID: {prompt_id}")
                return prompt_id
            else:
                logger.error(f"æäº¤ä»»åŠ¡å¤±è´¥: {response.status_code} - {response.text}")
                return None
                
        except Exception as e:
            logger.error(f"æäº¤ä»»åŠ¡å¼‚å¸¸: {e}")
            return None
    
    def clear_history(self) -> bool:
        """æ¸…é™¤å†å²è®°å½•"""
        try:
            response = self.session.post(f"{self.server_address}/history", json={"clear": True})
            return response.status_code == 200
        except:
            return False
    
    def clear_queue(self) -> bool:
        """æ¸…é™¤é˜Ÿåˆ—"""
        try:
            response = self.session.post(f"{self.server_address}/queue", json={"clear": True})
            return response.status_code == 200
        except:
            return False
    
    def wait_for_prompt_completion(self, prompt_id: str, timeout: int = 3600, poll_interval: int = 5) -> bool:
        """ç­‰å¾…ä»»åŠ¡å®Œæˆ"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            if self.is_prompt_completed(prompt_id):
                return True
            
            # æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
            if self.is_queue_empty():
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œä½†ä»»åŠ¡å¯èƒ½ä»åœ¨å¤„ç†ä¸­
                time.sleep(1)
                continue
            
            time.sleep(poll_interval)
            
            # è¾“å‡ºè¿›åº¦
            elapsed = int(time.time() - start_time)
            if elapsed % 30 == 0:  # æ¯30ç§’è¾“å‡ºä¸€æ¬¡çŠ¶æ€
                logger.info(f"â³ ä»»åŠ¡ {prompt_id[:8]}... å·²è¿è¡Œ {elapsed} ç§’")
        
        logger.warning(f"âš ï¸  ä»»åŠ¡ {prompt_id[:8]}... è¶…æ—¶ ({timeout}ç§’)")
        return False

class BatchOutputTracker:
    """æ‰¹æ¬¡è¾“å‡ºè·Ÿè¸ªå™¨ - ä¿®å¤ç‰ˆ"""
    
    def __init__(self, output_dir: str = None):
        """
        åˆå§‹åŒ–æ‰¹å¤„ç†çŠ¶æ€è·Ÿè¸ªå™¨
        ä¿®å¤ï¼šå‡†ç¡®æ£€æµ‹æ‰¹æ¬¡è¾“å‡ºæ–‡ä»¶
        """
        self.output_dir = output_dir or self.get_default_output_dir()
        
    def get_default_output_dir(self) -> str:
        """è·å–é»˜è®¤è¾“å‡ºç›®å½•"""
        comfyui_output = r"F:\AI\ComfyUI_Mie_V7.0\ComfyUI\output"
        if os.path.exists(comfyui_output):
            return comfyui_output
        
        default_output = os.path.join(os.getcwd(), "output")
        os.makedirs(default_output, exist_ok=True)
        return default_output
    
    def extract_output_pattern_from_workflow(self, workflow: Dict) -> str:
        """ä»å·¥ä½œæµä¸­æå–è¾“å‡ºæ–‡ä»¶åæ¨¡å¼"""
        output_prefix = ""
        file_format = "mov"
        
        for node_id, node_data in workflow.items():
            if node_data.get("class_type") == "VHS_VideoCombine":
                inputs = node_data.get("inputs", {})
                output_prefix = inputs.get("filename_prefix", "")
                # ä»æ ¼å¼é€‰é¡¹è·å–æ–‡ä»¶æ ¼å¼
                format_opt = inputs.get("format", "mov")
                if format_opt in ["mov", "mp4", "webm", "avi"]:
                    file_format = format_opt
                break
        
        if not output_prefix:
            # å¦‚æœæ²¡æœ‰è®¾ç½®å‰ç¼€ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼
            return f"ComfyUI_*.{file_format}"
        
        # ComfyUIçš„è¾“å‡ºæ ¼å¼é€šå¸¸æ˜¯: prefix_XXXX_YYYYYYY.format
        # å…¶ä¸­ XXXX æ˜¯æ‰¹æ¬¡å·ï¼ŒYYYYYYY æ˜¯éšæœºå­—ç¬¦ä¸²
        return f"{output_prefix}_*.{file_format}"
    
    def get_output_files(self, video_path: str, workflow: Dict) -> List[str]:
        """è·å–å®é™…ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶åˆ—è¡¨"""
        # ä»å·¥ä½œæµä¸­æå–è¾“å‡ºæ¨¡å¼
        pattern = self.extract_output_pattern_from_workflow(workflow)
        
        # åœ¨è¾“å‡ºç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
        all_files = []
        
        # æœç´¢åŒ¹é…çš„æ–‡ä»¶
        search_pattern = os.path.join(self.output_dir, pattern)
        logger.debug(f"æœç´¢è¾“å‡ºæ–‡ä»¶æ¨¡å¼: {search_pattern}")
        
        for ext in ['mov', 'mp4', 'webm', 'avi', 'MOV', 'MP4', 'WEBM', 'AVI']:
            # å°è¯•å„ç§æ‰©å±•å
            ext_pattern = os.path.join(self.output_dir, pattern.replace(".mov", f".{ext}"))
            matches = glob(ext_pattern)
            all_files.extend(matches)
        
        # å»é‡
        unique_files = list(set(all_files))
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰é¢
        unique_files.sort(key=os.path.getmtime, reverse=True)
        
        return unique_files
    
    def check_output_files_exist(self, video_path: str, workflow: Dict, expected_min_files: int = 1) -> Tuple[bool, List[str]]:
        """æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        è¿”å›: (æ–‡ä»¶å­˜åœ¨, æ–‡ä»¶åˆ—è¡¨)
        """
        output_files = self.get_output_files(video_path, workflow)
        
        if len(output_files) >= expected_min_files:
            logger.info(f"âœ… æ‰¾åˆ° {len(output_files)} ä¸ªè¾“å‡ºæ–‡ä»¶:")
            for file_path in output_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
                file_size_mb = file_size / (1024 * 1024)
                logger.info(f"  ğŸ“„ {os.path.basename(file_path)} ({file_size_mb:.1f}MB)")
            if len(output_files) > 5:
                logger.info(f"  ... è¿˜æœ‰ {len(output_files)-5} ä¸ªæ–‡ä»¶")
            return True, output_files
        else:
            logger.warning(f"âš ï¸  åªæ‰¾åˆ° {len(output_files)} ä¸ªè¾“å‡ºæ–‡ä»¶ï¼ŒæœŸæœ›è‡³å°‘ {expected_min_files} ä¸ª")
            if output_files:
                logger.info("æ‰¾åˆ°çš„æ–‡ä»¶:")
                for file_path in output_files:
                    logger.info(f"  ğŸ“„ {os.path.basename(file_path)}")
            return False, output_files
    
    def verify_output_files_complete(self, video_path: str, workflow: Dict, total_frames: int, frames_per_batch: int) -> Tuple[bool, int, int]:
        """éªŒè¯è¾“å‡ºæ–‡ä»¶æ˜¯å¦å®Œæ•´
        ä¿®å¤ï¼šæ­£ç¡®çš„æ‰¹æ¬¡è®¡ç®—å’Œæ–‡ä»¶éªŒè¯
        """
        # è®¡ç®—é¢„æœŸæ‰¹æ¬¡æ•°
        if total_frames <= 0 or frames_per_batch <= 0:
            logger.warning(f"âš ï¸  æ— æ•ˆçš„å¸§æ•°å‚æ•°: æ€»å¸§æ•°={total_frames}, æ¯æ‰¹å¸§æ•°={frames_per_batch}")
            return False, 0, 0
        
        num_batches = (total_frames + frames_per_batch - 1) // frames_per_batch
        logger.info(f"ğŸ“Š è§†é¢‘æ€»å¸§æ•°: {total_frames}, æ¯æ‰¹å¸§æ•°: {frames_per_batch}, éœ€è¦æ‰¹æ¬¡: {num_batches}")
        
        # è·å–å®é™…è¾“å‡ºæ–‡ä»¶
        output_files = self.get_output_files(video_path, workflow)
        found_batches = len(output_files)
        
        logger.info(f"ğŸ“Š æ‰¹æ¬¡å®Œæˆæƒ…å†µ: {found_batches}/{num_batches}")
        
        if found_batches >= num_batches:
            logger.info(f"âœ… æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶å·²ç”Ÿæˆ")
            return True, found_batches, num_batches
        elif found_batches > 0:
            logger.warning(f"âš ï¸  åªç”Ÿæˆ {found_batches}/{num_batches} ä¸ªæ‰¹æ¬¡æ–‡ä»¶")
            return False, found_batches, num_batches
        else:
            logger.error(f"âŒ æœªç”Ÿæˆä»»ä½•æ‰¹æ¬¡æ–‡ä»¶")
            return False, 0, num_batches

class ComfyUI_FlashVSR_BatchProcessor:
    def __init__(self, 
                 comfyui_url: str = "http://127.0.0.1:8188", 
                 task_timeout: int = 300,
                 max_retries: int = 3,
                 restart_delay: int = 5,
                 startup_timeout: int = 300):
        """
        åˆå§‹åŒ–æ‰¹é‡å¤„ç†å™¨ - ä¿®å¤ç‰ˆ
        """
        # APIå®¢æˆ·ç«¯
        self.client = ComfyUI_Client(comfyui_url)
        
        # æ‰¹å¤„ç†è·Ÿè¸ªå™¨
        self.output_tracker = BatchOutputTracker()
        
        # é…ç½®å‚æ•°
        self.comfyui_url = comfyui_url
        self.task_timeout = task_timeout
        self.max_retries = max_retries
        self.restart_delay = restart_delay
        self.startup_timeout = startup_timeout
        
        # çŠ¶æ€è·Ÿè¸ª
        self.processed_files = {}
        self.failed_files = {}
        self.restart_history = []
        self.current_retry_count = 0
        
        # æ³¨å†Œæ¸…ç†å‡½æ•°
        atexit.register(self.cleanup)
        
        logger.info("=" * 60)
        logger.info("ComfyUI FlashVSR æ‰¹é‡å¤„ç†å™¨ - ä¿®å¤ç‰ˆ")
        logger.info(f"ComfyUIåœ°å€: {comfyui_url}")
        logger.info(f"ä»»åŠ¡è¶…æ—¶: {task_timeout}ç§’")
        logger.info(f"æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}æ¬¡")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_tracker.output_dir}")
        logger.info("=" * 60)
    
    def ensure_comfyui_running(self) -> bool:
        """ç¡®ä¿ComfyUIåœ¨è¿è¡Œ"""
        if self.client.is_server_running():
            return True
        
        logger.warning("âš ï¸  ComfyUIæœªè¿è¡Œï¼Œè¯·æ‰‹åŠ¨å¯åŠ¨ComfyUI")
        return False
    
    def clear_cache(self) -> Dict[str, Any]:
        """æ¸…ç†ç¼“å­˜"""
        cleanup_results = {
            "system_memory_freed_mb": 0,
            "gpu_memory_freed_mb": 0,
            "success": False
        }
        
        logger.info("ğŸ§¹ æ¸…ç†ç¼“å­˜...")
        
        try:
            # æ¸…ç†GPUæ˜¾å­˜
            if TORCH_AVAILABLE and torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                logger.info("âœ… GPUæ˜¾å­˜å·²æ¸…ç†")
                cleanup_results["gpu_memory_freed_mb"] = 1
                cleanup_results["success"] = True
            
            # æ¸…ç†Pythonå†…å­˜
            collected = gc.collect()
            logger.info(f"âœ… Pythonåƒåœ¾å›æ”¶: {collected} ä¸ªå¯¹è±¡")
            cleanup_results["success"] = True
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        
        return cleanup_results
    
    def load_workflow_template(self, template_path: str) -> Dict:
        """åŠ è½½å·¥ä½œæµæ¨¡æ¿"""
        with open(template_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def update_workflow_parameters(
        self, 
        workflow: Dict, 
        video_path: str, 
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 201,
        gpu_device: str = "auto"
    ) -> Dict:
        """æ›´æ–°å·¥ä½œæµå‚æ•°"""
        # æ·±æ‹·è´å·¥ä½œæµ
        import copy
        modified_workflow = copy.deepcopy(workflow)
        
        # è®¾ç½®è¾“å…¥è§†é¢‘è·¯å¾„
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_LoadVideo":
                node_data["inputs"]["video"] = video_path
                logger.info(f"âœ… è®¾ç½®è¾“å…¥è§†é¢‘: {os.path.basename(video_path)}")
        
        # è®¾ç½®FlashVSRå‚æ•°
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "FlashVSRNodeAdv":
                inputs = node_data.get("inputs", {})
                if "{{scale}}" in str(inputs.get("scale", "")):
                    inputs["scale"] = scale
                if "{{t_z}}" in str(inputs.get("tile_size", "")):
                    inputs["tile_size"] = tile_size
                if "{{t_o}}" in str(inputs.get("tile_overlap", "")):
                    inputs["tile_overlap"] = tile_overlap
        
        # è®¾ç½®GPUè®¾å¤‡
        for node_id, node_data in modified_workflow.items():
            if node_id == "5" and node_data.get("class_type") == "FlashVSRInitPipe":
                inputs = node_data.get("inputs", {})
                if isinstance(inputs.get("device"), str):
                    if gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    inputs["device"] = device_value
                    logger.info(f"âœ… è®¾ç½®GPUè®¾å¤‡: {device_value}")
        
        # è®¾ç½®æ€»å¸§æ•°
        if total_frames is None or total_frames <= 0:
            video_info = get_video_info(video_path)
            total_frames = video_info.get('total_frames', 0)
            if total_frames <= 0:
                total_frames = 10000
                logger.warning(f"âš ï¸  æ— æ³•è·å–è§†é¢‘æ€»å¸§æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼: {total_frames}")
            else:
                logger.info(f"ğŸ“Š ä»è§†é¢‘è·å–æ€»å¸§æ•°: {total_frames}")
        
        for node_id, node_data in modified_workflow.items():
            if node_id == "50" and node_data.get("class_type") == "PrimitiveInt":
                node_data["inputs"]["value"] = total_frames
                logger.info(f"âœ… è®¾ç½®æ€»å¸§æ•°: {total_frames}")
        
        # è®¾ç½®æ¯æ‰¹å¸§æ•°
        for node_id, node_data in modified_workflow.items():
            if node_id == "8" and node_data.get("class_type") == "PrimitiveInt":
                node_data["inputs"]["value"] = frames_per_batch
                logger.info(f"âœ… è®¾ç½®æ¯æ‰¹å¸§æ•°: {frames_per_batch}")
        
        # è®¾ç½®è¾“å‡ºå‰ç¼€
        if output_prefix is None:
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            output_prefix = f"flashvsr_{base_name}"
        
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_VideoCombine":
                node_data["inputs"]["filename_prefix"] = output_prefix
                logger.info(f"âœ… è®¾ç½®è¾“å‡ºå‰ç¼€: {output_prefix}")
        
        return modified_workflow
    
    def wait_for_task_completion_with_verification(
        self, 
        prompt_id: str, 
        video_path: str, 
        workflow: Dict,
        total_frames: int,
        frames_per_batch: int,
        timeout: int = 300
    ) -> Tuple[bool, str, List[str]]:
        """
        ç­‰å¾…ä»»åŠ¡å®Œæˆå¹¶è¿›è¡ŒéªŒè¯ - ä¿®å¤ç‰ˆ
        è¿”å›: (æ˜¯å¦æˆåŠŸ, çŠ¶æ€ä¿¡æ¯, è¾“å‡ºæ–‡ä»¶åˆ—è¡¨)
        """
        logger.info(f"â³ ç­‰å¾…ä»»åŠ¡å®Œæˆ (è¶…æ—¶: {timeout}ç§’)...")
        
        start_time = time.time()
        last_status_check = 0
        status_check_interval = 5
        empty_queue_checks = 0
        max_empty_queue_checks = 3
        
        while time.time() - start_time < timeout:
            # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
            prompt_info = self.client.get_prompt_status(prompt_id)
            
            if prompt_info:
                status = prompt_info.get('status', {})
                
                if status.get('completed', False):
                    logger.info(f"âœ… ä»»åŠ¡ {prompt_id[:8]}... APIæŠ¥å‘Šå·²å®Œæˆ")
                    
                    # é‡è¦ï¼šç«‹å³æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
                    logger.info("ğŸ” éªŒè¯è¾“å‡ºæ–‡ä»¶...")
                    time.sleep(2)  # ç­‰å¾…æ–‡ä»¶å†™å…¥
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºæ–‡ä»¶
                    files_exist, output_files = self.output_tracker.check_output_files_exist(
                        video_path, workflow, expected_min_files=1
                    )
                    
                    if files_exist and output_files:
                        # éªŒè¯æ‰¹æ¬¡å®Œæ•´æ€§
                        is_complete, found_batches, total_batches = self.output_tracker.verify_output_files_complete(
                            video_path, workflow, total_frames, frames_per_batch
                        )
                        
                        if is_complete or found_batches > 0:
                            logger.info(f"âœ… è¾“å‡ºæ–‡ä»¶éªŒè¯é€šè¿‡ï¼Œæ‰¾åˆ° {len(output_files)} ä¸ªæ–‡ä»¶")
                            return True, "ä»»åŠ¡å®Œæˆ", output_files
                        else:
                            logger.warning(f"âš ï¸  è¾“å‡ºæ–‡ä»¶ä¸å®Œæ•´: {found_batches}/{total_batches}")
                            return False, f"è¾“å‡ºæ–‡ä»¶ä¸å®Œæ•´: {found_batches}/{total_batches}", output_files
                    else:
                        logger.warning("âš ï¸  APIæŠ¥å‘Šå®Œæˆä½†æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶")
                        return False, "æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶", []
                
                if status.get('error', False):
                    error_msg = status.get('error_message', 'æœªçŸ¥é”™è¯¯')
                    logger.error(f"âŒ ä»»åŠ¡å‡ºé”™: {error_msg}")
                    return False, f"ä»»åŠ¡å‡ºé”™: {error_msg}", []
            
            # æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
            queue_info = self.client.get_queue()
            queue_length = len(queue_info)
            
            if queue_length > 0:
                logger.debug(f"â³ é˜Ÿåˆ—ä¸­è¿˜æœ‰ {queue_length} ä¸ªä»»åŠ¡")
                empty_queue_checks = 0
            else:
                empty_queue_checks += 1
                logger.debug(f"â³ é˜Ÿåˆ—å·²ç©º ({empty_queue_checks}/{max_empty_queue_checks})")
                
                # é‡è¦ï¼šå³ä½¿é˜Ÿåˆ—ä¸ºç©ºï¼Œä¹Ÿè¦æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºæ–‡ä»¶
                if empty_queue_checks >= 2:  # ç¬¬äºŒæ¬¡æ£€æŸ¥é˜Ÿåˆ—ä¸ºç©ºæ—¶éªŒè¯æ–‡ä»¶
                    logger.info("ğŸ” é˜Ÿåˆ—ä¸ºç©ºï¼Œæ£€æŸ¥è¾“å‡ºæ–‡ä»¶...")
                    files_exist, output_files = self.output_tracker.check_output_files_exist(
                        video_path, workflow, expected_min_files=1
                    )
                    
                    if files_exist and output_files:
                        # éªŒè¯æ‰¹æ¬¡å®Œæ•´æ€§
                        is_complete, found_batches, total_batches = self.output_tracker.verify_output_files_complete(
                            video_path, workflow, total_frames, frames_per_batch
                        )
                        
                        if is_complete or found_batches > 0:
                            logger.info(f"âœ… é˜Ÿåˆ—ä¸ºç©ºä½†æ‰¾åˆ°è¾“å‡ºæ–‡ä»¶: {len(output_files)} ä¸ª")
                            return True, "ä»»åŠ¡å®Œæˆï¼ˆé˜Ÿåˆ—ä¸ºç©ºä½†å·²è¾“å‡ºæ–‡ä»¶ï¼‰", output_files
                    elif empty_queue_checks >= max_empty_queue_checks:
                        logger.warning(f"âš ï¸  é˜Ÿåˆ—è¿ç»­ {max_empty_queue_checks} æ¬¡ä¸ºç©ºä¸”æ— è¾“å‡ºæ–‡ä»¶")
                        return False, f"é˜Ÿåˆ—ä¸ºç©ºä¸”æ— è¾“å‡ºæ–‡ä»¶", []
            
            # å®šæœŸè¾“å‡ºè¿›åº¦
            elapsed = int(time.time() - start_time)
            if elapsed - last_status_check >= 30:
                logger.info(f"â³ å·²å¤„ç† {elapsed} ç§’ï¼Œé˜Ÿåˆ—: {queue_length} ä¸ªä»»åŠ¡")
                last_status_check = elapsed
            
            time.sleep(2)
        
        logger.warning(f"âš ï¸  ä»»åŠ¡ {prompt_id} è¶…æ—¶ ({timeout}ç§’)")
        return False, f"ä»»åŠ¡è¶…æ—¶ ({timeout}ç§’)", []
    
    def process_single_video(
        self,
        workflow_template: Dict,
        video_path: str,
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        frames_per_batch: int = 201,
        gpu_device: str = "auto"
    ) -> Tuple[bool, str, int, List[str]]:
        """
        å¤„ç†å•ä¸ªè§†é¢‘ - ä¿®å¤ç‰ˆ
        è¿”å›: (æ˜¯å¦æˆåŠŸ, çŠ¶æ€ä¿¡æ¯, é‡è¯•æ¬¡æ•°, è¾“å‡ºæ–‡ä»¶åˆ—è¡¨)
        """
        video_name = os.path.basename(video_path)
        retry_count = 0
        success = False
        status_msg = "åˆå§‹çŠ¶æ€"
        output_files = []
        
        # ç¡®ä¿ComfyUIåœ¨è¿è¡Œ
        if not self.ensure_comfyui_running():
            return False, "ComfyUIæœªè¿è¡Œ", 0, []
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = get_video_info(video_path)
        total_frames = video_info.get('total_frames', 0)
        
        if total_frames <= 0:
            logger.warning(f"âš ï¸  æ— æ³•è·å–è§†é¢‘ '{video_name}' çš„æ€»å¸§æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            total_frames = 10000
        
        # è®¡ç®—é¢„æœŸæ‰¹æ¬¡æ•°
        num_batches = 1
        if total_frames > 0 and frames_per_batch > 0:
            num_batches = (total_frames + frames_per_batch - 1) // frames_per_batch
        logger.info(f"ğŸ“Š è§†é¢‘ '{video_name}' éœ€è¦ {num_batches} ä¸ªæ‰¹æ¬¡ (æ€»å¸§æ•°: {total_frames}, æ¯æ‰¹: {frames_per_batch})")
        
        # å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰è¾“å‡ºæ–‡ä»¶
        logger.info("ğŸ” æ£€æŸ¥æ˜¯å¦å·²æœ‰è¾“å‡ºæ–‡ä»¶...")
        temp_workflow = self.update_workflow_parameters(
            workflow_template, video_path, output_prefix
        )
        files_exist, existing_files = self.output_tracker.check_output_files_exist(
            video_path, temp_workflow, expected_min_files=num_batches
        )
        
        if files_exist and len(existing_files) >= num_batches:
            logger.info(f"âœ… è§†é¢‘ '{video_name}' å·²æœ‰å®Œæ•´è¾“å‡ºæ–‡ä»¶ï¼Œè·³è¿‡å¤„ç†")
            return True, "å·²æœ‰å®Œæ•´è¾“å‡ºæ–‡ä»¶", 0, existing_files
        
        while retry_count < self.max_retries and not success:
            retry_count += 1
            logger.info(f"ğŸ”„ å°è¯• {retry_count}/{self.max_retries}")
            
            try:
                # æ›´æ–°å·¥ä½œæµå‚æ•°
                workflow = self.update_workflow_parameters(
                    workflow_template,
                    video_path,
                    output_prefix,
                    scale=scale,
                    tile_size=tile_size,
                    tile_overlap=tile_overlap,
                    total_frames=total_frames,
                    frames_per_batch=frames_per_batch,
                    gpu_device=gpu_device
                )
                
                # æäº¤ä»»åŠ¡
                prompt_id = self.client.submit_prompt(workflow)
                
                if not prompt_id:
                    status_msg = "æäº¤ä»»åŠ¡å¤±è´¥"
                    logger.error(f"âŒ {status_msg}")
                    continue
                
                logger.info(f"âœ… ä»»åŠ¡å·²æäº¤: {video_name}")
                logger.info(f"  ä»»åŠ¡ID: {prompt_id}")
                
                # ç­‰å¾…ä»»åŠ¡å®Œæˆå¹¶éªŒè¯è¾“å‡º
                task_success, task_status, output_files = self.wait_for_task_completion_with_verification(
                    prompt_id=prompt_id,
                    video_path=video_path,
                    workflow=workflow,
                    total_frames=total_frames,
                    frames_per_batch=frames_per_batch,
                    timeout=self.task_timeout
                )
                
                if task_success:
                    success = True
                    status_msg = task_status
                    
                    # æœ€ç»ˆéªŒè¯è¾“å‡ºæ–‡ä»¶
                    if output_files:
                        logger.info(f"âœ… è§†é¢‘å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(output_files)} ä¸ªè¾“å‡ºæ–‡ä»¶")
                        for i, file_path in enumerate(output_files[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                            file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
                            file_size_mb = file_size / (1024 * 1024)
                            logger.info(f"  {i+1}. {os.path.basename(file_path)} ({file_size_mb:.1f}MB)")
                        if len(output_files) > 3:
                            logger.info(f"  ... è¿˜æœ‰ {len(output_files)-3} ä¸ªæ–‡ä»¶")
                    else:
                        logger.warning("âš ï¸  ä»»åŠ¡æˆåŠŸä½†æœªè®°å½•è¾“å‡ºæ–‡ä»¶")
                    
                    break
                else:
                    status_msg = task_status
                    logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {status_msg}")
                    
                    # å¦‚æœå¤±è´¥ä½†æœ‰éƒ¨åˆ†è¾“å‡ºæ–‡ä»¶ï¼Œæ£€æŸ¥æ˜¯å¦å¯ç”¨
                    if output_files:
                        logger.info(f"ğŸ“ æ‰¾åˆ° {len(output_files)} ä¸ªéƒ¨åˆ†è¾“å‡ºæ–‡ä»¶")
                        is_complete, found_batches, total_batches = self.output_tracker.verify_output_files_complete(
                            video_path, workflow, total_frames, frames_per_batch
                        )
                        
                        if found_batches >= total_batches * 0.8:  # 80%å®Œæˆè®¤ä¸ºå¯ç”¨
                            logger.info(f"âœ… éƒ¨åˆ†è¾“å‡ºæ–‡ä»¶å¯ç”¨ ({found_batches}/{total_batches} æ‰¹æ¬¡)")
                            success = True
                            status_msg = f"éƒ¨åˆ†å®Œæˆ: {found_batches}/{total_batches} æ‰¹æ¬¡"
                            break
                    
                    # è®°å½•é‡å¯
                    self.record_restart(
                        video_path=video_path,
                        reason=status_msg,
                        attempt=retry_count
                    )
                    
                    if retry_count < self.max_retries:
                        logger.info(f"ğŸ”„ å‡†å¤‡é‡è¯• ({retry_count}/{self.max_retries})...")
                        time.sleep(self.restart_delay)
                    else:
                        logger.error(f"âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    
            except Exception as e:
                status_msg = f"å¤„ç†å¼‚å¸¸: {str(e)}"
                logger.error(f"âŒ {status_msg}")
                
                # è®°å½•é‡å¯
                self.record_restart(
                    video_path=video_path,
                    reason=status_msg,
                    attempt=retry_count
                )
                
                if retry_count < self.max_retries:
                    logger.info(f"ğŸ”„ å¼‚å¸¸åå‡†å¤‡é‡è¯• ({retry_count}/{self.max_retries})...")
                    time.sleep(self.restart_delay)
                else:
                    logger.error("âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
        
        return success, status_msg, retry_count, output_files
    
    def record_restart(self, video_path: str, reason: str, attempt: int = 1):
        """è®°å½•é‡å¯äº‹ä»¶"""
        restart_entry = {
            'timestamp': datetime.now().isoformat(),
            'video_path': video_path,
            'video_name': os.path.basename(video_path),
            'reason': reason,
            'attempt': attempt
        }
        self.restart_history.append(restart_entry)
        
        # ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶
        self.save_restart_log()
    
    def save_restart_log(self, filename: str = "restart_history.json"):
        """ä¿å­˜é‡å¯å†å²åˆ°æ–‡ä»¶"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.restart_history, f, indent=2, ensure_ascii=False, default=str)
            logger.debug(f"âœ… é‡å¯å†å²å·²ä¿å­˜: {filename}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜é‡å¯å†å²å¤±è´¥: {e}")
    
    def move_to_done_directory(self, video_path: str) -> Optional[str]:
        """ç§»åŠ¨æ–‡ä»¶åˆ°doneç›®å½•"""
        try:
            if not os.path.exists(video_path):
                logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                return None
            
            # è·å–åŸæ–‡ä»¶æ‰€åœ¨ç›®å½•
            original_dir = os.path.dirname(video_path)
            file_name = os.path.basename(video_path)
            
            # åˆ›å»ºdoneç›®å½•
            done_dir = os.path.join(original_dir, "done")
            os.makedirs(done_dir, exist_ok=True)
            
            # ç”Ÿæˆç›®æ ‡è·¯å¾„
            done_path = os.path.join(done_dir, file_name)
            
            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
            if os.path.exists(done_path):
                base_name, ext = os.path.splitext(file_name)
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                new_name = f"{base_name}_{timestamp}{ext}"
                done_path = os.path.join(done_dir, new_name)
            
            # ç§»åŠ¨æ–‡ä»¶
            shutil.move(video_path, done_path)
            logger.info(f"âœ… æ–‡ä»¶å·²ç§»åŠ¨åˆ°doneç›®å½•: {os.path.basename(done_path)}")
            
            return done_path
            
        except Exception as e:
            logger.error(f"âŒ ç§»åŠ¨æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def batch_process(
        self,
        workflow_template_path: str,
        video_files: List[str],
        output_prefix_base: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        frames_per_batch: int = 201,
        gpu_device: str = "auto",
        move_to_done: bool = True,
        cleanup_after_each: bool = True
    ) -> Dict[str, Tuple[bool, str, int, List[str]]]:
        """
        æ‰¹é‡å¤„ç†è§†é¢‘ - ä¿®å¤ç‰ˆ
        è¿”å›: å­—å…¸ï¼Œé”®ä¸ºè§†é¢‘è·¯å¾„ï¼Œå€¼ä¸º(æ˜¯å¦æˆåŠŸ, çŠ¶æ€ä¿¡æ¯, é‡è¯•æ¬¡æ•°, è¾“å‡ºæ–‡ä»¶åˆ—è¡¨)
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(video_files)} ä¸ªè§†é¢‘")
        logger.info(f"âš™ï¸  å‚æ•°: scale={scale}, tile_size={tile_size}, tile_overlap={tile_overlap}")
        logger.info(f"ğŸ® GPUè®¾å¤‡: {gpu_device}")
        logger.info(f"â±ï¸  ä»»åŠ¡è¶…æ—¶: {self.task_timeout}ç§’")
        logger.info(f"ğŸ”„ æœ€å¤§é‡è¯•: {self.max_retries}æ¬¡")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_tracker.output_dir}")
        logger.info(f"{'='*60}")
        
        # åŠ è½½å·¥ä½œæµæ¨¡æ¿
        try:
            workflow_template = self.load_workflow_template(workflow_template_path)
            logger.info(f"âœ… åŠ è½½å·¥ä½œæµæ¨¡æ¿: {workflow_template_path}")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å·¥ä½œæµæ¨¡æ¿å¤±è´¥: {e}")
            return {}
        
        # ç¡®ä¿ComfyUIåœ¨è¿è¡Œ
        if not self.ensure_comfyui_running():
            logger.error("âŒ ComfyUIæœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨ComfyUI")
            return {}
        
        results = {}
        processed_count = 0
        failed_count = 0
        
        for i, video_path in enumerate(video_files, 1):
            video_name = os.path.basename(video_path)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_path):
                logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
                self.failed_files[video_path] = {
                    'status': 'failed',
                    'message': 'æ–‡ä»¶ä¸å­˜åœ¨',
                    'timestamp': datetime.now().isoformat()
                }
                failed_count += 1
                continue
            
            logger.info(f"\nğŸ“Š [{i}/{len(video_files)}] å¤„ç†: {video_name}")
            logger.info(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {video_path}")
            
            # è®¾ç½®è¾“å‡ºå‰ç¼€
            output_prefix = None
            if output_prefix_base:
                base_name = os.path.splitext(video_name)[0]
                output_prefix = f"{output_prefix_base}_{base_name}"
            
            # å¤„ç†å•ä¸ªè§†é¢‘
            success, status_msg, retry_count, output_files = self.process_single_video(
                workflow_template=workflow_template,
                video_path=video_path,
                output_prefix=output_prefix,
                scale=scale,
                tile_size=tile_size,
                tile_overlap=tile_overlap,
                frames_per_batch=frames_per_batch,
                gpu_device=gpu_device
            )
            
            # è®°å½•ç»“æœ
            results[video_path] = (success, status_msg, retry_count, output_files)
            
            if success:
                processed_count += 1
                self.processed_files[video_path] = {
                    'status': 'success',
                    'message': status_msg,
                    'retries': retry_count,
                    'output_files': [os.path.basename(f) for f in output_files],
                    'timestamp': datetime.now().isoformat()
                }
                
                # ç§»åŠ¨æ–‡ä»¶åˆ°doneç›®å½•
                if move_to_done:
                    moved_path = self.move_to_done_directory(video_path)
                    if not moved_path:
                        logger.warning(f"âš ï¸  æ–‡ä»¶ç§»åŠ¨å¤±è´¥: {video_name}")
                
                # é‡ç½®é‡è¯•è®¡æ•°
                self.current_retry_count = 0
                
            else:
                failed_count += 1
                self.failed_files[video_path] = {
                    'status': 'failed',
                    'message': status_msg,
                    'retries': retry_count,
                    'output_files': [os.path.basename(f) for f in output_files] if output_files else [],
                    'timestamp': datetime.now().isoformat()
                }
                logger.error(f"âŒ å¤„ç†å¤±è´¥: {status_msg}")
            
            # æ¸…ç†ç¼“å­˜
            if cleanup_after_each and success:
                self.clear_cache()
            
            # çŸ­æš‚é—´éš”
            if i < len(video_files):
                wait_time = 2
                logger.info(f"â±ï¸  ç­‰å¾… {wait_time} ç§’...")
                time.sleep(wait_time)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info(f"\n{'='*60}")
        logger.info("æ‰¹é‡å¤„ç†å®Œæˆ")
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"  âœ… æˆåŠŸ: {processed_count}/{len(video_files)}")
        logger.info(f"  âŒ å¤±è´¥: {failed_count}/{len(video_files)}")
        logger.info(f"  ğŸ”„ æ€»é‡å¯æ¬¡æ•°: {len(self.restart_history)}")
        
        # è¾“å‡ºé‡å¯æ‘˜è¦
        if self.restart_history:
            logger.info(f"\nğŸ”„ é‡å¯æ‘˜è¦:")
            for entry in self.restart_history[-10:]:  # åªæ˜¾ç¤ºæœ€å10ä¸ª
                logger.info(f"  â€¢ {entry['video_name']}: {entry['reason']} (å°è¯• {entry['attempt']})")
            if len(self.restart_history) > 10:
                logger.info(f"  ... è¿˜æœ‰ {len(self.restart_history)-10} ä¸ªé‡å¯è®°å½•")
        
        # ä¿å­˜å¤„ç†æ—¥å¿—
        self.save_processing_log(video_files, results)
        
        return results
    
    def save_processing_log(self, video_files: List[str], results: Dict):
        """ä¿å­˜å¤„ç†æ—¥å¿—"""
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'total_files': len(video_files),
            'processed_files': self.processed_files,
            'failed_files': self.failed_files,
            'restart_history': self.restart_history,
            'results': {}
        }
        
        for video_path, (success, status, retries, output_files) in results.items():
            log_data['results'][video_path] = {
                'success': success,
                'status': status,
                'retries': retries,
                'output_files': [os.path.basename(f) for f in output_files] if output_files else [],
                'video_name': os.path.basename(video_path)
            }
        
        try:
            with open('processing_log.json', 'w', encoding='utf-8') as f:
                json.dump(log_data, f, indent=2, ensure_ascii=False, default=str)
            logger.info("âœ… å¤„ç†æ—¥å¿—å·²ä¿å­˜: processing_log.json")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å¤„ç†æ—¥å¿—å¤±è´¥: {e}")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†èµ„æº...")
        try:
            self.client.session.close()
        except:
            pass
        logger.info("âœ… æ¸…ç†å®Œæˆ")

def collect_video_files(input_path: str, pattern: str = '*.mp4') -> List[str]:
    """æ”¶é›†è§†é¢‘æ–‡ä»¶"""
    video_files = []
    
    if os.path.isfile(input_path):
        if input_path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv')):
            video_files.append(input_path)
            logger.info(f"âœ… æ·»åŠ å•ä¸ªæ–‡ä»¶: {input_path}")
    elif os.path.isdir(input_path):
        # æœç´¢è§†é¢‘æ–‡ä»¶
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', '.MP4', '.MOV', '.AVI', '.MKV']
        
        for ext in video_extensions:
            search_pattern = os.path.join(input_path, f"*{ext}")
            found_files = glob(search_pattern)
            video_files.extend(found_files)
        
        # å»é‡å¹¶æ’åº
        video_files = sorted(list(set(video_files)))
        
        if not video_files:
            logger.error(f"âŒ ç›®å½• {input_path} ä¸­æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        else:
            logger.info(f"âœ… ä»ç›®å½• {input_path} æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    else:
        logger.error(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    return video_files

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· - ä¿®å¤ç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘
  python batch_processor_fixed.py --input ./videos --gpu 0
  
  # è‡ªå®šä¹‰å‚æ•°
  python batch_processor_fixed.py --input ./videos --task-timeout 600 --max-retries 5
  
  # æŒ‡å®šå·¥ä½œæµæ¨¡æ¿
  python batch_processor_fixed.py --input ./videos --template flashvsr_template.json

ä¸»è¦ä¿®å¤:
  1. ä¿®å¤æ‰¹æ¬¡æ£€æµ‹é€»è¾‘ï¼Œæ­£ç¡®è¯†åˆ«è¾“å‡ºæ–‡ä»¶
  2. å¢åŠ è¾“å‡ºæ–‡ä»¶éªŒè¯ï¼Œé˜²æ­¢ç©ºä»»åŠ¡è¢«æ ‡è®°ä¸ºå®Œæˆ
  3. æ”¹è¿›æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
  4. æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘
        """
    )
    
    # è¾“å…¥å‚æ•°
    parser.add_argument('--template', type=str, default='flashvsr_template.json',
                       help='å·¥ä½œæµæ¨¡æ¿ JSON æ–‡ä»¶è·¯å¾„ (é»˜è®¤: flashvsr_template.json)')
    parser.add_argument('--input', type=str, required=True,
                       help='è¾“å…¥è·¯å¾„ï¼ˆè§†é¢‘æ–‡ä»¶æˆ–ç›®å½•ï¼‰')
    parser.add_argument('--pattern', type=str, default='*.mp4',
                       help='è§†é¢‘æ–‡ä»¶åŒ¹é…æ¨¡å¼ (é»˜è®¤: *.mp4)')
    
    # å¤„ç†å‚æ•°
    parser.add_argument('--scale', type=float, default=4.0,
                       help='æ”¾å¤§å€æ•° (é»˜è®¤: 4.0)')
    parser.add_argument('--tile-size', type=int, default=256,
                       help='åˆ†å—å¤§å° (é»˜è®¤: 256)')
    parser.add_argument('--tile-overlap', type=int, default=24,
                       help='åˆ†å—é‡å åƒç´  (é»˜è®¤: 24)')
    parser.add_argument('--frames-per-batch', type=int, default=125,
                       help='æ¯æ‰¹å¤„ç†çš„å¸§æ•° (é»˜è®¤: 125)')
    parser.add_argument('--gpu', type=str, default='auto',
                       help='GPUè®¾å¤‡é€‰æ‹© (é»˜è®¤: auto)')
    
    # ç›‘æ§å‚æ•°
    parser.add_argument('--task-timeout', type=int, default=300,
                       help='ä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 300)')
    parser.add_argument('--max-retries', type=int, default=3,
                       help='æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)')
    parser.add_argument('--restart-delay', type=int, default=5,
                       help='é‡å¯åç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 5)')
    
    # æ–‡ä»¶ç®¡ç†
    parser.add_argument('--no-move', action='store_true',
                       help='ä¸å°†å¤„ç†å®Œæˆçš„æ–‡ä»¶ç§»åŠ¨åˆ°doneç›®å½•')
    parser.add_argument('--no-cleanup', action='store_true',
                       help='ä¸æ¸…ç†ç¼“å­˜')
    
    # ç³»ç»Ÿå‚æ•°
    parser.add_argument('--server', type=str, default='http://127.0.0.1:8188',
                       help='ComfyUI æœåŠ¡å™¨åœ°å€ (é»˜è®¤: http://127.0.0.1:8188)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥pymediainfoæ˜¯å¦å®‰è£…
    if not PYMEDIAINFO_AVAILABLE:
        logger.warning("âš ï¸  pymediainfoæœªå®‰è£…ï¼Œå°†æ— æ³•è·å–è§†é¢‘çœŸå®å¸§æ•°")
        logger.info("è¯·è¿è¡Œ: pip install pymediainfo")
    
    # æ”¶é›†è§†é¢‘æ–‡ä»¶
    video_files = collect_video_files(args.input, args.pattern)
    
    if not video_files:
        logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        return
    
    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
    logger.info(f"\nğŸ“ æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶:")
    for i, vf in enumerate(video_files[:5], 1):
        logger.info(f"  {i}. {os.path.basename(vf)}")
    if len(video_files) > 5:
        logger.info(f"  ... è¿˜æœ‰ {len(video_files)-5} ä¸ªæ–‡ä»¶")
    
    # æ˜¾ç¤ºå¤„ç†å‚æ•°
    logger.info(f"\nâš™ï¸  å¤„ç†å‚æ•°:")
    logger.info(f"  scale: {args.scale}")
    logger.info(f"  tile_size: {args.tile_size}")
    logger.info(f"  tile_overlap: {args.tile_overlap}")
    logger.info(f"  frames_per_batch: {args.frames_per_batch}")
    logger.info(f"  GPU: {args.gpu}")
    logger.info(f"  ä»»åŠ¡è¶…æ—¶: {args.task_timeout}ç§’")
    logger.info(f"  æœ€å¤§é‡è¯•: {args.max_retries}æ¬¡")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = ComfyUI_FlashVSR_BatchProcessor(
        comfyui_url=args.server,
        task_timeout=args.task_timeout,
        max_retries=args.max_retries,
        restart_delay=args.restart_delay
    )
    
    # æ‰¹é‡å¤„ç†
    start_time = time.time()
    
    try:
        results = processor.batch_process(
            workflow_template_path=args.template,
            video_files=video_files,
            output_prefix_base=None,
            scale=args.scale,
            tile_size=args.tile_size,
            tile_overlap=args.tile_overlap,
            frames_per_batch=args.frames_per_batch,
            gpu_device=args.gpu,
            move_to_done=not args.no_move,
            cleanup_after_each=not args.no_cleanup
        )
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = time.time() - start_time
        hours, remainder = divmod(total_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        
        logger.info(f"\nâ±ï¸  æ€»è€—æ—¶: {int(hours)}æ—¶{int(minutes)}åˆ†{seconds:.0f}ç§’")
        
        # è¾“å‡ºè¯¦ç»†ç»“æœ
        success_count = sum(1 for success, _, _, _ in results.values() if success)
        output_file_count = sum(len(files) for _, _, _, files in results.values())
        
        logger.info(f"ğŸ“ æ€»è¾“å‡ºæ–‡ä»¶æ•°: {output_file_count}")
        
        if success_count > 0:
            logger.info(f"\nâœ… æˆåŠŸæ–‡ä»¶åˆ—è¡¨ (å‰10ä¸ª):")
            for video_path, (success, status, retries, files) in list(results.items())[:10]:
                if success:
                    file_count = len(files) if files else 0
                    logger.info(f"  âœ“ {os.path.basename(video_path)} - {status} (æ–‡ä»¶: {file_count}, é‡è¯•: {retries})")
            if success_count > 10:
                logger.info(f"  ... è¿˜æœ‰ {success_count-10} ä¸ªæˆåŠŸæ–‡ä»¶")
        
        if success_count < len(video_files):
            failed_count = len(video_files) - success_count
            logger.info(f"\nâŒ å¤±è´¥æ–‡ä»¶åˆ—è¡¨ (å‰10ä¸ª):")
            for video_path, (success, status, retries, files) in list(results.items())[:10]:
                if not success:
                    file_count = len(files) if files else 0
                    logger.info(f"  âœ— {os.path.basename(video_path)} - {status} (æ–‡ä»¶: {file_count}, é‡è¯•: {retries})")
            if failed_count > 10:
                logger.info(f"  ... è¿˜æœ‰ {failed_count-10} ä¸ªå¤±è´¥æ–‡ä»¶")
        
        logger.info(f"\nğŸ“Š è¯¦ç»†æ—¥å¿—å·²ä¿å­˜åˆ°:")
        logger.info(f"  â€¢ comfyui_batch_processor.log (è¿è¡Œæ—¥å¿—)")
        logger.info(f"  â€¢ processing_log.json (å¤„ç†ç»“æœ)")
        logger.info(f"  â€¢ restart_history.json (é‡å¯å†å²)")
        
    except KeyboardInterrupt:
        logger.info("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­å¤„ç†")
        logger.info("å·²ä¿å­˜å½“å‰è¿›åº¦")
    except Exception as e:
        logger.error(f"\nâŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
