#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· - å¢å¼ºä»»åŠ¡ç›‘æ§ç‰ˆï¼ˆä¿®æ­£ç‰ˆï¼‰
æ”¹è¿›çš„ä»»åŠ¡çŠ¶æ€ç›‘æ§é€»è¾‘ï¼Œæ”¯æŒå¤šAPIååŒç›‘æ§å’Œæ™ºèƒ½é‡è¯•
ä¿®å¤å ä½ç¬¦æ›¿æ¢é—®é¢˜
"""

import json
import requests
import os
import time
import sys
import math
import re
from glob import glob
from typing import List, Dict, Optional, Tuple, Union
from pathlib import Path
import subprocess
import psutil
import traceback

# å°è¯•å¯¼å…¥ pymediainfo
try:
    from pymediainfo import MediaInfo
    PYMEDIAINFO_AVAILABLE = True
except ImportError:
    PYMEDIAINFO_AVAILABLE = False
    print("âš ï¸  pymediainfo æœªå®‰è£…ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è·å–è§†é¢‘ä¿¡æ¯")

class ComfyUI_FlashVSR_BatchProcessor:
    def __init__(self, comfyui_url: str = "http://127.0.0.1:8188"):
        """
        åˆå§‹åŒ– ComfyUI FlashVSR æ‰¹é‡å¤„ç†å™¨
        
        å‚æ•°:
            comfyui_url: ComfyUI æœåŠ¡å™¨åœ°å€
        """
        self.comfyui_url = comfyui_url.rstrip('/')
        self.api_prompt = f"{comfyui_url}/prompt"
        self.api_history = f"{comfyui_url}/history"
        self.api_view = f"{comfyui_url}/view"
        self.api_queue = f"{comfyui_url}/queue"  # æ–°å¢ï¼šé˜Ÿåˆ—API
        
        # æ·»åŠ çŠ¶æ€è·Ÿè¸ª
        self.comfyui_process = None
        self.comfyui_path = r"F:\AI\ComfyUI_Mie_V7.0"
        self.comfyui_script = r"F:\AI\ComfyUI_Mie_V7.0\run_nvidia_gpu_fast_fp16_accumulation_hf_mirror.bat"
        self.output_dir = r"F:\AI\ComfyUI_Mie_V7.0\comfyui\output"
        
        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
        self.log_file = os.path.join(self.comfyui_path, "batch_processing.log")
        
    def save_processing_status(self, video_name: str, batch_number: int = None, action: str = None):
        """
        ä¿å­˜å¤„ç†çŠ¶æ€åˆ°æ—¥å¿—æ–‡ä»¶
        """
        try:
            timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
            with open(self.log_file, 'a', encoding='utf-8') as f:
                if batch_number is not None and action is not None:
                    f.write(f"[{timestamp}] è§†é¢‘: {video_name}, æ‰¹æ¬¡: {batch_number}, æ“ä½œ: {action}\n")
                elif batch_number is not None:
                    f.write(f"[{timestamp}] è§†é¢‘: {video_name}, æ‰¹æ¬¡: {batch_number}\n")
                else:
                    f.write(f"[{timestamp}] è§†é¢‘: {video_name}\n")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¤„ç†çŠ¶æ€å¤±è´¥: {e}")
    
    def kill_comfyui_processes(self):
        """å…³é—­æ‰€æœ‰ComfyUIç›¸å…³è¿›ç¨‹"""
        print("ğŸ”ª æ­£åœ¨å…³é—­ComfyUIè¿›ç¨‹...")
        self.save_processing_status("ç³»ç»Ÿ", action="å…³é—­ComfyUIè¿›ç¨‹")
        
        try:
            killed_count = 0
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = ' '.join(proc.info.get('cmdline', []))
                    if 'comfy' in cmdline.lower() or 'main.py' in cmdline:
                        print(f"  ç»ˆæ­¢è¿›ç¨‹ PID={proc.info['pid']}")
                        proc.kill()
                        killed_count += 1
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            if killed_count > 0:
                print(f"âœ… å·²ç»ˆæ­¢ {killed_count} ä¸ªComfyUIè¿›ç¨‹")
            else:
                print("â„¹ï¸ æœªæ‰¾åˆ°è¿è¡Œçš„ComfyUIè¿›ç¨‹")
            
            time.sleep(3)
            
        except Exception as e:
            print(f"âš ï¸ ç»ˆæ­¢è¿›ç¨‹æ—¶å‡ºé”™: {e}")
    
    def start_comfyui(self):
        """å¯åŠ¨ComfyUIè¿›ç¨‹"""
        print(f"ğŸš€ æ­£åœ¨å¯åŠ¨ComfyUI: {self.comfyui_script}")
        self.save_processing_status("ç³»ç»Ÿ", action="å¯åŠ¨ComfyUI")
        
        try:
            os.chdir(self.comfyui_path)
            
            self.comfyui_process = subprocess.Popen(
                [self.comfyui_script],
                creationflags=subprocess.CREATE_NEW_CONSOLE,
                cwd=self.comfyui_path
            )
            
            print(f"âœ… ComfyUIè¿›ç¨‹å·²å¯åŠ¨ï¼ŒPID: {self.comfyui_process.pid}")
            
            wait_time = 120
            for i in range(wait_time):
                print(f"â³ ç­‰å¾…ComfyUIå¯åŠ¨ ({i+1}/{wait_time})...")
                if self.check_comfyui_server(timeout=5):
                    print("âœ… ComfyUIæœåŠ¡å™¨å·²å‡†å¤‡å°±ç»ª")
                    return True
                time.sleep(1)
            
            print("âŒ ComfyUIå¯åŠ¨è¶…æ—¶")
            return False
            
        except Exception as e:
            print(f"âŒ å¯åŠ¨ComfyUIå¤±è´¥: {e}")
            return False
    
    def restart_comfyui(self):
        """é‡å¯ComfyUIæœåŠ¡"""
        print("ğŸ”„ æ­£åœ¨é‡å¯ComfyUIæœåŠ¡...")
        self.save_processing_status("ç³»ç»Ÿ", action="é‡å¯ComfyUI")
        
        self.kill_comfyui_processes()
        
        if self.start_comfyui():
            print("âœ… ComfyUIé‡å¯æˆåŠŸ")
            return True
        else:
            print("âŒ ComfyUIé‡å¯å¤±è´¥")
            return False
    
    def check_comfyui_server(self, timeout: int = 5) -> bool:
        """æ£€æŸ¥ComfyUIæœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.comfyui_url}/", timeout=timeout)
            return response.status_code == 200
        except requests.exceptions.RequestException:
            return False
    
    def get_queue_status(self) -> Optional[Dict]:
        """
        è·å–é˜Ÿåˆ—çŠ¶æ€
        
        è¿”å›:
            é˜Ÿåˆ—çŠ¶æ€å­—å…¸æˆ–None
        """
        try:
            response = requests.get(self.api_queue, timeout=10)
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            print(f"âš ï¸ è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}")
        return None
    
    def check_task_in_queue(self, prompt_id: str) -> str:
        """
        æ£€æŸ¥ä»»åŠ¡æ˜¯å¦åœ¨é˜Ÿåˆ—ä¸­
        
        è¿”å›:
            "running" - æ­£åœ¨æ‰§è¡Œ
            "pending" - ç­‰å¾…ä¸­
            "not_found" - ä¸åœ¨é˜Ÿåˆ—ä¸­
            "error" - æ£€æŸ¥å¤±è´¥
        """
        try:
            queue_data = self.get_queue_status()
            if not queue_data:
                return "error"
            
            # æ£€æŸ¥æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
            for task in queue_data.get("queue_running", []):
                if len(task) > 1 and task[1] == prompt_id:
                    return "running"
            
            # æ£€æŸ¥ç­‰å¾…ä¸­çš„ä»»åŠ¡
            for task in queue_data.get("queue_pending", []):
                if len(task) > 1 and task[1] == prompt_id:
                    return "pending"
            
            return "not_found"
            
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥é˜Ÿåˆ—å¤±è´¥: {e}")
            return "error"
    
    def check_history_api(self, prompt_id: str, max_items: int = 5) -> Dict:
        """
        æ£€æŸ¥å†å²è®°å½•ä¸­çš„ä»»åŠ¡çŠ¶æ€
        
        è¿”å›çŠ¶æ€å­—å…¸:
        {
            "status": "success" | "interrupted" | "error" | "not_found",
            "completed": bool,
            "has_error": bool,
            "message": str
        }
        """
        try:
            response = requests.get(f"{self.api_history}?max_items={max_items}", timeout=10)
            if response.status_code == 200:
                history_data = response.json()
                
                # æŸ¥æ‰¾ç‰¹å®šä»»åŠ¡
                for task_id, task_info in history_data.items():
                    if task_id == prompt_id:
                        status_info = task_info.get("status", {})
                        
                        # 1. æˆåŠŸå®Œæˆ
                        if status_info.get("status_str") == "success" and status_info.get("completed", False):
                            return {
                                "status": "success",
                                "completed": True,
                                "has_error": False,
                                "message": "ä»»åŠ¡æˆåŠŸå®Œæˆ"
                            }
                        
                        # 2. ä¸­æ–­
                        messages = status_info.get("messages", [])
                        is_interrupted = any(msg[0] == "execution_interrupted" for msg in messages)
                        
                        if is_interrupted or (status_info.get("status_str") == "error" and not status_info.get("completed", False)):
                            return {
                                "status": "interrupted",
                                "completed": False,
                                "has_error": True,
                                "message": "ä»»åŠ¡è¢«ä¸­æ–­"
                            }
                        
                        # 3. é”™è¯¯
                        if status_info.get("status_str") == "error":
                            return {
                                "status": "error",
                                "completed": status_info.get("completed", False),
                                "has_error": True,
                                "message": "ä»»åŠ¡æ‰§è¡Œé”™è¯¯"
                            }
                
                # ä»»åŠ¡ä¸åœ¨å†å²è®°å½•ä¸­
                return {
                    "status": "not_found",
                    "completed": False,
                    "has_error": False,
                    "message": "ä»»åŠ¡ä¸åœ¨å†å²è®°å½•ä¸­"
                }
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥å†å²APIå¤±è´¥: {e}")
        
        return {
            "status": "error",
            "completed": False,
            "has_error": True,
            "message": "æ£€æŸ¥å†å²è®°å½•å¤±è´¥"
        }
    
    def get_task_status(self, prompt_id: str) -> Dict:
        """
        ç»¼åˆæ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        
        è¿”å›çŠ¶æ€å­—å…¸:
        {
            "status": "success" | "interrupted" | "error" | "running" | "pending" | "unknown",
            "in_queue": bool,
            "in_history": bool,
            "is_completed": bool,
            "message": str
        }
        """
        # 1. å…ˆæ£€æŸ¥é˜Ÿåˆ—
        queue_status = self.check_task_in_queue(prompt_id)
        
        if queue_status == "running":
            return {
                "status": "running",
                "in_queue": True,
                "in_history": False,
                "is_completed": False,
                "message": "ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­"
            }
        elif queue_status == "pending":
            return {
                "status": "pending",
                "in_queue": True,
                "in_history": False,
                "is_completed": False,
                "message": "ä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ç­‰å¾…"
            }
        elif queue_status == "not_found":
            # 2. ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œæ£€æŸ¥å†å²è®°å½•
            history_result = self.check_history_api(prompt_id)
            
            if history_result["status"] == "success":
                return {
                    "status": "success",
                    "in_queue": False,
                    "in_history": True,
                    "is_completed": True,
                    "message": history_result["message"]
                }
            elif history_result["status"] in ["interrupted", "error"]:
                return {
                    "status": history_result["status"],
                    "in_queue": False,
                    "in_history": True,
                    "is_completed": history_result["completed"],
                    "message": history_result["message"]
                }
            else:
                # æ—¢ä¸åœ¨é˜Ÿåˆ—ä¹Ÿä¸åœ¨å†å²è®°å½•
                return {
                    "status": "unknown",
                    "in_queue": False,
                    "in_history": False,
                    "is_completed": False,
                    "message": "ä»»åŠ¡çŠ¶æ€æœªçŸ¥"
                }
        
        # é˜Ÿåˆ—æ£€æŸ¥å¤±è´¥
        return {
            "status": "unknown",
            "in_queue": False,
            "in_history": False,
            "is_completed": False,
            "message": "æ— æ³•è·å–ä»»åŠ¡çŠ¶æ€"
        }
    
    def smart_wait_for_completion(self, prompt_id: str, video_path: str, max_retries: int = 3) -> Tuple[bool, bool, int]:
        """
        æ™ºèƒ½ç­‰å¾…ä»»åŠ¡å®Œæˆ
        
        è¿”å›:
            (success: bool, need_restart: bool, retry_count: int)
        """
        video_name = os.path.basename(video_path)
        print(f"â³ ç­‰å¾…ä»»åŠ¡ {prompt_id} å®Œæˆ...")
        
        start_time = time.time()
        max_wait_time = 3600  # 1å°æ—¶
        poll_interval = 5
        
        retry_count = 0
        last_status = ""
        
        while time.time() - start_time < max_wait_time:
            # æ£€æŸ¥ComfyUIæœåŠ¡æ˜¯å¦å¯ç”¨
            if not self.check_comfyui_server():
                print("âŒ ComfyUIæœåŠ¡ä¸å¯ç”¨ï¼Œéœ€è¦é‡å¯")
                return False, True, retry_count
            
            # è·å–ä»»åŠ¡çŠ¶æ€
            task_status = self.get_task_status(prompt_id)
            current_status = task_status["status"]
            
            # è¾“å‡ºçŠ¶æ€å˜åŒ–
            if current_status != last_status:
                status_messages = {
                    "running": "â–¶ï¸ ä»»åŠ¡æ‰§è¡Œä¸­",
                    "pending": "â³ ä»»åŠ¡æ’é˜Ÿä¸­", 
                    "success": "âœ… ä»»åŠ¡æˆåŠŸå®Œæˆ",
                    "interrupted": "â¹ï¸ ä»»åŠ¡è¢«ä¸­æ–­",
                    "error": "âŒ ä»»åŠ¡æ‰§è¡Œé”™è¯¯",
                    "unknown": "â“ ä»»åŠ¡çŠ¶æ€æœªçŸ¥"
                }
                message = status_messages.get(current_status, current_status)
                print(f"[{time.strftime('%H:%M:%S')}] {message}")
                last_status = current_status
            
            # å¤„ç†ä¸åŒçŠ¶æ€
            if current_status == "success":
                print(f"âœ… ä»»åŠ¡ {prompt_id} æˆåŠŸå®Œæˆ")
                return True, False, retry_count
            
            elif current_status == "interrupted":
                print(f"â¹ï¸ ä»»åŠ¡è¢«ä¸­æ–­ï¼Œå°†é‡è¯• (é‡è¯• {retry_count + 1}/{max_retries})")
                retry_count += 1
                if retry_count >= max_retries:
                    print(f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                    return False, False, retry_count
                else:
                    # æ¸…ç†è¾“å‡ºæ–‡ä»¶åé‡è¯•
                    self.clean_output_files(video_path)
                    return False, False, retry_count
            
            elif current_status == "error":
                print(f"âŒ ä»»åŠ¡æ‰§è¡Œé”™è¯¯ï¼Œå°†é‡è¯• (é‡è¯• {retry_count + 1}/{max_retries})")
                retry_count += 1
                if retry_count >= max_retries:
                    print(f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                    return False, False, retry_count
                else:
                    self.clean_output_files(video_path)
                    return False, False, retry_count
            
            elif current_status in ["running", "pending"]:
                # ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­ï¼Œç»§ç»­ç­‰å¾…
                time.sleep(poll_interval)
                continue
            
            elif current_status == "unknown":
                # çŠ¶æ€æœªçŸ¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–ä»»åŠ¡è¢«ç³»ç»Ÿç§»é™¤
                print("âš ï¸ ä»»åŠ¡çŠ¶æ€æœªçŸ¥ï¼Œç­‰å¾…åé‡æ–°æ£€æŸ¥...")
                time.sleep(poll_interval * 2)
                continue
        
        # è¶…æ—¶
        print(f"â° ä»»åŠ¡ {prompt_id} ç­‰å¾…è¶…æ—¶")
        retry_count += 1
        return False, False, retry_count
    
    def clean_output_files(self, video_path: str):
        """æ¸…ç†æŒ‡å®šè§†é¢‘çš„è¾“å‡ºæ–‡ä»¶"""
        video_name = os.path.basename(video_path)
        base_name = os.path.splitext(video_name)[0]
        print(f"ğŸ§¹ æ¸…ç† {video_name} çš„è¾“å‡ºæ–‡ä»¶...")
        
        try:
            patterns = [
                f"flashvsr_{base_name}_enhanced*.mp4",
                f"flashvsr_{base_name}_enhanced*.png",
                f"*{base_name}*.mp4",
                f"*{base_name}*.png",
            ]
            
            deleted_count = 0
            for pattern in patterns:
                full_pattern = os.path.join(self.output_dir, pattern)
                for file_path in glob(full_pattern):
                    try:
                        filename = os.path.basename(file_path)
                        if base_name in filename:
                            os.remove(file_path)
                            deleted_count += 1
                    except Exception:
                        pass
            
            if deleted_count > 0:
                print(f"âœ… å·²æ¸…ç† {deleted_count} ä¸ªè¾“å‡ºæ–‡ä»¶")
            else:
                print("â„¹ï¸ æœªæ‰¾åˆ°éœ€è¦æ¸…ç†çš„è¾“å‡ºæ–‡ä»¶")
                
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def get_video_frame_count(self, video_path: str) -> Tuple[int, float, str]:
        """è·å–è§†é¢‘çš„æ€»å¸§æ•°ã€å¸§ç‡å’Œæ£€æµ‹æ–¹æ³•"""
        try:
            if PYMEDIAINFO_AVAILABLE:
                media_info = MediaInfo.parse(video_path)
                for track in media_info.tracks:
                    if track.track_type == 'Video':
                        frame_count = 0
                        if hasattr(track, 'frame_count') and track.frame_count:
                            frame_count = int(track.frame_count)
                        
                        frame_rate = 25.0
                        if hasattr(track, 'frame_rate') and track.frame_rate:
                            try:
                                frame_rate_str = str(track.frame_rate)
                                if '/' in frame_rate_str:
                                    numerator, denominator = map(float, frame_rate_str.split('/'))
                                    frame_rate = numerator / denominator
                                else:
                                    frame_rate = float(frame_rate_str)
                            except:
                                frame_rate = 25.0
                        
                        if frame_count > 0:
                            return frame_count, frame_rate, "pymediainfo"
            
            # å¤‡ç”¨æ–¹æ³•
            try:
                import cv2
                cap = cv2.VideoCapture(video_path)
                if cap.isOpened():
                    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    cap.release()
                    
                    if frame_count > 0 and fps > 0:
                        return frame_count, fps, "OpenCV"
            except ImportError:
                pass
            
            print(f"âš ï¸  æ— æ³•è·å– {os.path.basename(video_path)} çš„å‡†ç¡®å¸§æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return 100, 25.0, "é»˜è®¤å€¼"
            
        except Exception as e:
            print(f"âš ï¸  è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥ {os.path.basename(video_path)}: {e}")
            return 100, 25.0, "é”™è¯¯-é»˜è®¤å€¼"
    
    def load_workflow_template(self, template_path: str) -> Dict:
        """åŠ è½½å·¥ä½œæµ JSON æ¨¡æ¿"""
        with open(template_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def update_workflow_parameters(
        self, 
        workflow: Dict, 
        video_path: str, 
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 201,
        gpu_device: str = "auto"
    ) -> Dict:
        """
        æ›´æ–°å·¥ä½œæµä¸­çš„æ‰€æœ‰å‚æ•° - å…¼å®¹æ€§ä¿®æ­£ç‰ˆ
        æ”¯æŒå ä½ç¬¦æ›¿æ¢å’Œç›´æ¥èµ‹å€¼
        """
        modified_workflow = json.loads(json.dumps(workflow))
        
        print("=== å·¥ä½œæµå‚æ•°æ›´æ–°å¼€å§‹ ===")
        
        # 1. è®¾ç½®è¾“å…¥è§†é¢‘è·¯å¾„
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_LoadVideo":
                current_video = node_data["inputs"].get("video", "")
                if "{{VIDEO_PATH}}" in str(current_video):
                    node_data["inputs"]["video"] = video_path
                    print(f"âœ… å·²è®¾ç½®è§†é¢‘è·¯å¾„: {video_path}")
                elif isinstance(node_data["inputs"].get("video"), str):
                    node_data["inputs"]["video"] = video_path
                    print(f"âœ… å·²è®¾ç½®è§†é¢‘è·¯å¾„: {video_path} (ç›´æ¥èµ‹å€¼)")
        
        # 2. è®¾ç½® FlashVSR æ ¸å¿ƒå‚æ•° - æ£€æŸ¥å ä½ç¬¦
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "FlashVSRNodeAdv":
                # æ£€æŸ¥scaleå‚æ•°
                current_scale = str(node_data["inputs"].get("scale", ""))
                if "{{scale}}" in current_scale:
                    node_data["inputs"]["scale"] = scale
                    print(f"âœ… å·²è®¾ç½®ç¼©æ”¾æ¯”ä¾‹: {scale}")
                elif isinstance(node_data["inputs"].get("scale"), (int, float, str)):
                    try:
                        node_data["inputs"]["scale"] = float(scale)
                        print(f"âœ… å·²è®¾ç½®ç¼©æ”¾æ¯”ä¾‹: {scale} (ç›´æ¥èµ‹å€¼)")
                    except:
                        pass
                
                # æ£€æŸ¥tile_sizeå‚æ•°
                current_tile_size = str(node_data["inputs"].get("tile_size", ""))
                if "{{t_z}}" in current_tile_size or "{{tile_size}}" in current_tile_size:
                    node_data["inputs"]["tile_size"] = tile_size
                    print(f"âœ… å·²è®¾ç½®åˆ†å—å¤§å°: {tile_size}")
                elif isinstance(node_data["inputs"].get("tile_size"), (int, float, str)):
                    try:
                        node_data["inputs"]["tile_size"] = int(tile_size)
                        print(f"âœ… å·²è®¾ç½®åˆ†å—å¤§å°: {tile_size} (ç›´æ¥èµ‹å€¼)")
                    except:
                        pass
                
                # æ£€æŸ¥tile_overlapå‚æ•°
                current_tile_overlap = str(node_data["inputs"].get("tile_overlap", ""))
                if "{{t_o}}" in current_tile_overlap or "{{tile_overlap}}" in current_tile_overlap:
                    node_data["inputs"]["tile_overlap"] = tile_overlap
                    print(f"âœ… å·²è®¾ç½®åˆ†å—é‡å : {tile_overlap}")
                elif isinstance(node_data["inputs"].get("tile_overlap"), (int, float, str)):
                    try:
                        node_data["inputs"]["tile_overlap"] = int(tile_overlap)
                        print(f"âœ… å·²è®¾ç½®åˆ†å—é‡å : {tile_overlap} (ç›´æ¥èµ‹å€¼)")
                    except:
                        pass
        
        # 3. è®¾ç½® GPU è®¾å¤‡ - æ£€æŸ¥å ä½ç¬¦
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "FlashVSRInitPipe":
                current_device = str(node_data["inputs"].get("device", ""))
                if "{{gpu}}" in current_device:
                    if gpu_device == "auto":
                        device_value = "auto"
                    elif gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    node_data["inputs"]["device"] = device_value
                    print(f"âœ… å·²è®¾ç½®GPUè®¾å¤‡: {device_value}")
                elif isinstance(node_data["inputs"].get("device"), str):
                    if gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    node_data["inputs"]["device"] = device_value
                    print(f"âœ… å·²è®¾ç½®GPUè®¾å¤‡: {device_value} (ç›´æ¥èµ‹å€¼)")
        
        # 4. è®¾ç½®æ€»å¸§æ•° - æ£€æŸ¥å ä½ç¬¦
        if total_frames is None:
            total_frames, _, _ = self.get_video_frame_count(video_path)
            print(f"ğŸ“Š è‡ªåŠ¨æ£€æµ‹åˆ°è§†é¢‘æ€»å¸§æ•°: {total_frames}")
        
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "PrimitiveInt":
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ€»å¸§æ•°èŠ‚ç‚¹ï¼ˆèŠ‚ç‚¹50ï¼‰
                if node_id == "50":
                    current_value = str(node_data["inputs"].get("value", ""))
                    if "{{TOTAL_FRAMES}}" in current_value or "{{TATAL_FRAMES}}" in current_value:
                        node_data["inputs"]["value"] = total_frames
                        print(f"âœ… å·²è®¾ç½®æ€»å¸§æ•°: {total_frames} åˆ°èŠ‚ç‚¹ 50")
                    elif isinstance(node_data["inputs"].get("value"), (int, float, str)):
                        try:
                            node_data["inputs"]["value"] = int(total_frames)
                            print(f"âœ… å·²è®¾ç½®æ€»å¸§æ•°: {total_frames} åˆ°èŠ‚ç‚¹ 50 (ç›´æ¥èµ‹å€¼)")
                        except:
                            pass
                    else:
                        print(f"âš ï¸  èŠ‚ç‚¹ 50 çš„å€¼æ ¼å¼å¼‚å¸¸: {current_value}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¯æ‰¹å¸§æ•°èŠ‚ç‚¹ï¼ˆèŠ‚ç‚¹8ï¼‰
                elif node_id == "8":
                    current_value = str(node_data["inputs"].get("value", ""))
                    if "{{FRAMES_PER_BATCH}}" in current_value:
                        node_data["inputs"]["value"] = frames_per_batch
                        print(f"âœ… å·²è®¾ç½®æ¯æ‰¹å¸§æ•°: {frames_per_batch} åˆ°èŠ‚ç‚¹ 8")
                    elif isinstance(node_data["inputs"].get("value"), (int, float, str)):
                        try:
                            node_data["inputs"]["value"] = int(frames_per_batch)
                            print(f"âœ… å·²è®¾ç½®æ¯æ‰¹å¸§æ•°: {frames_per_batch} åˆ°èŠ‚ç‚¹ 8 (ç›´æ¥èµ‹å€¼)")
                        except:
                            pass
                    else:
                        print(f"âš ï¸  èŠ‚ç‚¹ 8 çš„å€¼æ ¼å¼å¼‚å¸¸: {current_value}")
        
        # 5. è®¾ç½®è¾“å‡ºæ–‡ä»¶åå‰ç¼€ - æ£€æŸ¥å ä½ç¬¦
        if output_prefix is None:
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            output_prefix = f"flashvsr_{base_name}_enhanced"
        
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_VideoCombine":
                current_prefix = str(node_data["inputs"].get("filename_prefix", ""))
                if "{{OUTPUT_PREFIX}}" in current_prefix:
                    node_data["inputs"]["filename_prefix"] = output_prefix
                    print(f"âœ… å·²è®¾ç½®è¾“å‡ºå‰ç¼€: {output_prefix}")
                elif isinstance(node_data["inputs"].get("filename_prefix"), str):
                    node_data["inputs"]["filename_prefix"] = output_prefix
                    print(f"âœ… å·²è®¾ç½®è¾“å‡ºå‰ç¼€: {output_prefix} (ç›´æ¥èµ‹å€¼)")
        
        print("=== å·¥ä½œæµå‚æ•°æ›´æ–°å®Œæˆ ===")
        return modified_workflow
    
    def queue_prompt(self, workflow: Dict, timeout: int = 300) -> Optional[str]:
        """å°†å·¥ä½œæµå‘é€åˆ° ComfyUI æ‰§è¡Œ - å¸¦è¯¦ç»†è°ƒè¯•ä¿¡æ¯"""
        if not self.check_comfyui_server():
            print("âŒ ComfyUI æœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•æäº¤ä»»åŠ¡")
            return None

        print("=== å·¥ä½œæµå‚æ•°éªŒè¯ ===")
        # éªŒè¯å…³é”®èŠ‚ç‚¹
        key_nodes = ["5", "8", "50", "49", "62"]
        for node_id in key_nodes:
            if node_id in workflow:
                node_data = workflow[node_id]
                node_type = node_data.get("class_type", "Unknown")
                inputs = node_data.get("inputs", {})
                print(f"èŠ‚ç‚¹ {node_id} ({node_type}):")
                
                for key in ["device", "value", "video", "filename_prefix", "scale", "tile_size", "tile_overlap"]:
                    if key in inputs:
                        print(f"  {key}: {inputs[key]}")
        
        try:
            print(f"ğŸ“¤ æ­£åœ¨æäº¤ä»»åŠ¡åˆ°: {self.api_prompt}")
            print(f"ğŸ“¦ å·¥ä½œæµå¤§å°: {len(str(workflow))} å­—ç¬¦")
            
            response = requests.post(
                self.api_prompt, 
                json={"prompt": workflow}, 
                timeout=timeout,
                headers={'Content-Type': 'application/json'}
            )
            
            print(f"ğŸ“¥ å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                prompt_id = data.get('prompt_id')
                
                if prompt_id:
                    print(f"âœ… ä»»åŠ¡å·²æäº¤ï¼ŒID: {prompt_id}")
                    return prompt_id
                else:
                    print(f"âŒ æœªæ”¶åˆ°ä»»åŠ¡IDï¼Œå®Œæ•´å“åº”: {data}")
                    return None
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"ğŸ“„ é”™è¯¯è¯¦æƒ…: {response.text[:500]}")
                
                # å¦‚æœæ”¶åˆ°400é”™è¯¯ï¼Œå¯èƒ½æ˜¯å·¥ä½œæµæ ¼å¼é—®é¢˜
                if response.status_code == 400:
                    print("ğŸ” åˆ†æ400é”™è¯¯å¯èƒ½çš„åŸå› :")
                    print("  1. å·¥ä½œæµä¸­å­˜åœ¨æœªæ›¿æ¢çš„å ä½ç¬¦ï¼ˆå¦‚{{gpu}}ã€{{TOTAL_FRAMES}}ï¼‰")
                    print("  2. å·¥ä½œæµæ ¼å¼ä¸ç¬¦åˆComfyUIè¦æ±‚")
                    print("  3. æŸäº›èŠ‚ç‚¹å‚æ•°ç±»å‹ä¸æ­£ç¡®")
                    
                    # æ£€æŸ¥å·¥ä½œæµä¸­æ˜¯å¦è¿˜æœ‰å ä½ç¬¦
                    workflow_str = json.dumps(workflow)
                    placeholder_patterns = ["{{gpu}}", "{{TOTAL_FRAMES}}", "{{FRAMES_PER_BATCH}}", 
                                          "{{OUTPUT_PREFIX}}", "{{VIDEO_PATH}}", "{{scale}}"]
                    
                    for pattern in placeholder_patterns:
                        if pattern in workflow_str:
                            print(f"âš ï¸  å‘ç°æœªæ›¿æ¢çš„å ä½ç¬¦: {pattern}")
                
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            return None
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±è´¥: {e}")
            return None
    
    def get_output_files(self, prompt_id: str) -> List[str]:
        """è·å–ä»»åŠ¡ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶åˆ—è¡¨"""
        try:
            response = requests.get(f"{self.api_view}/{prompt_id}", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                outputs = data.get("outputs", {})
                file_list = []
                
                for node_id, node_output in outputs.items():
                    if "images" in node_output:
                        for img in node_output["images"]:
                            if "filename" in img:
                                file_list.append(img["filename"])
                
                return file_list
                
        except Exception as e:
            print(f"âš ï¸ è·å–è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
        
        return []
    
    def process_video_with_retry(
        self,
        workflow_template: Dict,
        video_path: str,
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 125,
        gpu_device: str = "auto",
        max_retries: int = 3
    ) -> Tuple[bool, int, str]:
        """
        å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œæ”¯æŒæ™ºèƒ½é‡è¯•
        
        è¿”å›:
            (success: bool, retry_count: int, final_prompt_id: str)
        """
        video_name = os.path.basename(video_path)
        print(f"\n{'='*60}")
        print(f"å¤„ç†è§†é¢‘: {video_path}")
        print(f"{'='*60}")
        
        retry_count = 0
        current_prompt_id = None
        
        while retry_count < max_retries:
            retry_count += 1
            print(f"\nğŸ”„ å°è¯• {retry_count}/{max_retries}")
            
            # 1. æ£€æŸ¥å¹¶ç¡®ä¿ComfyUIæ­£åœ¨è¿è¡Œ
            if not self.check_comfyui_server():
                print("âŒ ComfyUIæœåŠ¡æœªè¿è¡Œï¼Œæ­£åœ¨å¯åŠ¨...")
                if not self.start_comfyui():
                    print("âŒ æ— æ³•å¯åŠ¨ComfyUIï¼Œè·³è¿‡æ­¤è§†é¢‘")
                    return False, retry_count, ""
            
            # 2. æ›´æ–°å·¥ä½œæµå‚æ•°å¹¶æäº¤ä»»åŠ¡
            workflow = self.update_workflow_parameters(
                workflow_template, 
                video_path, 
                output_prefix,
                scale=scale,
                tile_size=tile_size,
                tile_overlap=tile_overlap,
                total_frames=total_frames,
                frames_per_batch=frames_per_batch,
                gpu_device=gpu_device
            )
            
            current_prompt_id = self.queue_prompt(workflow)
            if not current_prompt_id:
                print(f"âŒ ä»»åŠ¡æäº¤å¤±è´¥ï¼Œå°†é‡è¯•")
                if retry_count < max_retries:
                    print("â³ 5ç§’åé‡è¯•...")
                    time.sleep(5)
                    continue
                return False, retry_count, ""
            
            # 3. æ™ºèƒ½ç­‰å¾…ä»»åŠ¡å®Œæˆ
            success, need_restart, wait_retries = self.smart_wait_for_completion(
                current_prompt_id, 
                video_path,
                max_retries - retry_count + 1  # å‰©ä½™é‡è¯•æ¬¡æ•°
            )
            
            if need_restart:
                # ComfyUIéœ€è¦é‡å¯
                print("ğŸ”„ ComfyUIéœ€è¦é‡å¯...")
                if not self.restart_comfyui():
                    print("âŒ ComfyUIé‡å¯å¤±è´¥")
                    return False, retry_count, current_prompt_id
                
                # æ¸…ç†è¾“å‡ºæ–‡ä»¶åç»§ç»­é‡è¯•
                self.clean_output_files(video_path)
                continue
            
            elif success:
                # ä»»åŠ¡æˆåŠŸå®Œæˆ
                print(f"âœ… è§†é¢‘ {video_name} å¤„ç†æˆåŠŸ")
                output_files = self.get_output_files(current_prompt_id)
                if output_files:
                    print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
                    for file in output_files:
                        print(f"  - {file}")
                return True, retry_count, current_prompt_id
            
            else:
                # ä»»åŠ¡å¤±è´¥ä½†ä¸æ˜¯å› ä¸ºComfyUIéœ€è¦é‡å¯
                print(f"âŒ è§†é¢‘ {video_name} å¤„ç†å¤±è´¥")
                
                if retry_count < max_retries:
                    print(f"â³ ç­‰å¾…5ç§’åé‡è¯•...")
                    time.sleep(5)
                    self.clean_output_files(video_path)
                    continue
                else:
                    print(f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                    return False, retry_count, current_prompt_id
        
        return False, retry_count, current_prompt_id if current_prompt_id else ""
    
    def batch_process_videos(
        self, 
        workflow_template_path: str, 
        video_files: List[str], 
        output_prefix_base: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 201,
        gpu_device: str = "auto",
        max_retries: int = 3
    ) -> Dict[str, Dict]:
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘æ–‡ä»¶
        
        è¿”å›:
            å­—å…¸ï¼š{è§†é¢‘æ–‡ä»¶: {æˆåŠŸ: bool, é‡è¯•æ¬¡æ•°: int, prompt_id: str}}
        """
        # åŠ è½½å·¥ä½œæµæ¨¡æ¿
        try:
            workflow_template = self.load_workflow_template(workflow_template_path)
            print(f"âœ… å·²åŠ è½½å·¥ä½œæµæ¨¡æ¿: {workflow_template_path}")
        except Exception as e:
            print(f"âŒ åŠ è½½å·¥ä½œæµæ¨¡æ¿å¤±è´¥: {e}")
            return {}
        
        # æ£€æŸ¥ComfyUIæœåŠ¡
        if not self.check_comfyui_server():
            print("âŒ ComfyUI æœåŠ¡æœªè¿è¡Œï¼Œæ­£åœ¨å¯åŠ¨...")
            if not self.start_comfyui():
                print("âŒ æ— æ³•å¯åŠ¨ComfyUIï¼Œç¨‹åºé€€å‡º")
                return {}
        
        results = {}
        total_videos = len(video_files)
        
        print(f"ğŸ¬ å¼€å§‹æ‰¹é‡å¤„ç† {total_videos} ä¸ªè§†é¢‘")
        print(f"âš™ï¸  å‚æ•°: scale={scale}, tile_size={tile_size}, tile_overlap={tile_overlap}")
        print(f"ğŸ® GPUè®¾å¤‡: {gpu_device}")
        print(f"ğŸ”„ æ¯ä¸ªä»»åŠ¡æœ€å¤šé‡è¯•: {max_retries}æ¬¡")
        print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ“‹ å·¥ä½œæµæ¨¡æ¿: {workflow_template_path}")
        
        for i, video_path in enumerate(video_files, 1):
            print(f"\nğŸ“Š è¿›åº¦: {i}/{total_videos}")
            
            # è®¾ç½®è¾“å‡ºå‰ç¼€
            output_prefix = None
            if output_prefix_base:
                base_name = os.path.splitext(os.path.basename(video_path))[0]
                output_prefix = f"{output_prefix_base}_{base_name}"
            
            # å¤„ç†å•ä¸ªè§†é¢‘
            success, retry_count, prompt_id = self.process_video_with_retry(
                workflow_template, 
                video_path, 
                output_prefix,
                scale=scale,
                tile_size=tile_size,
                tile_overlap=tile_overlap,
                total_frames=total_frames,
                frames_per_batch=frames_per_batch,
                gpu_device=gpu_device,
                max_retries=max_retries
            )
            
            results[video_path] = {
                "success": success,
                "retry_count": retry_count,
                "prompt_id": prompt_id,
                "message": "æˆåŠŸ" if success else f"å¤±è´¥ï¼ˆé‡è¯•{retry_count}æ¬¡ï¼‰"
            }
            
            if not success:
                print(f"âš ï¸ è§†é¢‘ {os.path.basename(video_path)} å¤„ç†å¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª")
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'='*60}")
        print("æ‰¹é‡å¤„ç†å®Œæˆ")
        print(f"{'='*60}")
        
        success_count = sum(1 for r in results.values() if r["success"])
        total_retries = sum(r["retry_count"] for r in results.values())
        
        print(f"âœ… æˆåŠŸ: {success_count}/{total_videos}")
        print(f"âŒ å¤±è´¥: {total_videos - success_count}/{total_videos}")
        print(f"ğŸ”„ æ€»é‡è¯•æ¬¡æ•°: {total_retries}")
        
        return results

def collect_video_files(input_path: str, pattern: str = '*.mp4') -> List[str]:
    """æ ¹æ®è¾“å…¥è·¯å¾„æ”¶é›†è§†é¢‘æ–‡ä»¶"""
    video_files = []
    
    if os.path.isfile(input_path):
        if input_path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv')):
            video_files.append(input_path)
            print(f"âœ… æ·»åŠ å•ä¸ªæ–‡ä»¶: {input_path}")
        else:
            print(f"âŒ æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ: {input_path}")
    elif os.path.isdir(input_path):
        search_pattern = os.path.join(input_path, pattern)
        found_files = glob(search_pattern)
        
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', '.MP4', '.MOV', '.AVI', '.MKV']
        for ext in video_extensions:
            if ext not in pattern:
                additional_pattern = os.path.join(input_path, f"*{ext}")
                additional_files = glob(additional_pattern)
                found_files.extend(additional_files)
        
        video_files = sorted(list(set(found_files)))
        
        if not video_files:
            print(f"âŒ ç›®å½• {input_path} ä¸­æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        else:
            print(f"âœ… ä»ç›®å½• {input_path} æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    else:
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    return video_files

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· - å¢å¼ºä»»åŠ¡ç›‘æ§ç‰ˆï¼ˆä¿®æ­£ç‰ˆï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨GPU 0
  python batch_process_videos.py --input video.mp4 --gpu 0
  
  # å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨GPU 1
  python batch_process_videos.py --input ./videos --gpu 1
  
  # è‡ªåŠ¨é€‰æ‹©GPU
  python batch_process_videos.py --input ./videos --gpu auto
  
  # è‡ªå®šä¹‰é‡è¯•æ¬¡æ•°
  python batch_process_videos.py --input ./videos --max-retries 5 --gpu 0

ä¸»è¦æ”¹è¿›:
  - ä¿®å¤å ä½ç¬¦æ›¿æ¢é—®é¢˜ï¼ˆæ”¯æŒ {{gpu}}, {{TOTAL_FRAMES}}, {{FRAMES_PER_BATCH}} ç­‰ï¼‰
  - å¢å¼ºè°ƒè¯•ä¿¡æ¯è¾“å‡º
  - æ™ºèƒ½ä»»åŠ¡çŠ¶æ€ç›‘æ§ï¼ˆä½¿ç”¨é˜Ÿåˆ—APIå’Œå†å²APIï¼‰
  - è‡ªåŠ¨åŒºåˆ†ä»»åŠ¡çŠ¶æ€ï¼šè¿è¡Œä¸­ã€æ’é˜Ÿä¸­ã€æˆåŠŸã€ä¸­æ–­ã€é”™è¯¯
  - å¤±è´¥æ—¶è‡ªåŠ¨é‡è¯•ï¼Œæœ€å¤šé‡è¯•3æ¬¡ï¼ˆå¯é…ç½®ï¼‰
  - å½“ComfyUIæœåŠ¡ä¸å¯ç”¨æ—¶è‡ªåŠ¨é‡å¯
  - é‡å¯å‰æ¸…ç†å½“å‰è§†é¢‘çš„è¾“å‡ºæ–‡ä»¶
  - é‡å¯åç»§ç»­å¤„ç†å½“å‰è§†é¢‘
        """
    )
    
    # è¾“å…¥å‚æ•°
    parser.add_argument('--template', type=str, default='flashvsr_template.json',
                       help='å·¥ä½œæµæ¨¡æ¿ JSON æ–‡ä»¶è·¯å¾„ (é»˜è®¤: flashvsr_template.json)')
    parser.add_argument('--input', type=str, required=True,
                       help='è¾“å…¥è·¯å¾„ï¼ˆå¯ä»¥æ˜¯è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–åŒ…å«è§†é¢‘æ–‡ä»¶çš„ç›®å½•ï¼‰')
    parser.add_argument('--pattern', type=str, default='*.mp4',
                       help='è§†é¢‘æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œå½“è¾“å…¥æ˜¯ç›®å½•æ—¶ä½¿ç”¨ (é»˜è®¤: *.mp4)')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output-prefix', type=str, 
                       help='è¾“å‡ºæ–‡ä»¶åå‰ç¼€ï¼ˆå¯é€‰ï¼Œç”¨äºåŒºåˆ†æ‰¹æ¬¡ï¼‰')
    
    # FlashVSR å¤„ç†å‚æ•°
    parser.add_argument('--scale', type=float, default=4.0,
                       help='æ”¾å¤§å€æ•° (é»˜è®¤: 4.0)')
    parser.add_argument('--tile-size', type=int, default=256,
                       help='åˆ†å—å¤§å° (é»˜è®¤: 256)')
    parser.add_argument('--tile-overlap', type=int, default=24,
                       help='åˆ†å—é‡å åƒç´  (é»˜è®¤: 24)')
    parser.add_argument('--frames-per-batch', type=int, default=201,
                       help='æ¯æ‰¹å¤„ç†çš„å¸§æ•° (é»˜è®¤: 201)')
    parser.add_argument('--total-frames', type=int,
                       help='è§†é¢‘æ€»å¸§æ•° (å¦‚ä¸æä¾›åˆ™è‡ªåŠ¨æ£€æµ‹)')
    
    # é‡è¯•å‚æ•°
    parser.add_argument('--max-retries', type=int, default=3,
                       help='æ¯ä¸ªä»»åŠ¡çš„æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)')
    
    # GPUå‚æ•°
    parser.add_argument('--gpu', type=str, default='auto',
                       help='GPUè®¾å¤‡é€‰æ‹©: auto, 0, 1, 2, cuda:0, cuda:1ç­‰ (é»˜è®¤: auto)')
    
    # ç³»ç»Ÿå‚æ•°
    parser.add_argument('--server', type=str, default='http://127.0.0.1:8188',
                       help='ComfyUI æœåŠ¡å™¨åœ°å€ (é»˜è®¤: http://127.0.0.1:8188)')
    parser.add_argument('--skip-pymedia-check', action='store_true',
                       help='è·³è¿‡ pymediainfo æ£€æŸ¥')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ pymediainfo
    if not PYMEDIAINFO_AVAILABLE and not args.skip_pymedia_check:
        print("âš ï¸  æœªæ£€æµ‹åˆ° pymediainfo åº“")
        response = input("æ˜¯å¦ç»§ç»­? (y/n): ")
        if response.lower() != 'y':
            print("é€€å‡ºç¨‹åº")
            return
    
    # å‡†å¤‡è§†é¢‘æ–‡ä»¶åˆ—è¡¨
    video_files = collect_video_files(args.input, args.pattern)
    
    if not video_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        return
    
    print(f"\næ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶:")
    for vf in video_files:
        print(f"  - {vf}")
    
    # æ˜¾ç¤ºå¤„ç†å‚æ•°
    print(f"\nâš™ï¸  å¤„ç†å‚æ•°:")
    print(f"  scale: {args.scale}")
    print(f"  tile_size: {args.tile_size}")
    print(f"  tile_overlap: {args.tile_overlap}")
    print(f"  frames_per_batch: {args.frames_per_batch}")
    print(f"  max_retries: {args.max_retries}")
    
    if args.total_frames:
        print(f"  total_frames: {args.total_frames} (æ‰‹åŠ¨æŒ‡å®š)")
    else:
        print(f"  total_frames: è‡ªåŠ¨æ£€æµ‹")
    
    if args.output_prefix:
        print(f"  output_prefix: {args.output_prefix} (è¾“å‡ºæ–‡ä»¶åå‰ç¼€)")
    
    if args.gpu == "auto":
        print(f"ğŸ® GPUè®¾å¤‡: auto (è‡ªåŠ¨é€‰æ‹©)")
    elif args.gpu.isdigit():
        print(f"ğŸ® GPUè®¾å¤‡: cuda:{args.gpu}")
    else:
        print(f"ğŸ® GPUè®¾å¤‡: {args.gpu}")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = ComfyUI_FlashVSR_BatchProcessor(comfyui_url=args.server)
    
    # æ‰¹é‡å¤„ç†
    start_time = time.time()
    
    results = processor.batch_process_videos(
        workflow_template_path=args.template,
        video_files=video_files,
        output_prefix_base=args.output_prefix,
        scale=args.scale,
        tile_size=args.tile_size,
        tile_overlap=args.tile_overlap,
        total_frames=args.total_frames,
        frames_per_batch=args.frames_per_batch,
        gpu_device=args.gpu,
        max_retries=args.max_retries
    )
    
    # è®¡ç®—æ€»è€—æ—¶
    total_time = time.time() - start_time
    print(f"\nâ±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’")
    
    # æœ€åå…³é—­ComfyUIè¿›ç¨‹
    print(f"\nğŸ”§ å¤„ç†å®Œæˆï¼Œæ­£åœ¨å…³é—­ComfyUIè¿›ç¨‹...")
    processor.kill_comfyui_processes()
    print("âœ… æ‰€æœ‰å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()
