#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· - å¢å¼ºç‰ˆ v25.1
æ”¹è¿›åŠŸèƒ½ï¼š
1. æ™ºèƒ½ComfyUIçŠ¶æ€ç›‘æ§ï¼Œå¸¦è¶…æ—¶é‡è¯•æœºåˆ¶
2. ç®€åŒ–çš„å†…å­˜æ¸…ç†åŠŸèƒ½ï¼Œç›´æ¥è°ƒç”¨ç³»ç»Ÿå‘½ä»¤
"""

import json
import requests
import os
import time
import sys
import math
import re
import subprocess
import threading
import signal
from glob import glob
from typing import List, Dict, Optional, Tuple, Union
from pathlib import Path
import psutil
import traceback

# å°è¯•å¯¼å…¥ pymediainfo
try:
    from pymediainfo import MediaInfo
    PYMEDIAINFO_AVAILABLE = True
except ImportError:
    PYMEDIAINFO_AVAILABLE = False
    print("âš ï¸  pymediainfo æœªå®‰è£…ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è·å–è§†é¢‘ä¿¡æ¯")

class ComfyUI_FlashVSR_BatchProcessor:
    def __init__(self, comfyui_url: str = "http://127.0.0.1:8188"):
        """
        åˆå§‹åŒ– ComfyUI FlashVSR æ‰¹é‡å¤„ç†å™¨
        
        å‚æ•°:
            comfyui_url: ComfyUI æœåŠ¡å™¨åœ°å€
        """
        self.comfyui_url = comfyui_url.rstrip('/')
        self.api_prompt = f"{comfyui_url}/prompt"
        self.api_history = f"{comfyui_url}/history"
        self.api_view = f"{comfyui_url}/view"
        self.api_queue = f"{comfyui_url}/queue"
        
        # æ·»åŠ çŠ¶æ€è·Ÿè¸ª
        self.comfyui_process = None
        self.comfyui_path = r"F:\AI\ComfyUI_Mie_V7.0"
        self.comfyui_script = r"F:\AI\ComfyUI_Mie_V7.0\run_nvidia_gpu_fast_fp16_accumulation_hf_mirror.bat"
        self.output_dir = r"F:\AI\ComfyUI_Mie_V7.0\comfyui\output"
        
        # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
        self.log_file = os.path.join(self.comfyui_path, "batch_processing_v25_1.log")
        
        # çŠ¶æ€ç›‘æ§ç›¸å…³
        self.server_check_interval = 5  # æœåŠ¡å™¨æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        self.monitor_timeout_factor = 2  # è¶…æ—¶å› å­ï¼ŒåŸºäºframes_per_batch
        
        # å†…å­˜æ¸…ç†ç›¸å…³
        self.clean_memory_enabled = True
        self.memreduct_timeout = 300  # å†…å­˜æ¸…ç†è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self.memreduct_check_interval = 5  # å†…å­˜æ¸…ç†æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        
        print(f"ğŸ“Š æœåŠ¡å™¨æ£€æŸ¥é—´éš”: {self.server_check_interval}ç§’")
        print(f"â±ï¸  å†…å­˜æ¸…ç†è¶…æ—¶: {self.memreduct_timeout}ç§’")
        
    def save_processing_status(self, video_name: str, batch_number: int = None, action: str = None):
        """
        ä¿å­˜å¤„ç†çŠ¶æ€åˆ°æ—¥å¿—æ–‡ä»¶
        """
        try:
            timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
            with open(self.log_file, 'a', encoding='utf-8') as f:
                if batch_number is not None and action is not None:
                    f.write(f"[{timestamp}] è§†é¢‘: {video_name}, æ‰¹æ¬¡: {batch_number}, æ“ä½œ: {action}\n")
                elif batch_number is not None:
                    f.write(f"[{timestamp}] è§†é¢‘: {video_name}, æ‰¹æ¬¡: {batch_number}\n")
                else:
                    f.write(f"[{timestamp}] è§†é¢‘: {video_name}\n")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜å¤„ç†çŠ¶æ€å¤±è´¥: {e}")
    
    def kill_comfyui_processes(self):
        """å…³é—­æ‰€æœ‰ComfyUIç›¸å…³è¿›ç¨‹"""
        print("ğŸ”ª æ­£åœ¨å…³é—­ComfyUIè¿›ç¨‹...")
        self.save_processing_status("ç³»ç»Ÿ", action="å…³é—­ComfyUIè¿›ç¨‹")
        
        try:
            killed_count = 0
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = ' '.join(proc.info.get('cmdline', []))
                    if 'comfy' in cmdline.lower() or 'main.py' in cmdline:
                        print(f"  ç»ˆæ­¢è¿›ç¨‹ PID={proc.info['pid']}")
                        proc.kill()
                        killed_count += 1
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            if killed_count > 0:
                print(f"âœ… å·²ç»ˆæ­¢ {killed_count} ä¸ªComfyUIè¿›ç¨‹")
            else:
                print("â„¹ï¸ æœªæ‰¾åˆ°è¿è¡Œçš„ComfyUIè¿›ç¨‹")
            
            time.sleep(3)
            
        except Exception as e:
            print(f"âš ï¸ ç»ˆæ­¢è¿›ç¨‹æ—¶å‡ºé”™: {e}")
    
    def start_comfyui(self):
        """å¯åŠ¨ComfyUIè¿›ç¨‹"""
        print(f"ğŸš€ æ­£åœ¨å¯åŠ¨ComfyUI: {self.comfyui_script}")
        self.save_processing_status("ç³»ç»Ÿ", action="å¯åŠ¨ComfyUI")
        
        try:
            os.chdir(self.comfyui_path)
            
            self.comfyui_process = subprocess.Popen(
                [self.comfyui_script],
                creationflags=subprocess.CREATE_NEW_CONSOLE,
                cwd=self.comfyui_path
            )
            
            print(f"âœ… ComfyUIè¿›ç¨‹å·²å¯åŠ¨ï¼ŒPID: {self.comfyui_process.pid}")
            
            # ç­‰å¾…ComfyUIå¯åŠ¨ï¼ˆå¢åŠ ç­‰å¾…æ—¶é—´ï¼‰
            wait_time = 180  # 3åˆ†é’Ÿ
            for i in range(wait_time):
                print(f"â³ ç­‰å¾…ComfyUIå¯åŠ¨ ({i+1}/{wait_time})...")
                if self.check_comfyui_server(timeout=10):
                    print("âœ… ComfyUIæœåŠ¡å™¨å·²å‡†å¤‡å°±ç»ª")
                    return True
                time.sleep(1)
            
            print("âŒ ComfyUIå¯åŠ¨è¶…æ—¶")
            return False
            
        except Exception as e:
            print(f"âŒ å¯åŠ¨ComfyUIå¤±è´¥: {e}")
            return False
    
    def restart_comfyui(self):
        """é‡å¯ComfyUIæœåŠ¡"""
        print("ğŸ”„ æ­£åœ¨é‡å¯ComfyUIæœåŠ¡...")
        self.save_processing_status("ç³»ç»Ÿ", action="é‡å¯ComfyUI")
        
        self.kill_comfyui_processes()
        
        if self.start_comfyui():
            print("âœ… ComfyUIé‡å¯æˆåŠŸ")
            return True
        else:
            print("âŒ ComfyUIé‡å¯å¤±è´¥")
            return False
    
    def check_comfyui_server(self, timeout: int = 10) -> bool:
        """æ£€æŸ¥ComfyUIæœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.comfyui_url}/", timeout=timeout)
            return response.status_code == 200
        except requests.exceptions.RequestException:
            return False
    
    def wait_for_server_ready(self, timeout_seconds: int = 300) -> bool:
        """
        ç­‰å¾…ComfyUIæœåŠ¡å™¨å°±ç»ªï¼ˆæ”¹è¿›ç‰ˆï¼‰
        
        å‚æ•°:
            timeout_seconds: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        
        è¿”å›:
            bool: æœåŠ¡å™¨æ˜¯å¦å°±ç»ª
        """
        print(f"â³ ç­‰å¾…ComfyUIæœåŠ¡å™¨å°±ç»ªï¼Œè¶…æ—¶æ—¶é—´: {timeout_seconds}ç§’")
        
        start_time = time.time()
        check_count = 0
        
        while time.time() - start_time < timeout_seconds:
            check_count += 1
            
            if self.check_comfyui_server(timeout=5):
                print(f"âœ… ComfyUIæœåŠ¡å™¨å°±ç»ªï¼Œè€—æ—¶: {time.time() - start_time:.1f}ç§’")
                return True
            
            elapsed = time.time() - start_time
            if elapsed > 30 and check_count % 3 == 0:  # æ¯30ç§’æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†çŠ¶æ€
                print(f"â° å·²ç­‰å¾… {elapsed:.1f} ç§’...")
            
            time.sleep(self.server_check_interval)
        
        print(f"âŒ ComfyUIæœåŠ¡å™¨ç­‰å¾…è¶…æ—¶ ({timeout_seconds}ç§’)")
        return False
    
    def get_queue_status(self) -> Optional[Dict]:
        """è·å–é˜Ÿåˆ—çŠ¶æ€"""
        try:
            response = requests.get(self.api_queue, timeout=15)
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            print(f"âš ï¸ è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}")
        return None
    
    def check_task_in_queue(self, prompt_id: str) -> str:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦åœ¨é˜Ÿåˆ—ä¸­"""
        try:
            queue_data = self.get_queue_status()
            if not queue_data:
                return "error"
            
            # æ£€æŸ¥æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
            for task in queue_data.get("queue_running", []):
                if len(task) > 1 and task[1] == prompt_id:
                    return "running"
            
            # æ£€æŸ¥ç­‰å¾…ä¸­çš„ä»»åŠ¡
            for task in queue_data.get("queue_pending", []):
                if len(task) > 1 and task[1] == prompt_id:
                    return "pending"
            
            return "not_found"
            
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥é˜Ÿåˆ—å¤±è´¥: {e}")
            return "error"
    
    def check_history_api(self, prompt_id: str, max_items: int = 5) -> Dict:
        """æ£€æŸ¥å†å²è®°å½•ä¸­çš„ä»»åŠ¡çŠ¶æ€"""
        try:
            response = requests.get(f"{self.api_history}?max_items={max_items}", timeout=15)
            if response.status_code == 200:
                history_data = response.json()
                
                # æŸ¥æ‰¾ç‰¹å®šä»»åŠ¡
                for task_id, task_info in history_data.items():
                    if task_id == prompt_id:
                        status_info = task_info.get("status", {})
                        
                        # 1. æˆåŠŸå®Œæˆ
                        if status_info.get("status_str") == "success" and status_info.get("completed", False):
                            return {
                                "status": "success",
                                "completed": True,
                                "has_error": False,
                                "message": "ä»»åŠ¡æˆåŠŸå®Œæˆ"
                            }
                        
                        # 2. ä¸­æ–­
                        messages = status_info.get("messages", [])
                        is_interrupted = any(msg[0] == "execution_interrupted" for msg in messages)
                        
                        if is_interrupted or (status_info.get("status_str") == "error" and not status_info.get("completed", False)):
                            return {
                                "status": "interrupted",
                                "completed": False,
                                "has_error": True,
                                "message": "ä»»åŠ¡è¢«ä¸­æ–­"
                            }
                        
                        # 3. é”™è¯¯
                        if status_info.get("status_str") == "error":
                            return {
                                "status": "error",
                                "completed": status_info.get("completed", False),
                                "has_error": True,
                                "message": "ä»»åŠ¡æ‰§è¡Œé”™è¯¯"
                            }
                
                # ä»»åŠ¡ä¸åœ¨å†å²è®°å½•ä¸­
                return {
                    "status": "not_found",
                    "completed": False,
                    "has_error": False,
                    "message": "ä»»åŠ¡ä¸åœ¨å†å²è®°å½•ä¸­"
                }
        except Exception as e:
            print(f"âš ï¸ æ£€æŸ¥å†å²APIå¤±è´¥: {e}")
        
        return {
            "status": "error",
            "completed": False,
            "has_error": True,
            "message": "æ£€æŸ¥å†å²è®°å½•å¤±è´¥"
        }
    
    def get_task_status(self, prompt_id: str) -> Dict:
        """ç»¼åˆæ£€æŸ¥ä»»åŠ¡çŠ¶æ€"""
        # 1. å…ˆæ£€æŸ¥é˜Ÿåˆ—
        queue_status = self.check_task_in_queue(prompt_id)
        
        if queue_status == "running":
            return {
                "status": "running",
                "in_queue": True,
                "in_history": False,
                "is_completed": False,
                "message": "ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­"
            }
        elif queue_status == "pending":
            return {
                "status": "pending",
                "in_queue": True,
                "in_history": False,
                "is_completed": False,
                "message": "ä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ç­‰å¾…"
            }
        elif queue_status == "not_found":
            # 2. ä¸åœ¨é˜Ÿåˆ—ä¸­ï¼Œæ£€æŸ¥å†å²è®°å½•
            history_result = self.check_history_api(prompt_id)
            
            if history_result["status"] == "success":
                return {
                    "status": "success",
                    "in_queue": False,
                    "in_history": True,
                    "is_completed": True,
                    "message": history_result["message"]
                }
            elif history_result["status"] in ["interrupted", "error"]:
                return {
                    "status": history_result["status"],
                    "in_queue": False,
                    "in_history": True,
                    "is_completed": history_result["completed"],
                    "message": history_result["message"]
                }
            else:
                # æ—¢ä¸åœ¨é˜Ÿåˆ—ä¹Ÿä¸åœ¨å†å²è®°å½•
                return {
                    "status": "unknown",
                    "in_queue": False,
                    "in_history": False,
                    "is_completed": False,
                    "message": "ä»»åŠ¡çŠ¶æ€æœªçŸ¥"
                }
        
        # é˜Ÿåˆ—æ£€æŸ¥å¤±è´¥
        return {
            "status": "unknown",
            "in_queue": False,
            "in_history": False,
            "is_completed": False,
            "message": "æ— æ³•è·å–ä»»åŠ¡çŠ¶æ€"
        }
    
    def smart_wait_for_completion(self, prompt_id: str, video_path: str, 
                                 frames_per_batch: int, max_retries: int = 3) -> Tuple[bool, bool, int]:
        """
        æ™ºèƒ½ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆæ”¹è¿›ç‰ˆï¼‰
        æ·»åŠ åŸºäºframes_per_batchçš„åŠ¨æ€è¶…æ—¶æœºåˆ¶
        
        è¿”å›:
            (success: bool, need_restart: bool, retry_count: int)
        """
        video_name = os.path.basename(video_path)
        print(f"â³ ç­‰å¾…ä»»åŠ¡ {prompt_id} å®Œæˆ...")
        
        # æ ¹æ®frames_per_batchè®¡ç®—è¶…æ—¶æ—¶é—´
        base_timeout = frames_per_batch * self.monitor_timeout_factor  # æ‰¹æ¬¡å¸§æ•° Ã— 2
        max_wait_time = max(300, base_timeout)  # è‡³å°‘5åˆ†é’Ÿï¼Œæœ€å¤§ä¸ºè®¡ç®—å€¼
        print(f"â±ï¸  æœ€å¤§ç­‰å¾…æ—¶é—´: {max_wait_time}ç§’ (åŸºäºframes_per_batch={frames_per_batch})")
        
        start_time = time.time()
        poll_interval = self.server_check_interval
        
        retry_count = 0
        last_status = ""
        
        while time.time() - start_time < max_wait_time:
            # æ£€æŸ¥ComfyUIæœåŠ¡æ˜¯å¦å¯ç”¨ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            server_available = False
            for _ in range(3):  # å°è¯•3æ¬¡
                if self.check_comfyui_server():
                    server_available = True
                    break
                time.sleep(2)
            
            if not server_available:
                print("âŒ ComfyUIæœåŠ¡ä¸å¯ç”¨ï¼Œä½†ç»§ç»­ç­‰å¾…5ç§’åé‡è¯•...")
                # ä¸ç«‹å³è¿”å›å¤±è´¥ï¼Œè€Œæ˜¯ç­‰å¾…åç»§ç»­æ£€æŸ¥
                time.sleep(5)
                continue
            
            # è·å–ä»»åŠ¡çŠ¶æ€
            task_status = self.get_task_status(prompt_id)
            current_status = task_status["status"]
            
            # è¾“å‡ºçŠ¶æ€å˜åŒ–
            if current_status != last_status:
                status_messages = {
                    "running": "â–¶ï¸ ä»»åŠ¡æ‰§è¡Œä¸­",
                    "pending": "â³ ä»»åŠ¡æ’é˜Ÿä¸­", 
                    "success": "âœ… ä»»åŠ¡æˆåŠŸå®Œæˆ",
                    "interrupted": "â¹ï¸ ä»»åŠ¡è¢«ä¸­æ–­",
                    "error": "âŒ ä»»åŠ¡æ‰§è¡Œé”™è¯¯",
                    "unknown": "â“ ä»»åŠ¡çŠ¶æ€æœªçŸ¥"
                }
                message = status_messages.get(current_status, current_status)
                elapsed_time = time.time() - start_time
                print(f"[{time.strftime('%H:%M:%S')}] {message} (å·²ç­‰å¾… {elapsed_time:.1f}ç§’)")
                last_status = current_status
            
            # å¤„ç†ä¸åŒçŠ¶æ€
            if current_status == "success":
                print(f"âœ… ä»»åŠ¡ {prompt_id} æˆåŠŸå®Œæˆ")
                return True, False, retry_count
            
            elif current_status == "interrupted":
                print(f"â¹ï¸ ä»»åŠ¡è¢«ä¸­æ–­ï¼Œå°†é‡è¯• (é‡è¯• {retry_count + 1}/{max_retries})")
                retry_count += 1
                if retry_count >= max_retries:
                    print(f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                    return False, False, retry_count
                else:
                    # æ¸…ç†è¾“å‡ºæ–‡ä»¶åé‡è¯•
                    self.clean_output_files(video_path)
                    return False, False, retry_count
            
            elif current_status == "error":
                print(f"âŒ ä»»åŠ¡æ‰§è¡Œé”™è¯¯ï¼Œå°†é‡è¯• (é‡è¯• {retry_count + 1}/{max_retries})")
                retry_count += 1
                if retry_count >= max_retries:
                    print(f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                    return False, False, retry_count
                else:
                    self.clean_output_files(video_path)
                    return False, False, retry_count
            
            elif current_status in ["running", "pending"]:
                # ä»»åŠ¡æ­£åœ¨è¿›è¡Œä¸­ï¼Œç»§ç»­ç­‰å¾…
                elapsed = time.time() - start_time
                if elapsed > 60 and int(elapsed) % 30 == 0:  # æ¯30ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                    print(f"â° ä»»åŠ¡ä»åœ¨å¤„ç†ä¸­ï¼Œå·²ç­‰å¾… {elapsed:.1f}ç§’")
                time.sleep(poll_interval)
                continue
            
            elif current_status == "unknown":
                # çŠ¶æ€æœªçŸ¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–ä»»åŠ¡è¢«ç³»ç»Ÿç§»é™¤
                elapsed = time.time() - start_time
                print(f"âš ï¸ ä»»åŠ¡çŠ¶æ€æœªçŸ¥ï¼Œå·²ç­‰å¾… {elapsed:.1f}ç§’ï¼Œç»§ç»­æ£€æŸ¥...")
                time.sleep(poll_interval * 2)
                continue
        
        # è¶…æ—¶
        elapsed_time = time.time() - start_time
        print(f"â° ä»»åŠ¡ {prompt_id} ç­‰å¾…è¶…æ—¶ ({elapsed_time:.1f}ç§’)")
        retry_count += 1
        return False, False, retry_count
    
    def clean_memory(self):
        """
        ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤æ¸…ç†å†…å­˜
        ä¸å†æ£€æŸ¥ç‰¹å®šå·¥å…·è·¯å¾„ï¼Œç›´æ¥æ‰§è¡Œmemreductå‘½ä»¤
        """
        if not self.clean_memory_enabled:
            print("â„¹ï¸ å†…å­˜æ¸…ç†åŠŸèƒ½å·²ç¦ç”¨")
            return True
        
        print(f"ğŸ§¹ æ­£åœ¨æ‰§è¡Œå†…å­˜æ¸…ç† (è¶…æ—¶: {self.memreduct_timeout}ç§’)")
        
        try:
            # ç›´æ¥è°ƒç”¨memreductå‘½ä»¤ï¼Œå‡è®¾å·²åœ¨ç³»ç»ŸPATHä¸­
            process = subprocess.Popen(
                ["memreduct", "--clean:full"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                creationflags=subprocess.CREATE_NO_WINDOW
            )
            
            start_time = time.time()
            
            # ç›‘æ§è¿›ç¨‹
            while time.time() - start_time < self.memreduct_timeout:
                time.sleep(self.memreduct_check_interval)
                
                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»åœ¨è¿è¡Œ
                poll_result = process.poll()
                if poll_result is not None:
                    # è¿›ç¨‹å·²ç»“æŸ
                    if poll_result == 0:
                        print(f"âœ… å†…å­˜æ¸…ç†å®Œæˆ (è€—æ—¶: {time.time() - start_time:.1f}ç§’)")
                        return True
                    else:
                        print(f"âš ï¸ å†…å­˜æ¸…ç†è¿”å›éé›¶é€€å‡ºç : {poll_result}")
                        # ç»§ç»­æ‰§è¡Œï¼Œä¸å› æ¸…ç†å¤±è´¥è€Œä¸­æ–­ä¸»æµç¨‹
                        return False
                
                # æ˜¾ç¤ºè¿›åº¦
                elapsed = time.time() - start_time
                if elapsed > 30 and int(elapsed) % 30 == 0:
                    print(f"â° å†…å­˜æ¸…ç†è¿›è¡Œä¸­ï¼Œå·²æ‰§è¡Œ {elapsed:.1f}ç§’")
            
            # è¶…æ—¶ï¼Œå¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹
            print(f"â° å†…å­˜æ¸…ç†è¶…æ—¶ ({self.memreduct_timeout}ç§’)ï¼Œç»ˆæ­¢è¿›ç¨‹")
            try:
                process.terminate()
                process.wait(timeout=5)
            except:
                try:
                    process.kill()
                except:
                    pass
            
            # å³ä½¿è¶…æ—¶ä¹Ÿç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­ä¸»æµç¨‹
            return False
            
        except FileNotFoundError:
            print("âš ï¸ memreductå‘½ä»¤æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿memreductå·²åœ¨ç³»ç»ŸPATHä¸­")
            return False
        except Exception as e:
            print(f"âš ï¸ æ‰§è¡Œå†…å­˜æ¸…ç†æ—¶å‡ºé”™: {e}")
            # ç»§ç»­æ‰§è¡Œï¼Œä¸å› æ¸…ç†å¤±è´¥è€Œä¸­æ–­ä¸»æµç¨‹
            return False
    
    def clean_output_files(self, video_path: str):
        """æ¸…ç†æŒ‡å®šè§†é¢‘çš„è¾“å‡ºæ–‡ä»¶"""
        video_name = os.path.basename(video_path)
        base_name = os.path.splitext(video_name)[0]
        print(f"ğŸ§¹ æ¸…ç† {video_name} çš„è¾“å‡ºæ–‡ä»¶...")
        
        try:
            patterns = [
                f"flashvsr_{base_name}_enhanced*.mp4",
                f"flashvsr_{base_name}_enhanced*.png",
                f"*{base_name}*.mp4",
                f"*{base_name}*.png",
            ]
            
            deleted_count = 0
            for pattern in patterns:
                full_pattern = os.path.join(self.output_dir, pattern)
                for file_path in glob(full_pattern):
                    try:
                        filename = os.path.basename(file_path)
                        if base_name in filename:
                            os.remove(file_path)
                            deleted_count += 1
                    except Exception as e:
                        print(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            
            if deleted_count > 0:
                print(f"âœ… å·²æ¸…ç† {deleted_count} ä¸ªè¾“å‡ºæ–‡ä»¶")
            else:
                print("â„¹ï¸ æœªæ‰¾åˆ°éœ€è¦æ¸…ç†çš„è¾“å‡ºæ–‡ä»¶")
                
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def get_video_frame_count(self, video_path: str) -> Tuple[int, float, str]:
        """è·å–è§†é¢‘çš„æ€»å¸§æ•°ã€å¸§ç‡å’Œæ£€æµ‹æ–¹æ³•"""
        try:
            if PYMEDIAINFO_AVAILABLE:
                media_info = MediaInfo.parse(video_path)
                for track in media_info.tracks:
                    if track.track_type == 'Video':
                        frame_count = 0
                        if hasattr(track, 'frame_count') and track.frame_count:
                            frame_count = int(track.frame_count)
                        
                        frame_rate = 25.0
                        if hasattr(track, 'frame_rate') and track.frame_rate:
                            try:
                                frame_rate_str = str(track.frame_rate)
                                if '/' in frame_rate_str:
                                    numerator, denominator = map(float, frame_rate_str.split('/'))
                                    frame_rate = numerator / denominator
                                else:
                                    frame_rate = float(frame_rate_str)
                            except:
                                frame_rate = 25.0
                        
                        if frame_count > 0:
                            return frame_count, frame_rate, "pymediainfo"
            
            # å¤‡ç”¨æ–¹æ³•
            try:
                import cv2
                cap = cv2.VideoCapture(video_path)
                if cap.isOpened():
                    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    cap.release()
                    
                    if frame_count > 0 and fps > 0:
                        return frame_count, fps, "OpenCV"
            except ImportError:
                pass
            
            print(f"âš ï¸  æ— æ³•è·å– {os.path.basename(video_path)} çš„å‡†ç¡®å¸§æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return 100, 25.0, "é»˜è®¤å€¼"
            
        except Exception as e:
            print(f"âš ï¸  è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥ {os.path.basename(video_path)}: {e}")
            return 100, 25.0, "é”™è¯¯-é»˜è®¤å€¼"
    
    def load_workflow_template(self, template_path: str) -> Dict:
        """åŠ è½½å·¥ä½œæµ JSON æ¨¡æ¿"""
        with open(template_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def update_workflow_parameters(
        self, 
        workflow: Dict, 
        video_path: str, 
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 201,
        gpu_device: str = "auto"
    ) -> Dict:
        """æ›´æ–°å·¥ä½œæµä¸­çš„æ‰€æœ‰å‚æ•°"""
        modified_workflow = json.loads(json.dumps(workflow))
        
        print("=== å·¥ä½œæµå‚æ•°æ›´æ–°å¼€å§‹ ===")
        
        # 1. è®¾ç½®è¾“å…¥è§†é¢‘è·¯å¾„
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_LoadVideo":
                current_video = node_data["inputs"].get("video", "")
                if "{{VIDEO_PATH}}" in str(current_video):
                    node_data["inputs"]["video"] = video_path
                    print(f"âœ… å·²è®¾ç½®è§†é¢‘è·¯å¾„: {video_path}")
                elif isinstance(node_data["inputs"].get("video"), str):
                    node_data["inputs"]["video"] = video_path
                    print(f"âœ… å·²è®¾ç½®è§†é¢‘è·¯å¾„: {video_path} (ç›´æ¥èµ‹å€¼)")
        
        # 2. è®¾ç½® FlashVSR æ ¸å¿ƒå‚æ•°
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "FlashVSRNodeAdv":
                # æ£€æŸ¥scaleå‚æ•°
                current_scale = str(node_data["inputs"].get("scale", ""))
                if "{{scale}}" in current_scale:
                    node_data["inputs"]["scale"] = scale
                    print(f"âœ… å·²è®¾ç½®ç¼©æ”¾æ¯”ä¾‹: {scale}")
                elif isinstance(node_data["inputs"].get("scale"), (int, float, str)):
                    try:
                        node_data["inputs"]["scale"] = float(scale)
                        print(f"âœ… å·²è®¾ç½®ç¼©æ”¾æ¯”ä¾‹: {scale} (ç›´æ¥èµ‹å€¼)")
                    except:
                        pass
                
                # æ£€æŸ¥tile_sizeå‚æ•°
                current_tile_size = str(node_data["inputs"].get("tile_size", ""))
                if "{{t_z}}" in current_tile_size or "{{tile_size}}" in current_tile_size:
                    node_data["inputs"]["tile_size"] = tile_size
                    print(f"âœ… å·²è®¾ç½®åˆ†å—å¤§å°: {tile_size}")
                elif isinstance(node_data["inputs"].get("tile_size"), (int, float, str)):
                    try:
                        node_data["inputs"]["tile_size"] = int(tile_size)
                        print(f"âœ… å·²è®¾ç½®åˆ†å—å¤§å°: {tile_size} (ç›´æ¥èµ‹å€¼)")
                    except:
                        pass
                
                # æ£€æŸ¥tile_overlapå‚æ•°
                current_tile_overlap = str(node_data["inputs"].get("tile_overlap", ""))
                if "{{t_o}}" in current_tile_overlap or "{{tile_overlap}}" in current_tile_overlap:
                    node_data["inputs"]["tile_overlap"] = tile_overlap
                    print(f"âœ… å·²è®¾ç½®åˆ†å—é‡å : {tile_overlap}")
                elif isinstance(node_data["inputs"].get("tile_overlap"), (int, float, str)):
                    try:
                        node_data["inputs"]["tile_overlap"] = int(tile_overlap)
                        print(f"âœ… å·²è®¾ç½®åˆ†å—é‡å : {tile_overlap} (ç›´æ¥èµ‹å€¼)")
                    except:
                        pass
        
        # 3. è®¾ç½® GPU è®¾å¤‡
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "FlashVSRInitPipe":
                current_device = str(node_data["inputs"].get("device", ""))
                if "{{gpu}}" in current_device:
                    if gpu_device == "auto":
                        device_value = "auto"
                    elif gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    node_data["inputs"]["device"] = device_value
                    print(f"âœ… å·²è®¾ç½®GPUè®¾å¤‡: {device_value}")
                elif isinstance(node_data["inputs"].get("device"), str):
                    if gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    node_data["inputs"]["device"] = device_value
                    print(f"âœ… å·²è®¾ç½®GPUè®¾å¤‡: {device_value} (ç›´æ¥èµ‹å€¼)")
        
        # 4. è®¾ç½®æ€»å¸§æ•°
        if total_frames is None:
            total_frames, _, _ = self.get_video_frame_count(video_path)
            print(f"ğŸ“Š è‡ªåŠ¨æ£€æµ‹åˆ°è§†é¢‘æ€»å¸§æ•°: {total_frames}")
        
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "PrimitiveInt":
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ€»å¸§æ•°èŠ‚ç‚¹ï¼ˆèŠ‚ç‚¹50ï¼‰
                if node_id == "50":
                    current_value = str(node_data["inputs"].get("value", ""))
                    if "{{TOTAL_FRAMES}}" in current_value or "{{TATAL_FRAMES}}" in current_value:
                        node_data["inputs"]["value"] = total_frames
                        print(f"âœ… å·²è®¾ç½®æ€»å¸§æ•°: {total_frames} åˆ°èŠ‚ç‚¹ 50")
                    elif isinstance(node_data["inputs"].get("value"), (int, float, str)):
                        try:
                            node_data["inputs"]["value"] = int(total_frames)
                            print(f"âœ… å·²è®¾ç½®æ€»å¸§æ•°: {total_frames} åˆ°èŠ‚ç‚¹ 50 (ç›´æ¥èµ‹å€¼)")
                        except:
                            pass
                    else:
                        print(f"âš ï¸  èŠ‚ç‚¹ 50 çš„å€¼æ ¼å¼å¼‚å¸¸: {current_value}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ¯æ‰¹å¸§æ•°èŠ‚ç‚¹ï¼ˆèŠ‚ç‚¹8ï¼‰
                elif node_id == "8":
                    current_value = str(node_data["inputs"].get("value", ""))
                    if "{{FRAMES_PER_BATCH}}" in current_value:
                        node_data["inputs"]["value"] = frames_per_batch
                        print(f"âœ… å·²è®¾ç½®æ¯æ‰¹å¸§æ•°: {frames_per_batch} åˆ°èŠ‚ç‚¹ 8")
                    elif isinstance(node_data["inputs"].get("value"), (int, float, str)):
                        try:
                            node_data["inputs"]["value"] = int(frames_per_batch)
                            print(f"âœ… å·²è®¾ç½®æ¯æ‰¹å¸§æ•°: {frames_per_batch} åˆ°èŠ‚ç‚¹ 8 (ç›´æ¥èµ‹å€¼)")
                        except:
                            pass
                    else:
                        print(f"âš ï¸  èŠ‚ç‚¹ 8 çš„å€¼æ ¼å¼å¼‚å¸¸: {current_value}")
        
        # 5. è®¾ç½®è¾“å‡ºæ–‡ä»¶åå‰ç¼€
        if output_prefix is None:
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            output_prefix = f"flashvsr_{base_name}_enhanced"
        
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_VideoCombine":
                current_prefix = str(node_data["inputs"].get("filename_prefix", ""))
                if "{{OUTPUT_PREFIX}}" in current_prefix:
                    node_data["inputs"]["filename_prefix"] = output_prefix
                    print(f"âœ… å·²è®¾ç½®è¾“å‡ºå‰ç¼€: {output_prefix}")
                elif isinstance(node_data["inputs"].get("filename_prefix"), str):
                    node_data["inputs"]["filename_prefix"] = output_prefix
                    print(f"âœ… å·²è®¾ç½®è¾“å‡ºå‰ç¼€: {output_prefix} (ç›´æ¥èµ‹å€¼)")
        
        print("=== å·¥ä½œæµå‚æ•°æ›´æ–°å®Œæˆ ===")
        return modified_workflow
    
    def queue_prompt(self, workflow: Dict, timeout: int = 300) -> Optional[str]:
        """å°†å·¥ä½œæµå‘é€åˆ° ComfyUI æ‰§è¡Œ"""
        if not self.check_comfyui_server():
            print("âŒ ComfyUI æœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•æäº¤ä»»åŠ¡")
            return None

        print("=== å·¥ä½œæµå‚æ•°éªŒè¯ ===")
        key_nodes = ["5", "8", "50", "49", "62"]
        for node_id in key_nodes:
            if node_id in workflow:
                node_data = workflow[node_id]
                node_type = node_data.get("class_type", "Unknown")
                inputs = node_data.get("inputs", {})
                print(f"èŠ‚ç‚¹ {node_id} ({node_type}):")
                
                for key in ["device", "value", "video", "filename_prefix", "scale", "tile_size", "tile_overlap"]:
                    if key in inputs:
                        print(f"  {key}: {inputs[key]}")
        
        try:
            print(f"ğŸ“¤ æ­£åœ¨æäº¤ä»»åŠ¡åˆ°: {self.api_prompt}")
            print(f"ğŸ“¦ å·¥ä½œæµå¤§å°: {len(str(workflow))} å­—ç¬¦")
            
            response = requests.post(
                self.api_prompt, 
                json={"prompt": workflow}, 
                timeout=timeout,
                headers={'Content-Type': 'application/json'}
            )
            
            print(f"ğŸ“¥ å“åº”çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                prompt_id = data.get('prompt_id')
                
                if prompt_id:
                    print(f"âœ… ä»»åŠ¡å·²æäº¤ï¼ŒID: {prompt_id}")
                    return prompt_id
                else:
                    print(f"âŒ æœªæ”¶åˆ°ä»»åŠ¡IDï¼Œå®Œæ•´å“åº”: {data}")
                    return None
            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"ğŸ“„ é”™è¯¯è¯¦æƒ…: {response.text[:500]}")
                
                if response.status_code == 400:
                    print("ğŸ” åˆ†æ400é”™è¯¯å¯èƒ½çš„åŸå› :")
                    print("  1. å·¥ä½œæµä¸­å­˜åœ¨æœªæ›¿æ¢çš„å ä½ç¬¦ï¼ˆå¦‚{{gpu}}ã€{{TOTAL_FRAMES}}ï¼‰")
                    print("  2. å·¥ä½œæµæ ¼å¼ä¸ç¬¦åˆComfyUIè¦æ±‚")
                    print("  3. æŸäº›èŠ‚ç‚¹å‚æ•°ç±»å‹ä¸æ­£ç¡®")
                
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            return None
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±è´¥: {e}")
            return None
    
    def get_output_files(self, prompt_id: str) -> List[str]:
        """è·å–ä»»åŠ¡ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶åˆ—è¡¨"""
        try:
            response = requests.get(f"{self.api_view}/{prompt_id}", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                outputs = data.get("outputs", {})
                file_list = []
                
                for node_id, node_output in outputs.items():
                    if "images" in node_output:
                        for img in node_output["images"]:
                            if "filename" in img:
                                file_list.append(img["filename"])
                
                return file_list
                
        except Exception as e:
            print(f"âš ï¸ è·å–è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
        
        return []
    
    def process_video_with_retry(
        self,
        workflow_template: Dict,
        video_path: str,
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 125,
        gpu_device: str = "auto",
        max_retries: int = 3
    ) -> Tuple[bool, int, str]:
        """
        å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œæ”¯æŒæ™ºèƒ½é‡è¯•å’Œå†…å­˜æ¸…ç†
        
        è¿”å›:
            (success: bool, retry_count: int, final_prompt_id: str)
        """
        video_name = os.path.basename(video_path)
        print(f"\n{'='*60}")
        print(f"å¤„ç†è§†é¢‘: {video_path}")
        print(f"{'='*60}")
        
        retry_count = 0
        current_prompt_id = None
        
        while retry_count < max_retries:
            retry_count += 1
            print(f"\nğŸ”„ å°è¯• {retry_count}/{max_retries}")
            
            # 1. æ£€æŸ¥å¹¶ç¡®ä¿ComfyUIæ­£åœ¨è¿è¡Œ
            if not self.check_comfyui_server():
                print("âŒ ComfyUIæœåŠ¡æœªè¿è¡Œï¼Œæ­£åœ¨å¯åŠ¨...")
                if not self.start_comfyui():
                    print("âŒ æ— æ³•å¯åŠ¨ComfyUIï¼Œè·³è¿‡æ­¤è§†é¢‘")
                    return False, retry_count, ""
            
            # 2. æ›´æ–°å·¥ä½œæµå‚æ•°å¹¶æäº¤ä»»åŠ¡
            workflow = self.update_workflow_parameters(
                workflow_template, 
                video_path, 
                output_prefix,
                scale=scale,
                tile_size=tile_size,
                tile_overlap=tile_overlap,
                total_frames=total_frames,
                frames_per_batch=frames_per_batch,
                gpu_device=gpu_device
            )
            
            current_prompt_id = self.queue_prompt(workflow)
            if not current_prompt_id:
                print(f"âŒ ä»»åŠ¡æäº¤å¤±è´¥ï¼Œå°†é‡è¯•")
                if retry_count < max_retries:
                    print("â³ 5ç§’åé‡è¯•...")
                    time.sleep(5)
                    continue
                return False, retry_count, ""
            
            # 3. æ™ºèƒ½ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆä½¿ç”¨æ”¹è¿›çš„ç­‰å¾…æœºåˆ¶ï¼‰
            success, need_restart, wait_retries = self.smart_wait_for_completion(
                current_prompt_id, 
                video_path,
                frames_per_batch,  # ä¼ é€’frames_per_batchç”¨äºè®¡ç®—è¶…æ—¶æ—¶é—´
                max_retries - retry_count + 1
            )
            
            if need_restart:
                # ComfyUIéœ€è¦é‡å¯
                print("ğŸ”„ ComfyUIéœ€è¦é‡å¯...")
                if not self.restart_comfyui():
                    print("âŒ ComfyUIé‡å¯å¤±è´¥")
                    return False, retry_count, current_prompt_id
                
                # æ¸…ç†è¾“å‡ºæ–‡ä»¶åç»§ç»­é‡è¯•
                self.clean_output_files(video_path)
                continue
            
            elif success:
                # ä»»åŠ¡æˆåŠŸå®Œæˆ
                print(f"âœ… è§†é¢‘ {video_name} å¤„ç†æˆåŠŸ")
                
                # 4. æ‰§è¡Œå†…å­˜æ¸…ç†ï¼ˆæˆåŠŸæ—¶æ‰æ‰§è¡Œï¼‰
                if self.clean_memory_enabled:
                    print("ğŸ§¹ ä»»åŠ¡æˆåŠŸï¼Œæ‰§è¡Œå†…å­˜æ¸…ç†...")
                    memory_clean_success = self.clean_memory()
                    if memory_clean_success:
                        print("âœ… å†…å­˜æ¸…ç†æˆåŠŸ")
                    else:
                        print("âš ï¸ å†…å­˜æ¸…ç†å¤±è´¥æˆ–è¶…æ—¶ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªä»»åŠ¡")
                
                output_files = self.get_output_files(current_prompt_id)
                if output_files:
                    print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
                    for file in output_files:
                        print(f"  - {file}")
                return True, retry_count, current_prompt_id
            
            else:
                # ä»»åŠ¡å¤±è´¥ä½†ä¸æ˜¯å› ä¸ºComfyUIéœ€è¦é‡å¯
                print(f"âŒ è§†é¢‘ {video_name} å¤„ç†å¤±è´¥")
                
                if retry_count < max_retries:
                    print(f"â³ ç­‰å¾…5ç§’åé‡è¯•...")
                    time.sleep(5)
                    self.clean_output_files(video_path)
                    continue
                else:
                    print(f"âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                    return False, retry_count, current_prompt_id
        
        return False, retry_count, current_prompt_id if current_prompt_id else ""
    
    def batch_process_videos(
        self, 
        workflow_template_path: str, 
        video_files: List[str], 
        output_prefix_base: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 201,
        gpu_device: str = "auto",
        max_retries: int = 3
    ) -> Dict[str, Dict]:
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘æ–‡ä»¶
        
        è¿”å›:
            å­—å…¸ï¼š{è§†é¢‘æ–‡ä»¶: {æˆåŠŸ: bool, é‡è¯•æ¬¡æ•°: int, prompt_id: str}}
        """
        # åŠ è½½å·¥ä½œæµæ¨¡æ¿
        try:
            workflow_template = self.load_workflow_template(workflow_template_path)
            print(f"âœ… å·²åŠ è½½å·¥ä½œæµæ¨¡æ¿: {workflow_template_path}")
        except Exception as e:
            print(f"âŒ åŠ è½½å·¥ä½œæµæ¨¡æ¿å¤±è´¥: {e}")
            return {}
        
        # æ£€æŸ¥ComfyUIæœåŠ¡
        if not self.check_comfyui_server():
            print("âŒ ComfyUI æœåŠ¡æœªè¿è¡Œï¼Œæ­£åœ¨å¯åŠ¨...")
            if not self.start_comfyui():
                print("âŒ æ— æ³•å¯åŠ¨ComfyUIï¼Œç¨‹åºé€€å‡º")
                return {}
        
        results = {}
        total_videos = len(video_files)
        
        print(f"ğŸ¬ å¼€å§‹æ‰¹é‡å¤„ç† {total_videos} ä¸ªè§†é¢‘")
        print(f"âš™ï¸  å‚æ•°: scale={scale}, tile_size={tile_size}, tile_overlap={tile_overlap}")
        print(f"ğŸ® GPUè®¾å¤‡: {gpu_device}")
        print(f"ğŸ”„ æ¯ä¸ªä»»åŠ¡æœ€å¤šé‡è¯•: {max_retries}æ¬¡")
        print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ“‹ å·¥ä½œæµæ¨¡æ¿: {workflow_template_path}")
        print(f"â±ï¸  åŠ¨æ€è¶…æ—¶å› å­: {self.monitor_timeout_factor} Ã— frames_per_batch")
        print(f"ğŸ§¹ å†…å­˜æ¸…ç†: {'å¯ç”¨' if self.clean_memory_enabled else 'ç¦ç”¨'}")
        
        for i, video_path in enumerate(video_files, 1):
            print(f"\nğŸ“Š è¿›åº¦: {i}/{total_videos}")
            
            # è®¾ç½®è¾“å‡ºå‰ç¼€
            output_prefix = None
            if output_prefix_base:
                base_name = os.path.splitext(os.path.basename(video_path))[0]
                output_prefix = f"{output_prefix_base}_{base_name}"
            
            # å¤„ç†å•ä¸ªè§†é¢‘
            success, retry_count, prompt_id = self.process_video_with_retry(
                workflow_template, 
                video_path, 
                output_prefix,
                scale=scale,
                tile_size=tile_size,
                tile_overlap=tile_overlap,
                total_frames=total_frames,
                frames_per_batch=frames_per_batch,
                gpu_device=gpu_device,
                max_retries=max_retries
            )
            
            results[video_path] = {
                "success": success,
                "retry_count": retry_count,
                "prompt_id": prompt_id,
                "message": "æˆåŠŸ" if success else f"å¤±è´¥ï¼ˆé‡è¯•{retry_count}æ¬¡ï¼‰"
            }
            
            if not success:
                print(f"âš ï¸ è§†é¢‘ {os.path.basename(video_path)} å¤„ç†å¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª")
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'='*60}")
        print("æ‰¹é‡å¤„ç†å®Œæˆ")
        print(f"{'='*60}")
        
        success_count = sum(1 for r in results.values() if r["success"])
        total_retries = sum(r["retry_count"] for r in results.values())
        
        print(f"âœ… æˆåŠŸ: {success_count}/{total_videos}")
        print(f"âŒ å¤±è´¥: {total_videos - success_count}/{total_videos}")
        print(f"ğŸ”„ æ€»é‡è¯•æ¬¡æ•°: {total_retries}")
        
        return results

def collect_video_files(input_path: str, pattern: str = '*.mp4') -> List[str]:
    """æ ¹æ®è¾“å…¥è·¯å¾„æ”¶é›†è§†é¢‘æ–‡ä»¶"""
    video_files = []
    
    if os.path.isfile(input_path):
        if input_path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv')):
            video_files.append(input_path)
            print(f"âœ… æ·»åŠ å•ä¸ªæ–‡ä»¶: {input_path}")
        else:
            print(f"âŒ æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ: {input_path}")
    elif os.path.isdir(input_path):
        search_pattern = os.path.join(input_path, pattern)
        found_files = glob(search_pattern)
        
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', '.MP4', '.MOV', '.AVI', '.MKV']
        for ext in video_extensions:
            if ext not in pattern:
                additional_pattern = os.path.join(input_path, f"*{ext}")
                additional_files = glob(additional_pattern)
                found_files.extend(additional_files)
        
        video_files = sorted(list(set(found_files)))
        
        if not video_files:
            print(f"âŒ ç›®å½• {input_path} ä¸­æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        else:
            print(f"âœ… ä»ç›®å½• {input_path} æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    else:
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    return video_files

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· - å¢å¼ºä»»åŠ¡ç›‘æ§ç‰ˆ v25.1',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä¸»è¦æ”¹è¿› v25.1:
1. ComfyUIçŠ¶æ€ç›‘æ§æ”¹è¿›:
   - å½“APIæœåŠ¡ä¸å¯ç”¨æ—¶ï¼Œä¸æ˜¯ç«‹å³åˆ¤å®šå¤±è´¥
   - æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡æœåŠ¡å™¨çŠ¶æ€
   - è¶…æ—¶æ—¶é—´åŸºäºframes_per_batchåŠ¨æ€è®¡ç®—ï¼ˆå¸§æ•°Ã—2ï¼‰
   - æä¾›è¯¦ç»†çš„ç­‰å¾…è¿›åº¦æ˜¾ç¤º

2. å†…å­˜æ¸…ç†åŠŸèƒ½:
   - æ¯ä¸ªè§†é¢‘ä»»åŠ¡æˆåŠŸåè‡ªåŠ¨æ‰§è¡Œmemreduct --clean:full
   - æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡æ¸…ç†è¿›ç¨‹çŠ¶æ€
   - è¶…æ—¶300ç§’ï¼Œè¶…æ—¶åå¼ºåˆ¶ç»ˆæ­¢æ¸…ç†è¿›ç¨‹
   - å³ä½¿æ¸…ç†å¤±è´¥æˆ–è¶…æ—¶ï¼Œä¹Ÿç»§ç»­ä¸‹ä¸€ä¸ªä»»åŠ¡
   - ç®€åŒ–å†…å­˜æ¸…ç†ï¼Œç›´æ¥è°ƒç”¨ç³»ç»Ÿå‘½ä»¤

ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨GPU 0
  python v25.py --input video.mp4 --gpu 0
  
  # å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨GPU 1
  python v25.py --input ./videos --gpu 1
  
  # è‡ªå®šä¹‰æ¯æ‰¹å¸§æ•°ï¼Œè‡ªåŠ¨è®¡ç®—è¶…æ—¶
  python v25.py --input ./videos --frames-per-batch 150 --gpu 0
  
  # ç¦ç”¨å†…å­˜æ¸…ç†
  python v25.py --input ./videos --no-memory-clean --gpu 0

å‚æ•°è¯´æ˜:
  --frames-per-batch: æ¯æ‰¹å¤„ç†çš„å¸§æ•°ï¼Œå½±å“è¶…æ—¶æ—¶é—´è®¡ç®—ï¼ˆè¶…æ—¶=å¸§æ•°Ã—2ç§’ï¼‰
  --monitor-timeout-factor: è¶…æ—¶å› å­ï¼Œé»˜è®¤2ï¼ˆè¶…æ—¶æ—¶é—´=å¸§æ•°Ã—å› å­ï¼‰
        """
    )
    
    # è¾“å…¥å‚æ•°
    parser.add_argument('--template', type=str, default='flashvsr_template.json',
                       help='å·¥ä½œæµæ¨¡æ¿ JSON æ–‡ä»¶è·¯å¾„ (é»˜è®¤: flashvsr_template.json)')
    parser.add_argument('--input', type=str, required=True,
                       help='è¾“å…¥è·¯å¾„ï¼ˆå¯ä»¥æ˜¯è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–åŒ…å«è§†é¢‘æ–‡ä»¶çš„ç›®å½•ï¼‰')
    parser.add_argument('--pattern', type=str, default='*.mp4',
                       help='è§†é¢‘æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œå½“è¾“å…¥æ˜¯ç›®å½•æ—¶ä½¿ç”¨ (é»˜è®¤: *.mp4)')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output-prefix', type=str, 
                       help='è¾“å‡ºæ–‡ä»¶åå‰ç¼€ï¼ˆå¯é€‰ï¼Œç”¨äºåŒºåˆ†æ‰¹æ¬¡ï¼‰')
    
    # FlashVSR å¤„ç†å‚æ•°
    parser.add_argument('--scale', type=float, default=4.0,
                       help='æ”¾å¤§å€æ•° (é»˜è®¤: 4.0)')
    parser.add_argument('--tile-size', type=int, default=256,
                       help='åˆ†å—å¤§å° (é»˜è®¤: 256)')
    parser.add_argument('--tile-overlap', type=int, default=24,
                       help='åˆ†å—é‡å åƒç´  (é»˜è®¤: 24)')
    parser.add_argument('--frames-per-batch', type=int, default=201,
                       help='æ¯æ‰¹å¤„ç†çš„å¸§æ•° (é»˜è®¤: 201)')
    parser.add_argument('--total-frames', type=int,
                       help='è§†é¢‘æ€»å¸§æ•° (å¦‚ä¸æä¾›åˆ™è‡ªåŠ¨æ£€æµ‹)')
    
    # é‡è¯•å‚æ•°
    parser.add_argument('--max-retries', type=int, default=3,
                       help='æ¯ä¸ªä»»åŠ¡çš„æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: 3)')
    
    # ç›‘æ§å‚æ•°
    parser.add_argument('--monitor-timeout-factor', type=float, default=2.0,
                       help='ç›‘æ§è¶…æ—¶å› å­ (é»˜è®¤: 2.0, è¶…æ—¶=å¸§æ•°Ã—å› å­)')
    parser.add_argument('--check-interval', type=int, default=5,
                       help='æœåŠ¡å™¨æ£€æŸ¥é—´éš” (ç§’, é»˜è®¤: 5)')
    
    # å†…å­˜æ¸…ç†å‚æ•°
    parser.add_argument('--no-memory-clean', action='store_true',
                       help='ç¦ç”¨å†…å­˜æ¸…ç†åŠŸèƒ½')
    parser.add_argument('--memreduct-timeout', type=int, default=300,
                       help='å†…å­˜æ¸…ç†è¶…æ—¶æ—¶é—´ (ç§’, é»˜è®¤: 300)')
    parser.add_argument('--memreduct-check-interval', type=int, default=5,
                       help='å†…å­˜æ¸…ç†æ£€æŸ¥é—´éš” (ç§’, é»˜è®¤: 5)')
    
    # GPUå‚æ•°
    parser.add_argument('--gpu', type=str, default='auto',
                       help='GPUè®¾å¤‡é€‰æ‹©: auto, 0, 1, 2, cuda:0, cuda:1ç­‰ (é»˜è®¤: auto)')
    
    # ç³»ç»Ÿå‚æ•°
    parser.add_argument('--server', type=str, default='http://127.0.0.1:8188',
                       help='ComfyUI æœåŠ¡å™¨åœ°å€ (é»˜è®¤: http://127.0.0.1:8188)')
    parser.add_argument('--skip-pymedia-check', action='store_true',
                       help='è·³è¿‡ pymediainfo æ£€æŸ¥')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ pymediainfo
    if not PYMEDIAINFO_AVAILABLE and not args.skip_pymedia_check:
        print("âš ï¸  æœªæ£€æµ‹åˆ° pymediainfo åº“")
        response = input("æ˜¯å¦ç»§ç»­? (y/n): ")
        if response.lower() != 'y':
            print("é€€å‡ºç¨‹åº")
            return
    
    # å‡†å¤‡è§†é¢‘æ–‡ä»¶åˆ—è¡¨
    video_files = collect_video_files(args.input, args.pattern)
    
    if not video_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        return
    
    print(f"\næ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶:")
    for vf in video_files:
        print(f"  - {vf}")
    
    # æ˜¾ç¤ºå¤„ç†å‚æ•°
    print(f"\nâš™ï¸  å¤„ç†å‚æ•°:")
    print(f"  scale: {args.scale}")
    print(f"  tile_size: {args.tile_size}")
    print(f"  tile_overlap: {args.tile_overlap}")
    print(f"  frames_per_batch: {args.frames_per_batch}")
    print(f"  max_retries: {args.max_retries}")
    print(f"  monitor_timeout_factor: {args.monitor_timeout_factor}")
    print(f"  check_interval: {args.check_interval}")
    
    # åŠ¨æ€è¶…æ—¶è®¡ç®—
    dynamic_timeout = args.frames_per_batch * args.monitor_timeout_factor
    print(f"  åŠ¨æ€è¶…æ—¶: {dynamic_timeout}ç§’ (frames_per_batch Ã— timeout_factor)")
    
    if args.total_frames:
        print(f"  total_frames: {args.total_frames} (æ‰‹åŠ¨æŒ‡å®š)")
    else:
        print(f"  total_frames: è‡ªåŠ¨æ£€æµ‹")
    
    if args.output_prefix:
        print(f"  output_prefix: {args.output_prefix} (è¾“å‡ºæ–‡ä»¶åå‰ç¼€)")
    
    if args.gpu == "auto":
        print(f"ğŸ® GPUè®¾å¤‡: auto (è‡ªåŠ¨é€‰æ‹©)")
    elif args.gpu.isdigit():
        print(f"ğŸ® GPUè®¾å¤‡: cuda:{args.gpu}")
    else:
        print(f"ğŸ® GPUè®¾å¤‡: {args.gpu}")
    
    # å†…å­˜æ¸…ç†é…ç½®
    if args.no_memory_clean:
        print(f"ğŸ§¹ å†…å­˜æ¸…ç†: å·²ç¦ç”¨")
    else:
        print(f"ğŸ§¹ å†…å­˜æ¸…ç†: å·²å¯ç”¨")
        print(f"  memreduct_timeout: {args.memreduct_timeout}ç§’")
        print(f"  memreduct_check_interval: {args.memreduct_check_interval}ç§’")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = ComfyUI_FlashVSR_BatchProcessor(comfyui_url=args.server)
    
    # é…ç½®å¤„ç†å™¨å‚æ•°
    processor.server_check_interval = args.check_interval
    processor.monitor_timeout_factor = args.monitor_timeout_factor
    
    processor.clean_memory_enabled = not args.no_memory_clean
    processor.memreduct_timeout = args.memreduct_timeout
    processor.memreduct_check_interval = args.memreduct_check_interval
    
    # æ‰¹é‡å¤„ç†
    start_time = time.time()
    
    results = processor.batch_process_videos(
        workflow_template_path=args.template,
        video_files=video_files,
        output_prefix_base=args.output_prefix,
        scale=args.scale,
        tile_size=args.tile_size,
        tile_overlap=args.tile_overlap,
        total_frames=args.total_frames,
        frames_per_batch=args.frames_per_batch,
        gpu_device=args.gpu,
        max_retries=args.max_retries
    )
    
    # è®¡ç®—æ€»è€—æ—¶
    total_time = time.time() - start_time
    print(f"\nâ±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’ ({total_time/60:.1f} åˆ†é’Ÿ)")
    
    # è¾“å‡ºè¯¦ç»†ç»Ÿè®¡
    if results:
        success_count = sum(1 for r in results.values() if r["success"])
        fail_count = len(results) - success_count
        total_retries = sum(r["retry_count"] for r in results.values())
        
        print(f"\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")
        print(f"  å¤„ç†è§†é¢‘æ•°: {len(results)}")
        print(f"  æˆåŠŸ: {success_count}")
        print(f"  å¤±è´¥: {fail_count}")
        print(f"  æ€»é‡è¯•æ¬¡æ•°: {total_retries}")
        print(f"  å¹³å‡é‡è¯•æ¬¡æ•°: {total_retries/len(results):.1f}")
        
        if fail_count > 0:
            print(f"\nâŒ å¤±è´¥è§†é¢‘åˆ—è¡¨:")
            for video_path, result in results.items():
                if not result["success"]:
                    print(f"  - {os.path.basename(video_path)}: {result['message']}")
    
    # æœ€åå…³é—­ComfyUIè¿›ç¨‹
    print(f"\nğŸ”§ å¤„ç†å®Œæˆï¼Œæ­£åœ¨å…³é—­ComfyUIè¿›ç¨‹...")
    processor.kill_comfyui_processes()
    print("âœ… æ‰€æœ‰å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()
