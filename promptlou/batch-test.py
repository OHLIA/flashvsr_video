#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· - å¢å¼ºç‰ˆï¼ˆæ”¯æŒè‡ªåŠ¨é‡å¯å’Œæ–­ç‚¹ç»­ä¼ ï¼‰
æ”¯æŒåŠ¨æ€å‚æ•°ä¼ é€’ã€è‡ªåŠ¨æ£€æµ‹è§†é¢‘å¸§æ•°ã€GPUè®¾å¤‡é€‰æ‹©
è‡ªåŠ¨å¤„ç†è¿æ¥å¤±è´¥å’Œè¿›ç¨‹é‡å¯
è¾“å‡ºæ–‡ä»¶æŒ‰ç…§ ComfyUI é»˜è®¤æ–¹æ³•å­˜å‚¨
"""

import json
import requests
import os
import time
import sys
import math
from glob import glob
from typing import List, Dict, Optional, Tuple
from pathlib import Path
import subprocess
import signal
import psutil
import traceback

# å°è¯•å¯¼å…¥ pymediainfo
try:
    from pymediainfo import MediaInfo
    PYMEDIAINFO_AVAILABLE = True
except ImportError:
    PYMEDIAINFO_AVAILABLE = False
    print("âš ï¸  pymediainfo æœªå®‰è£…ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è·å–è§†é¢‘ä¿¡æ¯")

class ComfyUI_FlashVSR_BatchProcessor:
    def __init__(self, comfyui_url: str = "http://127.0.0.1:8188"):
        """
        åˆå§‹åŒ– ComfyUI FlashVSR æ‰¹é‡å¤„ç†å™¨
        
        å‚æ•°:
            comfyui_url: ComfyUI æœåŠ¡å™¨åœ°å€
        """
        self.comfyui_url = comfyui_url.rstrip('/')
        self.api_prompt = f"{comfyui_url}/prompt"
        self.api_history = f"{comfyui_url}/history"
        self.api_view = f"{comfyui_url}/view"
        
        # æ·»åŠ çŠ¶æ€è·Ÿè¸ª
        self.comfyui_process = None
        self.comfyui_path = r"F:\AI\ComfyUI_Mie_V7.0"
        self.comfyui_script = r"F:\AI\ComfyUI_Mie_V7.0\run_nvidia_gpu_fast_fp16_accumulation_hf_mirror.bat"
        self.output_dir = r"F:\AI\ComfyUI_Mie_V7.0\comfyui\output"
    
    def kill_comfyui_processes(self):
        """å…³é—­æ‰€æœ‰ComfyUIç›¸å…³è¿›ç¨‹"""
        print("ğŸ”ª æ­£åœ¨å…³é—­ComfyUIè¿›ç¨‹...")
        try:
            # æŸ¥æ‰¾å¹¶ç»ˆæ­¢ComfyUIç›¸å…³è¿›ç¨‹
            killed_count = 0
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    cmdline = proc.info.get('cmdline', [])
                    if cmdline and any('comfy' in part.lower() or 'python' in part.lower() for part in cmdline):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ComfyUIè¿›ç¨‹
                        is_comfyui = any('main.py' in ' '.join(cmdline) or 'run_nvidia_gpu' in ' '.join(cmdline) for part in cmdline)
                        if is_comfyui:
                            print(f"  ç»ˆæ­¢è¿›ç¨‹ PID={proc.info['pid']}, å‘½ä»¤={cmdline}")
                            proc.kill()
                            killed_count += 1
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            if killed_count > 0:
                print(f"âœ… å·²ç»ˆæ­¢ {killed_count} ä¸ªComfyUIè¿›ç¨‹")
            else:
                print("â„¹ï¸ æœªæ‰¾åˆ°è¿è¡Œçš„ComfyUIè¿›ç¨‹")
            
            # ç­‰å¾…è¿›ç¨‹å®Œå…¨ç»ˆæ­¢
            time.sleep(3)
            
        except Exception as e:
            print(f"âš ï¸ ç»ˆæ­¢è¿›ç¨‹æ—¶å‡ºé”™: {e}")
    
    def start_comfyui(self):
        """å¯åŠ¨ComfyUIè¿›ç¨‹"""
        print(f"ğŸš€ æ­£åœ¨å¯åŠ¨ComfyUI: {self.comfyui_script}")
        
        try:
            # åˆ‡æ¢åˆ°ComfyUIç›®å½•
            os.chdir(self.comfyui_path)
            
            # å¯åŠ¨æ–°è¿›ç¨‹
            self.comfyui_process = subprocess.Popen(
                [self.comfyui_script],
                creationflags=subprocess.CREATE_NEW_CONSOLE,
                cwd=self.comfyui_path
            )
            
            print(f"âœ… ComfyUIè¿›ç¨‹å·²å¯åŠ¨ï¼ŒPID: {self.comfyui_process.pid}")
            
            # ç­‰å¾…å¯åŠ¨å®Œæˆ
            wait_time = 120
            for i in range(wait_time):
                print(f"â³ ç­‰å¾…ComfyUIå¯åŠ¨ ({i+1}/{wait_time})...")
                if self.check_comfyui_server(timeout=5):
                    print("âœ… ComfyUIæœåŠ¡å™¨å·²å‡†å¤‡å°±ç»ª")
                    return True
                time.sleep(1)
            
            print("âŒ ComfyUIå¯åŠ¨è¶…æ—¶")
            return False
            
        except Exception as e:
            print(f"âŒ å¯åŠ¨ComfyUIå¤±è´¥: {e}")
            return False
    
    def restart_comfyui(self):
        """é‡å¯ComfyUIæœåŠ¡"""
        print("ğŸ”„ æ­£åœ¨é‡å¯ComfyUIæœåŠ¡...")
        
        # 1. å…³é—­ç°æœ‰è¿›ç¨‹
        self.kill_comfyui_processes()
        
        # 2. å¯åŠ¨æ–°è¿›ç¨‹
        if self.start_comfyui():
            print("âœ… ComfyUIé‡å¯æˆåŠŸ")
            return True
        else:
            print("âŒ ComfyUIé‡å¯å¤±è´¥")
            return False
    
    def check_comfyui_server(self, timeout: int = 5) -> bool:
        """
        æ£€æŸ¥ComfyUIæœåŠ¡æ˜¯å¦å¯ç”¨
        
        å‚æ•°:
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
        è¿”å›:
            True å¦‚æœæœåŠ¡å¯ç”¨ï¼ŒFalse å¦‚æœä¸å¯ç”¨
        """
        try:
            response = requests.get(f"{self.comfyui_url}/", timeout=timeout)
            if response.status_code == 200:
                return True
        except requests.exceptions.RequestException as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ° ComfyUI æœåŠ¡: {e}")
        return False
    
    def wait_for_completion(self, prompt_id: str, poll_interval: int = 5) -> bool:
        """
        ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆå¢å¼ºç‰ˆï¼Œæ”¯æŒè¿æ¥å¤±è´¥æ£€æµ‹å’Œè‡ªåŠ¨é‡å¯ï¼‰
        
        å‚æ•°:
            prompt_id: ä»»åŠ¡ID
            poll_interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
        
        è¿”å›:
            True å¦‚æœæˆåŠŸå®Œæˆï¼ŒFalse å¦‚æœå¤±è´¥æˆ–è¶…æ—¶
        """
        print(f"â³ ç­‰å¾…ä»»åŠ¡ {prompt_id} å®Œæˆ...")
        
        start_time = time.time()
        max_wait_time = 3600  # æœ€é•¿ç­‰å¾…1å°æ—¶
        poll_failures = 0
        max_poll_failures = 5  # æœ€å¤§è½®è¯¢å¤±è´¥æ¬¡æ•°
        
        while time.time() - start_time < max_wait_time:
            try:
                response = requests.get(f"{self.api_history}/{prompt_id}", timeout=10)
                
                if response.status_code == 200:
                    history = response.json()
                    
                    if history and len(history) > 0:
                        status = history[prompt_id]
                        
                        if status.get("status", {}).get("completed", False):
                            print(f"âœ… ä»»åŠ¡ {prompt_id} å·²å®Œæˆ")
                            return True
                        
                        if status.get("status", {}).get("has_error", False):
                            print(f"âŒ ä»»åŠ¡ {prompt_id} æ‰§è¡Œå¤±è´¥")
                            return False
                
                # ä»»åŠ¡ä»åœ¨è¿›è¡Œä¸­
                poll_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
                time.sleep(poll_interval)
                
            except requests.exceptions.RequestException as e:
                print(f"âš ï¸ è½®è¯¢å¤±è´¥: {e}")
                poll_failures += 1
                
                if poll_failures >= max_poll_failures:
                    print(f"âŒ è½®è¯¢å¤±è´¥è¶…è¿‡ {max_poll_failures} æ¬¡ï¼Œè®¤ä¸ºä»»åŠ¡å¤±è´¥")
                    return False
                
                time.sleep(poll_interval)
        
        print(f"âŒ ä»»åŠ¡ {prompt_id} è¶…æ—¶")
        return False
    
    def wait_for_completion_with_restart(self, prompt_id: str, video_name: str, poll_interval: int = 5) -> Tuple[bool, bool]:
        """
        ç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œæ”¯æŒè¿æ¥å¤±è´¥æ—¶çš„è‡ªåŠ¨é‡å¯
        
        å‚æ•°:
            prompt_id: ä»»åŠ¡ID
            video_name: å½“å‰å¤„ç†çš„è§†é¢‘åç§°ï¼ˆç”¨äºæ¸…ç†è¾“å‡ºæ–‡ä»¶ï¼‰
            poll_interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
        
        è¿”å›:
            (success: bool, was_restarted: bool) - æ˜¯å¦æˆåŠŸï¼Œæ˜¯å¦é‡å¯äº†ComfyUI
        """
        print(f"â³ ç­‰å¾…ä»»åŠ¡ {prompt_id} å®Œæˆ...")
        
        start_time = time.time()
        max_wait_time = 3600
        poll_failures = 0
        max_poll_failures = 10
        
        while time.time() - start_time < max_wait_time:
            try:
                response = requests.get(f"{self.api_history}/{prompt_id}", timeout=10)
                
                if response.status_code == 200:
                    history = response.json()
                    
                    if history and len(history) > 0:
                        status = history[prompt_id]
                        
                        if status.get("status", {}).get("completed", False):
                            print(f"âœ… ä»»åŠ¡ {prompt_id} å·²å®Œæˆ")
                            return True, False
                        
                        if status.get("status", {}).get("has_error", False):
                            print(f"âŒ ä»»åŠ¡ {prompt_id} æ‰§è¡Œå¤±è´¥")
                            return False, False
                
                # ä»»åŠ¡ä»åœ¨è¿›è¡Œä¸­
                poll_failures = 0
                time.sleep(poll_interval)
                
            except requests.exceptions.RequestException as e:
                print(f"âš ï¸ è½®è¯¢å¤±è´¥: {e}")
                poll_failures += 1
                
                if poll_failures >= max_poll_failures:
                    print(f"âŒ è½®è¯¢å¤±è´¥è¶…è¿‡ {max_poll_failures} æ¬¡ï¼Œå°†é‡å¯ComfyUI")
                    
                    # æ¸…ç†å½“å‰è§†é¢‘çš„è¾“å‡ºæ–‡ä»¶
                    self.clean_output_files(video_name)
                    
                    # é‡å¯ComfyUI
                    if self.restart_comfyui():
                        print(f"ğŸ”„ ComfyUIå·²é‡å¯ï¼Œè¿”å›å¤±è´¥çŠ¶æ€ä»¥ä¾¿é‡è¯•")
                        return False, True
                    else:
                        print(f"âŒ ComfyUIé‡å¯å¤±è´¥ï¼Œä»»åŠ¡ä¸­æ­¢")
                        return False, False
                
                time.sleep(poll_interval)
        
        print(f"âŒ ä»»åŠ¡ {prompt_id} è¶…æ—¶")
        return False, False
    
    def clean_output_files(self, video_name: str):
        """
        æ¸…ç†æŒ‡å®šè§†é¢‘çš„è¾“å‡ºæ–‡ä»¶
        
        å‚æ•°:
            video_name: è§†é¢‘æ–‡ä»¶åï¼ˆç”¨äºåŒ¹é…è¾“å‡ºæ–‡ä»¶ï¼‰
        """
        print(f"ğŸ§¹ æ¸…ç† {video_name} çš„è¾“å‡ºæ–‡ä»¶...")
        
        try:
            # è·å–è§†é¢‘åŸºæœ¬åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
            base_name = os.path.splitext(video_name)[0]
            
            # æ„å»ºæ–‡ä»¶åŒ¹é…æ¨¡å¼
            patterns = [
                f"flashvsr_*{base_name}*",
                f"*{base_name}*enhanced*",
                f"*{base_name}*_batch*"
            ]
            
            deleted_count = 0
            for pattern in patterns:
                for file_path in glob(os.path.join(self.output_dir, pattern)):
                    try:
                        os.remove(file_path)
                        print(f"  åˆ é™¤: {os.path.basename(file_path)}")
                        deleted_count += 1
                    except Exception as e:
                        print(f"  åˆ é™¤å¤±è´¥ {file_path}: {e}")
            
            if deleted_count > 0:
                print(f"âœ… å·²æ¸…ç† {deleted_count} ä¸ªè¾“å‡ºæ–‡ä»¶")
            else:
                print("â„¹ï¸ æœªæ‰¾åˆ°éœ€è¦æ¸…ç†çš„è¾“å‡ºæ–‡ä»¶")
                
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def get_video_frame_count(self, video_path: str) -> Tuple[int, float, str]:
        """
        è·å–è§†é¢‘çš„æ€»å¸§æ•°ã€å¸§ç‡å’Œæ£€æµ‹æ–¹æ³•
        """
        try:
            if PYMEDIAINFO_AVAILABLE:
                media_info = MediaInfo.parse(video_path)
                video_track = None
                
                for track in media_info.tracks:
                    if track.track_type == 'Video':
                        video_track = track
                        break
                
                if video_track:
                    frame_count = 0
                    if hasattr(video_track, 'frame_count') and video_track.frame_count:
                        frame_count = int(video_track.frame_count)
                    
                    frame_rate = 25.0
                    if hasattr(video_track, 'frame_rate') and video_track.frame_rate:
                        try:
                            frame_rate_str = str(video_track.frame_rate)
                            if '/' in frame_rate_str:
                                numerator, denominator = map(float, frame_rate_str.split('/'))
                                frame_rate = numerator / denominator
                            else:
                                frame_rate = float(frame_rate_str)
                        except:
                            frame_rate = 25.0
                    
                    if frame_count > 0:
                        return frame_count, frame_rate, "pymediainfo"
            
            # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨ OpenCV
            try:
                import cv2
                cap = cv2.VideoCapture(video_path)
                if cap.isOpened():
                    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    cap.release()
                    
                    if frame_count > 0 and fps > 0:
                        return frame_count, fps, "OpenCV"
            except ImportError:
                pass
            
            print(f"âš ï¸  æ— æ³•è·å– {os.path.basename(video_path)} çš„å‡†ç¡®å¸§æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return 100, 25.0, "é»˜è®¤å€¼"
            
        except Exception as e:
            print(f"âš ï¸  è·å–è§†é¢‘ä¿¡æ¯å¤±è´¥ {os.path.basename(video_path)}: {e}")
            return 100, 25.0, "é”™è¯¯-é»˜è®¤å€¼"
    
    def load_workflow_template(self, template_path: str) -> Dict:
        """åŠ è½½å·¥ä½œæµ JSON æ¨¡æ¿"""
        with open(template_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def update_workflow_parameters(
        self, 
        workflow: Dict, 
        video_path: str, 
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 201,
        gpu_device: str = "auto"
    ) -> Dict:
        """æ›´æ–°å·¥ä½œæµä¸­çš„æ‰€æœ‰å‚æ•°"""
        modified_workflow = json.loads(json.dumps(workflow))
        
        # 1. è®¾ç½®è¾“å…¥è§†é¢‘è·¯å¾„
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_LoadVideo":
                node_data["inputs"]["video"] = video_path
        
        # 2. è®¾ç½® FlashVSR æ ¸å¿ƒå‚æ•°
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "FlashVSRNodeAdv":
                if "{{scale}}" in str(node_data["inputs"].get("scale", "")):
                    node_data["inputs"]["scale"] = scale
                if "{{t_z}}" in str(node_data["inputs"].get("tile_size", "")):
                    node_data["inputs"]["tile_size"] = tile_size
                if "{{t_o}}" in str(node_data["inputs"].get("tile_overlap", "")):
                    node_data["inputs"]["tile_overlap"] = tile_overlap
        
        # 3. è®¾ç½® GPU è®¾å¤‡
        for node_id, node_data in modified_workflow.items():
            if node_id == "5" and node_data.get("class_type") == "FlashVSRInitPipe":
                if "{{gpu}}" in str(node_data["inputs"].get("device", "")):
                    if gpu_device == "auto":
                        device_value = "auto"
                    elif gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    node_data["inputs"]["device"] = device_value
                    print(f"âœ… å·²å°†GPUè®¾å¤‡è®¾ç½®ä¸º: {device_value}")
                elif isinstance(node_data["inputs"].get("device"), str):
                    if gpu_device.isdigit():
                        device_value = f"cuda:{gpu_device}"
                    else:
                        device_value = gpu_device
                    node_data["inputs"]["device"] = device_value
                    print(f"âœ… å·²å°†GPUè®¾å¤‡è®¾ç½®ä¸º: {device_value} (ç›´æ¥èµ‹å€¼)")
        
        # 4. è®¾ç½®æ€»å¸§æ•°
        if total_frames is None:
            total_frames, _, _ = self.get_video_frame_count(video_path)
        
        for node_id, node_data in modified_workflow.items():
            if node_id == "50" and node_data.get("class_type") == "PrimitiveInt":
                current_value = str(node_data["inputs"].get("value", ""))
                if "{{TOTAL_FRAMES}}" in current_value or "{{TATAL_FRAMES}}" in current_value:
                    node_data["inputs"]["value"] = total_frames
                    print(f"âœ… å·²å°†æ€»å¸§æ•° {total_frames} è®¾ç½®åˆ°èŠ‚ç‚¹ 50")
                elif isinstance(node_data["inputs"].get("value"), (int, float)):
                    node_data["inputs"]["value"] = total_frames
                    print(f"âœ… å·²å°†æ€»å¸§æ•° {total_frames} è®¾ç½®åˆ°èŠ‚ç‚¹ 50 (ç›´æ¥èµ‹å€¼)")
                else:
                    print(f"âš ï¸  èŠ‚ç‚¹ 50 çš„å€¼æ—¢ä¸æ˜¯å ä½ç¬¦ä¹Ÿä¸æ˜¯æ•°å­—: {current_value}")
        
        # 5. è®¾ç½®æ¯æ‰¹å¸§æ•°
        for node_id, node_data in modified_workflow.items():
            if node_id == "8" and node_data.get("class_type") == "PrimitiveInt":
                if "{{FRAMES_PER_BATCH}}" in str(node_data["inputs"].get("value", "")):
                    node_data["inputs"]["value"] = frames_per_batch
                    print(f"âœ… å·²å°†æ¯æ‰¹å¸§æ•° {frames_per_batch} è®¾ç½®åˆ°èŠ‚ç‚¹ 8")
                elif isinstance(node_data["inputs"].get("value"), (int, float)):
                    node_data["inputs"]["value"] = frames_per_batch
                    print(f"âœ… å·²å°†æ¯æ‰¹å¸§æ•° {frames_per_batch} è®¾ç½®åˆ°èŠ‚ç‚¹ 8 (ç›´æ¥èµ‹å€¼)")
        
        # 6. è®¾ç½®è¾“å‡ºæ–‡ä»¶åå‰ç¼€
        if output_prefix is None:
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            output_prefix = f"flashvsr_{base_name}_enhanced"
        
        for node_id, node_data in modified_workflow.items():
            if node_data.get("class_type") == "VHS_VideoCombine":
                if "{{OUTPUT_PREFIX}}" in str(node_data["inputs"].get("filename_prefix", "")):
                    node_data["inputs"]["filename_prefix"] = output_prefix
                elif isinstance(node_data["inputs"].get("filename_prefix"), str):
                    node_data["inputs"]["filename_prefix"] = output_prefix
        
        return modified_workflow
    
    def queue_prompt(self, workflow: Dict, timeout: int = 300) -> Optional[str]:
        """å°†å·¥ä½œæµå‘é€åˆ° ComfyUI æ‰§è¡Œ"""
        if not self.check_comfyui_server():
            print("âŒ ComfyUI æœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•æäº¤ä»»åŠ¡")
            return None
        
        print("=== å·¥ä½œæµå‚æ•°éªŒè¯ ===")
        for node_id, node_data in workflow.items():
            if node_id in ["5", "8", "50"]:
                print(f"èŠ‚ç‚¹ {node_id} ({node_data.get('class_type')}): {node_data['inputs']}")

        try:
            response = requests.post(
                self.api_prompt, 
                json={"prompt": workflow}, 
                timeout=timeout
            )
            response.raise_for_status()
            
            data = response.json()
            prompt_id = data.get('prompt_id')
            
            if prompt_id:
                print(f"âœ… ä»»åŠ¡å·²æäº¤ï¼ŒID: {prompt_id}")
                return prompt_id
            else:
                print(f"âŒ æœªæ”¶åˆ°ä»»åŠ¡IDï¼Œå“åº”: {data}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
            return None
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æå¤±è´¥: {e}")
            return None
    
    def get_output_files(self, prompt_id: str) -> List[str]:
        """è·å–ä»»åŠ¡ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶åˆ—è¡¨"""
        try:
            response = requests.get(f"{self.api_view}/{prompt_id}", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                outputs = data.get("outputs", {})
                file_list = []
                
                for node_id, node_output in outputs.items():
                    if "images" in node_output:
                        for img in node_output["images"]:
                            if "filename" in img:
                                file_list.append(img["filename"])
                
                return file_list
                
        except Exception as e:
            print(f"âš ï¸ è·å–è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
        
        return []
    
    def process_single_video(
        self, 
        workflow_template: Dict, 
        video_path: str, 
        output_prefix: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 64,
        tile_overlap: int = 8,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 125,
        gpu_device: str = "auto"
    ) -> Tuple[bool, int]:
        """
        å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œæ”¯æŒé‡è¯•
        
        è¿”å›:
            (success: bool, retry_count: int) - æ˜¯å¦æˆåŠŸï¼Œé‡è¯•æ¬¡æ•°
        """
        video_name = os.path.basename(video_path)
        print(f"\n{'='*60}")
        print(f"å¤„ç†è§†é¢‘: {video_path}")
        print(f"{'='*60}")
        
        if not os.path.exists(video_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return False, 0
        
        # è·å–è§†é¢‘ä¿¡æ¯
        detected_total_frames, fps, detection_method = self.get_video_frame_count(video_path)
        
        if total_frames is None:
            total_frames = detected_total_frames
            print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {total_frames} å¸§, {fps:.2f} FPS (è‡ªåŠ¨æ£€æµ‹)")
            print(f"ğŸ” æ£€æµ‹æ–¹æ³•: {detection_method}")
        else:
            print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {total_frames} å¸§ (æ‰‹åŠ¨æŒ‡å®š), {fps:.2f} FPS (è‡ªåŠ¨æ£€æµ‹)")
        
        if frames_per_batch > 0 and total_frames > 0:
            batch_count = math.ceil(total_frames / frames_per_batch)
            print(f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡: {batch_count} æ‰¹ï¼ˆæ¯æ‰¹ {frames_per_batch} å¸§ï¼‰")
        
        if fps > 0 and total_frames > 0:
            duration_seconds = total_frames / fps
            minutes = int(duration_seconds // 60)
            seconds = int(duration_seconds % 60)
            print(f"â±ï¸  è§†é¢‘æ—¶é•¿: {minutes}:{seconds:02d} (mm:ss)")
        
        if gpu_device == "auto":
            print(f"ğŸ® GPUè®¾å¤‡: auto (è‡ªåŠ¨é€‰æ‹©)")
        elif gpu_device.isdigit():
            print(f"ğŸ® GPUè®¾å¤‡: cuda:{gpu_device}")
        else:
            print(f"ğŸ® GPUè®¾å¤‡: {gpu_device}")
        
        # æ›´æ–°å·¥ä½œæµå‚æ•°
        workflow = self.update_workflow_parameters(
            workflow_template, 
            video_path, 
            output_prefix,
            scale=scale,
            tile_size=tile_size,
            tile_overlap=tile_overlap,
            total_frames=total_frames,
            frames_per_batch=frames_per_batch,
            gpu_device=gpu_device
        )
        
        # å°è¯•æäº¤ä»»åŠ¡ï¼Œæœ€å¤šé‡è¯•3æ¬¡
        max_retries = 3
        for retry_count in range(max_retries):
            print(f"\nğŸ”„ å°è¯• {retry_count + 1}/{max_retries}")
            
            # æäº¤ä»»åŠ¡
            prompt_id = self.queue_prompt(workflow)
            if not prompt_id:
                if retry_count < max_retries - 1:
                    print("â³ ä»»åŠ¡æäº¤å¤±è´¥ï¼Œ5ç§’åé‡è¯•...")
                    time.sleep(5)
                    continue
                return False, retry_count + 1
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼Œæ”¯æŒè‡ªåŠ¨é‡å¯
            success, was_restarted = self.wait_for_completion_with_restart(
                prompt_id, 
                os.path.splitext(video_name)[0]  # åªä¼ åŸºæœ¬åç§°
            )
            
            if was_restarted:
                # å¦‚æœComfyUIè¢«é‡å¯ï¼Œéœ€è¦é‡è¯•
                if retry_count < max_retries - 1:
                    print("â³ ComfyUIå·²é‡å¯ï¼Œ5ç§’åé‡è¯•æ­¤ä»»åŠ¡...")
                    time.sleep(5)
                    continue
                else:
                    return False, retry_count + 1
            elif not success:
                if retry_count < max_retries - 1:
                    print("â³ ä»»åŠ¡å¤„ç†å¤±è´¥ï¼Œ5ç§’åé‡è¯•...")
                    time.sleep(5)
                    continue
                return False, retry_count + 1
            else:
                # æˆåŠŸ
                output_files = self.get_output_files(prompt_id)
                if output_files:
                    print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ï¼ˆä¿å­˜åœ¨ ComfyUI é»˜è®¤è¾“å‡ºç›®å½•ï¼‰:")
                    for file in output_files:
                        print(f"  - {file}")
                else:
                    print("â„¹ï¸  ä»»åŠ¡å®Œæˆï¼Œä½†æœªè·å–åˆ°è¾“å‡ºæ–‡ä»¶åˆ—è¡¨")
                return True, retry_count + 1
        
        return False, max_retries
    
    def batch_process_videos(
        self, 
        workflow_template_path: str, 
        video_files: List[str], 
        output_prefix_base: Optional[str] = None,
        scale: float = 4.0,
        tile_size: int = 256,
        tile_overlap: int = 24,
        total_frames: Optional[int] = None,
        frames_per_batch: int = 201,
        gpu_device: str = "auto"
    ) -> Dict[str, Dict]:
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘æ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œé‡è¯•
        
        è¿”å›:
            å­—å…¸ï¼š{è§†é¢‘æ–‡ä»¶: {æˆåŠŸ: bool, é‡è¯•æ¬¡æ•°: int, ä¿¡æ¯: str}}
        """
        # åŠ è½½å·¥ä½œæµæ¨¡æ¿
        try:
            workflow_template = self.load_workflow_template(workflow_template_path)
        except Exception as e:
            print(f"âŒ åŠ è½½å·¥ä½œæµæ¨¡æ¿å¤±è´¥: {e}")
            return {}
        
        # å…ˆæ£€æŸ¥ComfyUIæœåŠ¡
        if not self.check_comfyui_server():
            print("âŒ ComfyUI æœåŠ¡æœªè¿è¡Œï¼Œæ­£åœ¨å¯åŠ¨...")
            if not self.start_comfyui():
                print("âŒ æ— æ³•å¯åŠ¨ComfyUIï¼Œç¨‹åºé€€å‡º")
                return {}
        
        results = {}
        total_videos = len(video_files)
        
        print(f"ğŸ¬ å¼€å§‹æ‰¹é‡å¤„ç† {total_videos} ä¸ªè§†é¢‘")
        print(f"âš™ï¸  å‚æ•°: scale={scale}, tile_size={tile_size}, tile_overlap={tile_overlap}")
        print(f"ğŸ® GPUè®¾å¤‡: {gpu_device}")
        print(f"ğŸ”„ æ¯ä¸ªä»»åŠ¡æœ€å¤šé‡è¯•: 3æ¬¡")
        print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {self.output_dir}")
        
        for i, video_path in enumerate(video_files, 1):
            print(f"\nğŸ“Š è¿›åº¦: {i}/{total_videos}")
            
            # è®¾ç½®è¾“å‡ºå‰ç¼€
            output_prefix = None
            if output_prefix_base:
                base_name = os.path.splitext(os.path.basename(video_path))[0]
                output_prefix = f"{output_prefix_base}_{base_name}"
            
            # å¤„ç†å•ä¸ªè§†é¢‘
            success, retry_count = self.process_single_video(
                workflow_template, 
                video_path, 
                output_prefix,
                scale=scale,
                tile_size=tile_size,
                tile_overlap=tile_overlap,
                total_frames=total_frames,
                frames_per_batch=frames_per_batch,
                gpu_device=gpu_device
            )
            
            results[video_path] = {
                "success": success,
                "retry_count": retry_count,
                "message": "æˆåŠŸ" if success else f"å¤±è´¥ï¼ˆé‡è¯•{retry_count}æ¬¡ï¼‰"
            }
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'='*60}")
        print("æ‰¹é‡å¤„ç†å®Œæˆ")
        print(f"{'='*60}")
        
        success_count = sum(1 for r in results.values() if r["success"])
        total_retries = sum(r["retry_count"] for r in results.values())
        
        print(f"âœ… æˆåŠŸ: {success_count}/{total_videos}")
        print(f"âŒ å¤±è´¥: {total_videos - success_count}/{total_videos}")
        print(f"ğŸ”„ æ€»é‡è¯•æ¬¡æ•°: {total_retries}")
        print(f"ğŸ® GPUè®¾å¤‡: {gpu_device}")
        print(f"ğŸ’¾ è¾“å‡ºä½ç½®: {self.output_dir}")
        
        if success_count > 0:
            print(f"\nâœ… æˆåŠŸæ–‡ä»¶åˆ—è¡¨:")
            for video_path, result in results.items():
                if result["success"]:
                    print(f"  âœ“ {os.path.basename(video_path)} (é‡è¯•: {result['retry_count']})")
        
        if success_count < total_videos:
            print(f"\nâŒ å¤±è´¥æ–‡ä»¶åˆ—è¡¨:")
            for video_path, result in results.items():
                if not result["success"]:
                    print(f"  âœ— {os.path.basename(video_path)} (é‡è¯•: {result['retry_count']})")
        
        return results

def collect_video_files(input_path: str, pattern: str = '*.mp4') -> List[str]:
    """æ ¹æ®è¾“å…¥è·¯å¾„æ”¶é›†è§†é¢‘æ–‡ä»¶"""
    video_files = []
    
    if os.path.isfile(input_path):
        if input_path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv')):
            video_files.append(input_path)
            print(f"âœ… æ·»åŠ å•ä¸ªæ–‡ä»¶: {input_path}")
        else:
            print(f"âŒ æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ: {input_path}")
    elif os.path.isdir(input_path):
        search_pattern = os.path.join(input_path, pattern)
        found_files = glob(search_pattern)
        
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.flv', '.MP4', '.MOV', '.AVI', '.MKV']
        for ext in video_extensions:
            if ext not in pattern:
                additional_pattern = os.path.join(input_path, f"*{ext}")
                additional_files = glob(additional_pattern)
                found_files.extend(additional_files)
        
        video_files = sorted(list(set(found_files)))
        
        if not video_files:
            print(f"âŒ ç›®å½• {input_path} ä¸­æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        else:
            print(f"âœ… ä»ç›®å½• {input_path} æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    else:
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    return video_files

def main():
    """ä¸»å‡½æ•°ï¼šæ‰¹é‡å¤„ç†è§†é¢‘ç¤ºä¾‹"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='ComfyUI FlashVSR æ‰¹é‡è§†é¢‘å¤„ç†å·¥å…· - å¢å¼ºç‰ˆï¼ˆæ”¯æŒè‡ªåŠ¨é‡å¯å’Œæ–­ç‚¹ç»­ä¼ ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨GPU 0
  python batch_process_videos.py --input video.mp4 --gpu 0
  
  # å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰è§†é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨GPU 1
  python batch_process_videos.py --input ./videos --gpu 1
  
  # è‡ªåŠ¨é€‰æ‹©GPU
  python batch_process_videos.py --input ./videos --gpu auto
  
  # è‡ªå®šä¹‰å‚æ•°
  python batch_process_videos.py --input ./videos --scale 2.0 --tile-size 128 --gpu 0
  
  # æ‰‹åŠ¨æŒ‡å®šæ€»å¸§æ•°
  python batch_process_videos.py --input ./videos --total-frames 300 --gpu 0
  
  # è®¾ç½®è¾“å‡ºæ–‡ä»¶å‰ç¼€
  python batch_process_videos.py --input ./videos --output-prefix batch_001 --gpu 0

è‡ªåŠ¨é‡å¯åŠŸèƒ½:
  - å½“è½®è¯¢å¤±è´¥è¶…è¿‡10æ¬¡æ—¶ï¼Œè‡ªåŠ¨é‡å¯ComfyUI
  - é‡å¯å‰ä¼šæ¸…ç†å½“å‰è§†é¢‘çš„è¾“å‡ºæ–‡ä»¶
  - é‡å¯åè‡ªåŠ¨é‡æ–°å¤„ç†å½“å‰è§†é¢‘
  - æ¯ä¸ªè§†é¢‘æœ€å¤šé‡è¯•3æ¬¡
        """
    )
    
    # è¾“å…¥å‚æ•°
    input_group = parser.add_argument_group('è¾“å…¥é€‰é¡¹')
    input_group.add_argument('--template', type=str, default='flashvsr_template.json',
                           help='å·¥ä½œæµæ¨¡æ¿ JSON æ–‡ä»¶è·¯å¾„ (é»˜è®¤: flashvsr_template.json)')
    input_group.add_argument('--input', type=str, required=True,
                           help='è¾“å…¥è·¯å¾„ï¼ˆå¯ä»¥æ˜¯è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–åŒ…å«è§†é¢‘æ–‡ä»¶çš„ç›®å½•ï¼‰')
    input_group.add_argument('--pattern', type=str, default='*.mp4',
                           help='è§†é¢‘æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œå½“è¾“å…¥æ˜¯ç›®å½•æ—¶ä½¿ç”¨ (é»˜è®¤: *.mp4)')
    
    # è¾“å‡ºå‚æ•°
    output_group = parser.add_argument_group('è¾“å‡ºé€‰é¡¹')
    output_group.add_argument('--output-prefix', type=str, 
                            help='è¾“å‡ºæ–‡ä»¶åå‰ç¼€ï¼ˆå¯é€‰ï¼Œç”¨äºåŒºåˆ†æ‰¹æ¬¡ï¼‰')
    
    # FlashVSR å¤„ç†å‚æ•°
    processing_group = parser.add_argument_group('å¤„ç†å‚æ•°')
    processing_group.add_argument('--scale', type=float, default=4.0,
                                help='æ”¾å¤§å€æ•° (é»˜è®¤: 4.0)')
    processing_group.add_argument('--tile-size', type=int, default=256,
                                help='åˆ†å—å¤§å° (é»˜è®¤: 256)')
    processing_group.add_argument('--tile-overlap', type=int, default=24,
                                help='åˆ†å—é‡å åƒç´  (é»˜è®¤: 24)')
    processing_group.add_argument('--frames-per-batch', type=int, default=201,
                                help='æ¯æ‰¹å¤„ç†çš„å¸§æ•° (é»˜è®¤: 201)')
    processing_group.add_argument('--total-frames', type=int,
                                help='è§†é¢‘æ€»å¸§æ•° (å¦‚ä¸æä¾›åˆ™è‡ªåŠ¨æ£€æµ‹)')
    
    # GPUå‚æ•°
    gpu_group = parser.add_argument_group('GPUé€‰é¡¹')
    gpu_group.add_argument('--gpu', type=str, default='auto',
                         help='GPUè®¾å¤‡é€‰æ‹©: auto, 0, 1, 2, cuda:0, cuda:1ç­‰ (é»˜è®¤: auto)')
    
    # ç³»ç»Ÿå‚æ•°
    system_group = parser.add_argument_group('ç³»ç»Ÿå‚æ•°')
    system_group.add_argument('--server', type=str, default='http://127.0.0.1:8188',
                            help='ComfyUI æœåŠ¡å™¨åœ°å€ (é»˜è®¤: http://127.0.0.1:8188)')
    system_group.add_argument('--skip-pymedia-check', action='store_true',
                            help='è·³è¿‡ pymediainfo æ£€æŸ¥')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ pymediainfo
    if not PYMEDIAINFO_AVAILABLE and not args.skip_pymedia_check:
        print("âš ï¸  æœªæ£€æµ‹åˆ° pymediainfo åº“")
        print("   å»ºè®®å®‰è£…ä»¥è·å¾—æ›´å‡†ç¡®çš„è§†é¢‘å¸§æ•°æ£€æµ‹:")
        print("   pip install pymediainfo")
        print("   æˆ–æ·»åŠ  --skip-pymedia-check å‚æ•°è·³è¿‡æ­¤è­¦å‘Š")
        
        response = input("æ˜¯å¦ç»§ç»­? (y/n): ")
        if response.lower() != 'y':
            print("é€€å‡ºç¨‹åº")
            return
    
    # å‡†å¤‡è§†é¢‘æ–‡ä»¶åˆ—è¡¨
    video_files = collect_video_files(args.input, args.pattern)
    
    if not video_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        return
    
    print(f"\næ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶:")
    for vf in video_files:
        print(f"  - {vf}")
    
    # æ˜¾ç¤ºå¤„ç†å‚æ•°
    print(f"\nâš™ï¸  å¤„ç†å‚æ•°:")
    print(f"  scale: {args.scale}")
    print(f"  tile_size: {args.tile_size}")
    print(f"  tile_overlap: {args.tile_overlap}")
    print(f"  frames_per_batch: {args.frames_per_batch}")
    
    if args.total_frames:
        print(f"  total_frames: {args.total_frames} (æ‰‹åŠ¨æŒ‡å®š)")
    else:
        print(f"  total_frames: è‡ªåŠ¨æ£€æµ‹")
    
    if args.output_prefix:
        print(f"  output_prefix: {args.output_prefix} (è¾“å‡ºæ–‡ä»¶åå‰ç¼€)")
    
    if args.gpu == "auto":
        print(f"ğŸ® GPUè®¾å¤‡: auto (è‡ªåŠ¨é€‰æ‹©)")
    elif args.gpu.isdigit():
        print(f"ğŸ® GPUè®¾å¤‡: cuda:{args.gpu}")
    else:
        print(f"ğŸ® GPUè®¾å¤‡: {args.gpu}")
    
    print(f"ğŸ’¾ è¾“å‡ºç›®å½•: F:\\AI\\ComfyUI_Mie_V7.0\\comfyui\\output")
    print(f"ğŸ”„ æ¯ä¸ªä»»åŠ¡æœ€å¤šé‡è¯•: 3æ¬¡")
    print(f"ğŸ”„ è½®è¯¢å¤±è´¥å¤„ç†: è¶…è¿‡10æ¬¡è‡ªåŠ¨é‡å¯ComfyUI")
    print(f"ğŸ”§ æ–­ç‚¹ç»­ä¼ : æ”¯æŒ (å¤±è´¥æ—¶è‡ªåŠ¨æ¸…ç†å¹¶é‡è¯•)")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = ComfyUI_FlashVSR_BatchProcessor(comfyui_url=args.server)
    
    # æ‰¹é‡å¤„ç†
    start_time = time.time()
    
    results = processor.batch_process_videos(
        workflow_template_path=args.template,
        video_files=video_files,
        output_prefix_base=args.output_prefix,
        scale=args.scale,
        tile_size=args.tile_size,
        tile_overlap=args.tile_overlap,
        total_frames=args.total_frames,
        frames_per_batch=args.frames_per_batch,
        gpu_device=args.gpu
    )
    
    # è®¡ç®—æ€»è€—æ—¶
    total_time = time.time() - start_time
    print(f"\nâ±ï¸  æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"ğŸ’¾ æ‰€æœ‰è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜åˆ°: F:\\AI\\ComfyUI_Mie_V7.0\\comfyui\\output")
    print(f"   æ‚¨å¯ä»¥åœ¨ ComfyUI çš„ output æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°ç”Ÿæˆçš„æ–‡ä»¶")
    
    # æœ€åå…³é—­ComfyUIè¿›ç¨‹
    print(f"\nğŸ”§ å¤„ç†å®Œæˆï¼Œæ­£åœ¨å…³é—­ComfyUIè¿›ç¨‹...")
    processor.kill_comfyui_processes()
    print("âœ… æ‰€æœ‰å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()
