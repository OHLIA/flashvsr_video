#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import re
import time
import argparse
import numpy as np
from PIL import Image
import imageio
from tqdm import tqdm
import torch
from einops import rearrange
import subprocess
import tempfile
import shutil
import json
import threading
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed
import math

# æ·»åŠ  pymediainfo å¯¼å…¥
try:
    from pymediainfo import MediaInfo
    PYMEDIAINFO_AVAILABLE = True
except ImportError:
    print("è­¦å‘Š: æœªå®‰è£… pymediainfoï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
    PYMEDIAINFO_AVAILABLE = False

from diffsynth import ModelManager, FlashVSRTinyLongPipeline
from utils.utils import Causal_LQ4x_Proj
from utils.TCDecoder import build_tcdecoder

# å…¨å±€å˜é‡ç”¨äºè®°å½•æ—¥å¿—ä¿¡æ¯
log_context = {"current_task": 0, "total_tasks": 0, "parallel_tasks": 0}

def log_message(message, task_id=None, parallel_tasks=None):
    """ç»Ÿä¸€çš„æ—¥å¿—è¾“å‡ºå‡½æ•°ï¼Œæ”¯æŒä»»åŠ¡åºå·å’Œå¹¶è¡Œä»»åŠ¡æ•°æ ‡è¯†"""
    if task_id is None:
        task_id = log_context.get("current_task", 0)
    if parallel_tasks is None:
        parallel_tasks = log_context.get("parallel_tasks", 0)
    
    prefix = f"[{task_id}/{parallel_tasks}]" if task_id > 0 else "[0/0]"
    print(f"{prefix} {message}")

def get_video_info_accurate(path):
    """ä½¿ç”¨ pymediainfo è·å–ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯"""
    if not PYMEDIAINFO_AVAILABLE:
        return get_video_info_fallback(path)
    
    try:
        media_info = MediaInfo.parse(path)
        video_track = None
        general_track = None
        
        for track in media_info.tracks:
            if track.track_type == 'Video':
                video_track = track
            elif track.track_type == 'General':
                general_track = track
        
        if not video_track:
            raise ValueError("æœªæ‰¾åˆ°è§†é¢‘æµ")
        
        # è·å–ç²¾ç¡®çš„å¸§ç‡
        frame_rate = None
        if hasattr(video_track, 'frame_rate') and video_track.frame_rate:
            frame_rate_str = str(video_track.frame_rate)
            # å¤„ç†åˆ†æ•°å½¢å¼çš„å¸§ç‡ (å¦‚ 30000/1001)
            if '/' in frame_rate_str:
                try:
                    numerator, denominator = map(float, frame_rate_str.split('/'))
                    frame_rate = numerator / denominator
                except:
                    frame_rate = float(frame_rate_str)
            else:
                frame_rate = float(frame_rate_str)
        
        # è·å–æ€»å¸§æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ç²¾ç¡®ç»Ÿè®¡ï¼‰
        frame_count = None
        if hasattr(video_track, 'frame_count') and video_track.frame_count:
            frame_count = int(video_track.frame_count)
        
        # è·å–æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰- ä¼˜å…ˆä½¿ç”¨è§†é¢‘æµæ—¶é•¿
        duration_ms = None
        if hasattr(video_track, 'duration') and video_track.duration:
            duration_ms = float(video_track.duration)
            log_message(f"ä½¿ç”¨è§†é¢‘æµæ—¶é•¿: {duration_ms}ms")
        elif hasattr(general_track, 'duration') and general_track.duration:
            duration_ms = float(general_track.duration)
            log_message(f"ä½¿ç”¨å®¹å™¨æ—¶é•¿: {duration_ms}ms")
        
        # è®¡ç®—æ—¶é•¿ï¼ˆç§’ï¼‰
        duration_seconds = duration_ms / 1000.0 if duration_ms else None
        
        # å¦‚æœå¸§æ•°æœªçŸ¥ä½†æ—¶é•¿å’Œå¸§ç‡å·²çŸ¥ï¼Œè®¡ç®—å¸§æ•°
        if frame_count is None and duration_seconds and frame_rate:
            frame_count = int(round(duration_seconds * frame_rate))
        
        # å¦‚æœæ—¶é•¿æœªçŸ¥ä½†å¸§æ•°å’Œå¸§ç‡å·²çŸ¥ï¼Œè®¡ç®—æ—¶é•¿
        if duration_seconds is None and frame_count and frame_rate:
            duration_seconds = frame_count / frame_rate
        
        # é»˜è®¤å€¼
        if frame_rate is None:
            frame_rate = 25.0
        if frame_count is None:
            # ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            return get_video_info_fallback(path)
        if duration_seconds is None:
            duration_seconds = frame_count / frame_rate
        
        # è·å–åˆ†è¾¨ç‡
        width = int(video_track.width) if hasattr(video_track, 'width') else 0
        height = int(video_track.height) if hasattr(video_track, 'height') else 0
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        calculated_frames = int(round(duration_seconds * frame_rate))
        if abs(calculated_frames - frame_count) > 2:  # å…è®¸2å¸§è¯¯å·®
            log_message(f"å¸§æ•°ä¸ä¸€è‡´: ç»Ÿè®¡={frame_count}, è®¡ç®—={calculated_frames}, ä½¿ç”¨ç»Ÿè®¡å€¼")
        
        log_message(f"pymediainfo ç²¾ç¡®ä¿¡æ¯: {frame_count}å¸§, {frame_rate:.6f}fps, {duration_seconds:.6f}ç§’")
        
        return {
            'frame_count': frame_count,
            'frame_rate': frame_rate,
            'duration': duration_seconds,
            'width': width,
            'height': height,
            'is_accurate': True
        }
        
    except Exception as e:
        log_message(f"pymediainfo è§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
        return get_video_info_fallback(path)

def get_video_info_fallback(path):
    """å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨ ffprobe è·å–è§†é¢‘ä¿¡æ¯"""
    try:
        # ä½¿ç”¨ ffprobe è·å–ç²¾ç¡®å¸§æ•°
        frame_count_cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'v:0',
            '-count_frames',
            '-show_entries', 'stream=nb_read_frames',
            '-of', 'csv=p=0',
            path
        ]
        
        result = subprocess.run(frame_count_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            frame_count = int(result.stdout.strip())
        else:
            frame_count = 0
        
        # è·å–æ—¶é•¿å’Œå¸§ç‡
        info_cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'v:0',
            '-show_entries', 'stream=r_frame_rate,duration,width,height',
            '-of', 'json',
            path
        ]
        
        result = subprocess.run(info_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            info = json.loads(result.stdout)
            stream = info['streams'][0] if info['streams'] else {}
            
            # è§£æå¸§ç‡
            frame_rate_str = stream.get('r_frame_rate', '25/1')
            if '/' in frame_rate_str:
                num, den = map(int, frame_rate_str.split('/'))
                frame_rate = num / den
            else:
                frame_rate = float(frame_rate_str)
            
            # è·å–æ—¶é•¿
            duration = float(stream.get('duration', 0))
            
            # å¦‚æœæ—¶é•¿æœªçŸ¥ï¼Œä½¿ç”¨å¸§æ•°å’Œå¸§ç‡è®¡ç®—
            if duration <= 0 and frame_count > 0:
                duration = frame_count / frame_rate
            
            # å¦‚æœå¸§æ•°æœªçŸ¥ï¼Œä½¿ç”¨æ—¶é•·å’Œå¸§ç‡è®¡ç®—
            if frame_count <= 0 and duration > 0:
                frame_count = int(round(duration * frame_rate))
            
            width = int(stream.get('width', 0))
            height = int(stream.get('height', 0))
            
            log_message(f"ffprobe ä¿¡æ¯: {frame_count}å¸§, {frame_rate:.6f}fps, {duration:.6f}ç§’")
            
            return {
                'frame_count': frame_count,
                'frame_rate': frame_rate,
                'duration': duration,
                'width': width,
                'height': height,
                'is_accurate': False
            }
    
    except Exception as e:
        log_message(f"å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
    
    # æœ€ç»ˆå¤‡ç”¨å€¼
    return {
        'frame_count': 250,  # é»˜è®¤å€¼
        'frame_rate': 25.0,
        'duration': 10.0,
        'width': 720,
        'height': 540,
        'is_accurate': False
    }

def tensor2video(frames):
    frames = rearrange(frames, "C T H W -> T H W C")
    frames = ((frames.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)
    frames = [Image.fromarray(frame) for frame in frames]
    return frames

def natural_key(name: str):
    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'([0-9]+)', os.path.basename(name))]

def list_images_natural(folder: str):
    exts = ('.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG')
    fs = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(exts)]
    fs.sort(key=natural_key)
    return fs

def list_videos_natural(folder: str):
    exts = ('.mp4', '.mov', '.avi', '.mkv', '.MP4', '.MOV', '.AVI', '.MKV')
    fs = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(exts)]
    fs.sort(key=natural_key)
    return fs

def get_input_files(input_path):
    input_files = []
    
    if os.path.isfile(input_path):
        input_files.append(input_path)
    elif os.path.isdir(input_path):
        video_files = list_videos_natural(input_path)
        input_files.extend(video_files)
        
        for item in os.listdir(input_path):
            item_path = os.path.join(input_path, item)
            if os.path.isdir(item_path):
                image_files = list_images_natural(item_path)
                if image_files:
                    input_files.append(item_path)
    else:
        raise ValueError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    return input_files

def largest_8n1_leq(n):
    return 0 if n < 1 else ((n - 1)//8)*8 + 1

def is_video(path):
    return os.path.isfile(path) and path.lower().endswith(('.mp4','.mov','.avi','.mkv'))

def pil_to_tensor_neg1_1(img: Image.Image, dtype=torch.bfloat16, device='cuda'):
    t = torch.from_numpy(np.asarray(img, np.uint8)).to(device=device, dtype=torch.float32)
    t = t.permute(2,0,1) / 255.0 * 2.0 - 1.0
    return t.to(dtype)

def save_video_directly_from_tensor(frames, save_path, fps=30, quality=5):
    """ç›´æ¥ä»å¼ é‡åˆ›å»ºè§†é¢‘ï¼Œè·³è¿‡PNGä¸­é—´æ­¥éª¤"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    w = imageio.get_writer(save_path, fps=fps, quality=quality)
    
    # å°†å¼ é‡è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ä¿å­˜
    frames_array = ((frames.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)
    frames_array = rearrange(frames_array, "C T H W -> T H W C")
    
    for i in tqdm(range(frames_array.shape[0]), desc=f"Creating video directly {os.path.basename(save_path)}"):
        frame = frames_array[i]
        w.append_data(frame)
    w.close()

def compute_scaled_and_target_dims(w0: int, h0: int, scale: float = 4.0, multiple: int = 128):
    if w0 <= 0 or h0 <= 0:
        raise ValueError("Invalid original size")
    if scale <= 0:
        raise ValueError("scale must be > 0")

    sW = int(round(w0 * scale))
    sH = int(round(h0 * scale))
    tW = (sW // multiple) * multiple
    tH = (sH // multiple) * multiple

    if tW == 0 or tH == 0:
        raise ValueError(
            f"Scaled size too small ({sW}x{sH}) for multiple={multiple}. "
            f"Increase scale (got {scale})."
        )
    return sW, sH, tW, tH

def upscale_then_center_crop(img: Image.Image, scale: float, tW: int, tH: int) -> Image.Image:
    w0, h0 = img.size
    sW = int(round(w0 * scale))
    sH = int(round(h0 * scale))

    if tW > sW or tH > sH:
        raise ValueError(
            f"Target crop ({tW}x{tH}) exceeds scaled size ({sW}x{sH}). "
            f"Increase scale."
        )

    up = img.resize((sW, sH), Image.BICUBIC)
    l = (sW - tW) // 2
    t = (sH - tH) // 2
    return up.crop((l, t, l + tW, t + tH))

def prepare_input_tensor(path: str, scale: float = 4, dtype=torch.bfloat16, device='cuda'):
    """å‡†å¤‡è¾“å…¥å¼ é‡ï¼Œä½¿ç”¨ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯"""
    # ä½¿ç”¨ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯è·å–
    if is_video(path):
        video_info = get_video_info_accurate(path)
        original_frame_count = video_info['frame_count']
        original_fps = video_info['frame_rate']
        original_duration = video_info['duration']
        w0 = video_info['width']
        h0 = video_info['height']
        
        is_video_input = True
        
        log_message(f"ç²¾ç¡®è§†é¢‘ä¿¡æ¯: {original_frame_count}å¸§, {original_fps:.6f}fps, {original_duration:.6f}ç§’, {w0}x{h0}")
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        calculated_frames = int(round(original_duration * original_fps))
        if abs(calculated_frames - original_frame_count) > 1:
            log_message(f"è­¦å‘Š: å¸§æ•°ä¸ä¸€è‡´ï¼Œä½¿ç”¨ç»Ÿè®¡å€¼ {original_frame_count} è€Œéè®¡ç®—å€¼ {calculated_frames}")
        
    else:
        # å›¾åƒåºåˆ—å¤„ç†ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        paths0 = list_images_natural(path)
        if not paths0:
            raise FileNotFoundError(f"No images in {path}")

        with Image.open(paths0[0]) as _img0:
            w0, h0 = _img0.size
            original_frame_count = len(paths0)
            original_fps = 30.0
            original_duration = original_frame_count / original_fps

        is_video_input = False
        log_message(f"å›¾åƒåºåˆ—: {original_frame_count}å¸§, {original_fps}fps, {original_duration:.2f}ç§’, {w0}x{h0}")

    # è®¡ç®—ç›®æ ‡å°ºå¯¸
    sW, sH, tW, tH = compute_scaled_and_target_dims(w0, h0, scale=scale, multiple=128)
    log_message(f"ç¼©æ”¾ç›®æ ‡: {w0}x{h0} -> {sW}x{sH} -> {tW}x{tH} (x{scale:.2f})")

    # å¸§å¤„ç†é€»è¾‘
    if is_video(path):
        # è§†é¢‘æ–‡ä»¶å¤„ç†
        rdr = imageio.get_reader(path)
        
        # ä½¿ç”¨ç²¾ç¡®çš„å¸§æ•°
        total = original_frame_count
        
        idx = list(range(total)) + [total-1]*4
        F = largest_8n1_leq(len(idx))
        if F == 0:
            rdr.close()
            raise RuntimeError(f"å¸§æ•°ä¸è¶³: {path}, å¾—åˆ° {len(idx)} å¸§")
        
        idx = idx[:F]
        processed_frame_count = F - 4  # å®é™…å¤„ç†çš„å¸§æ•°ï¼ˆå‡å»å¡«å……ï¼‰
        
        log_message(f"å¸§å¤„ç†: åŸå§‹{total}å¸§ -> å¡«å……å{F}å¸§ -> å®é™…å¤„ç†{processed_frame_count}å¸§")

        frames = []
        try:
            for i in idx:
                img = Image.fromarray(rdr.get_data(i)).convert('RGB')
                img_out = upscale_then_center_crop(img, scale=scale, tW=tW, tH=tH)
                frames.append(pil_to_tensor_neg1_1(img_out, dtype, 'cpu'))
        finally:
            try: 
                rdr.close()
            except Exception: 
                pass

        vid = torch.stack(frames, 0).permute(1,0,2,3).unsqueeze(0)
        fps = original_fps
        
    else:
        # å›¾åƒåºåˆ—å¤„ç†
        paths0 = list_images_natural(path)
        paths = paths0 + [paths0[-1]] * 4
        F = largest_8n1_leq(len(paths))
        if F == 0:
            raise RuntimeError(f"å¸§æ•°ä¸è¶³: {path}, å¾—åˆ° {len(paths)} å¸§")
        
        paths = paths[:F]
        processed_frame_count = F - 4
        
        log_message(f"å¸§å¤„ç†: åŸå§‹{len(paths0)}å¸§ -> å¡«å……å{F}å¸§ -> å®é™…å¤„ç†{processed_frame_count}å¸§")

        frames = []
        for p in paths:
            with Image.open(p).convert('RGB') as img:
                img_out = upscale_then_center_crop(img, scale=scale, tW=tW, tH=tH)
                frames.append(pil_to_tensor_neg1_1(img_out, dtype, 'cpu'))
        
        vid = torch.stack(frames, 0).permute(1,0,2,3).unsqueeze(0)
        fps = original_fps

    return (vid, tH, tW, F, fps, is_video_input, original_fps, original_duration, original_frame_count, processed_frame_count)

def init_pipeline(gpu_id=0):
    # é¦–å…ˆæ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        raise RuntimeError("CUDAä¸å¯ç”¨")
    
    # æ£€æŸ¥GPUæ•°é‡
    gpu_count = torch.cuda.device_count()
    log_message(f"ç³»ç»Ÿæ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    for i in range(gpu_count):
        log_message(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    
    # æ£€æŸ¥è¯·æ±‚çš„GPUæ˜¯å¦å­˜åœ¨
    if gpu_id >= gpu_count:
        raise RuntimeError(f"GPU {gpu_id} ä¸å­˜åœ¨ï¼Œå¯ç”¨GPU: 0-{gpu_count-1}")
    
    # è®¾ç½®å½“å‰è®¾å¤‡
    device = f'cuda:{gpu_id}'
    torch.cuda.set_device(gpu_id)
    
    log_message(f"æ­£åœ¨ä½¿ç”¨GPU: {gpu_id} ({torch.cuda.get_device_name(gpu_id)})")
    log_message(f"GPUå†…å­˜: {torch.cuda.get_device_properties(gpu_id).total_memory / 1024**3:.1f} GB")
    
    # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
    mm = ModelManager(torch_dtype=torch.bfloat16, device="cpu")
    mm.load_models([
        "./FlashVSR-v1.1/diffusion_pytorch_model_streaming_dmd.safetensors",
    ])
    
    # åˆ›å»ºç®¡é“
    pipe = FlashVSRTinyLongPipeline.from_model_manager(mm, device=device)
    
    # åŠ è½½LQæŠ•å½±å™¨
    pipe.denoising_model().LQ_proj_in = Causal_LQ4x_Proj(in_dim=3, out_dim=1536, layer_num=1).to(device, dtype=torch.bfloat16)
    LQ_proj_in_path = "./FlashVSR-v1.1/LQ_proj_in.ckpt"
    if os.path.exists(LQ_proj_in_path):
        pipe.denoising_model().LQ_proj_in.load_state_dict(torch.load(LQ_proj_in_path, map_location="cpu"), strict=True)
        pipe.denoising_model().LQ_proj_in.to(device)

    # åŠ è½½TCè§£ç å™¨
    multi_scale_channels = [512, 256, 128, 128]
    pipe.TCDecoder = build_tcdecoder(new_channels=multi_scale_channels, new_latent_channels=16+768)
    mis = pipe.TCDecoder.load_state_dict(torch.load("./FlashVSR-v1.1/TCDecoder.ckpt"), strict=False)
    log_message(f"TCè§£ç å™¨åŠ è½½çŠ¶æ€: {mis}")

    # å°†ç®¡é“ç§»åŠ¨åˆ°GPU
    pipe.to(device)
    pipe.enable_vram_management(num_persistent_param_in_dit=None)
    pipe.init_cross_kv()
    pipe.load_models_to_device(["dit","vae"])
    
    return pipe, device

def process_video_finalization(args):
    """å¤„ç†è§†é¢‘æœ€ç»ˆåŒ–ä»»åŠ¡ - ç›´æ¥æ–¹æ³•ç‰ˆ"""
    task_id, parallel_tasks, temp_dir, video_tensor, temp_video_path, final_video_path, original_fps, original_frame_count, original_duration, is_video_file, input_path, _ = args
    
    try:
        log_message(f"å¼€å§‹åˆ›å»ºçº¯è§†é¢‘æ–‡ä»¶: {os.path.basename(final_video_path)}", task_id, parallel_tasks)
        log_message(f"  ä½¿ç”¨å¸§ç‡: {original_fps:.6f} FPS, å¤„ç†å¸§æ•°: {video_tensor.shape[2]}", task_id, parallel_tasks)
        
        # ç›´æ¥æ–¹æ³•ï¼šä»å¼ é‡ç›´æ¥åˆ›å»ºè§†é¢‘
        log_message("ä½¿ç”¨ç›´æ¥æ–¹æ³•ï¼šä»å¼ é‡ç›´æ¥åˆ›å»ºè§†é¢‘ï¼ˆè·³è¿‡PNGä¸­è½¬ï¼‰", task_id, parallel_tasks)
        
        # åˆ›å»ºè§†é¢‘ç›®å½•
        os.makedirs(os.path.dirname(temp_video_path), exist_ok=True)
        
        # ä»å¼ é‡ç›´æ¥åˆ›å»ºè§†é¢‘
        save_video_directly_from_tensor(video_tensor, temp_video_path, fps=original_fps, quality=5)
        
        log_message(f"è§†é¢‘åˆ›å»ºå®Œæˆ: {os.path.basename(final_video_path)}", task_id, parallel_tasks)
        
        # å¤åˆ¶ä¸´æ—¶è§†é¢‘åˆ°æœ€ç»ˆè·¯å¾„
        shutil.copy(temp_video_path, final_video_path)
        log_message(f"å®Œæˆçº¯è§†é¢‘è¾“å‡º: {os.path.basename(final_video_path)}", task_id, parallel_tasks)
        
        # éªŒè¯æœ€ç»ˆæ–‡ä»¶å‚æ•°
        try:
            final_info = get_video_info_accurate(final_video_path)
            log_message(f"æœ€ç»ˆè§†é¢‘å‚æ•°:", task_id, parallel_tasks)
            log_message(f"  å¸§æ•°: {final_info['frame_count']} (åŸå§‹: {original_frame_count})", task_id, parallel_tasks)
            log_message(f"  å¸§ç‡: {final_info['frame_rate']:.6f} (åŸå§‹: {original_fps:.6f})", task_id, parallel_tasks)
            log_message(f"  æ—¶é•¿: {final_info['duration']:.6f}ç§’", task_id, parallel_tasks)
            
            # æ£€æŸ¥å‚æ•°ä¸€è‡´æ€§
            fps_match = abs(final_info['frame_rate'] - original_fps) < 0.01
            
            if fps_match:
                log_message("å¸§ç‡ä¸€è‡´æ€§: âœ… åŒ¹é…", task_id, parallel_tasks)
            else:
                log_message(f"å¸§ç‡å·®å¼‚: {final_info['frame_rate']:.6f} vs {original_fps:.6f}", task_id, parallel_tasks)
        except Exception as e:
            log_message(f"æ— æ³•éªŒè¯æœ€ç»ˆæ–‡ä»¶å‚æ•°: {e}", task_id, parallel_tasks)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if os.path.exists(temp_video_path):
                os.remove(temp_video_path)
        except:
            pass
            
        return True, final_video_path
        
    except Exception as e:
        log_message(f"è§†é¢‘æœ€ç»ˆåŒ–å¤±è´¥ {os.path.basename(final_video_path)}: {e}", task_id, parallel_tasks)
        return False, final_video_path

def main():
    parser = argparse.ArgumentParser(description='FlashVSRè§†é¢‘è¶…åˆ†è¾¨ç‡å¤„ç†')
    parser.add_argument('--input', type=str, required=True, help='è¾“å…¥æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--output', type=str, default='./results', help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--preprocess', action='store_true', help='å·²ç§»é™¤ï¼šå‚æ•°ä¿ç•™ä½†æ— æ•ˆ')
    parser.add_argument('--gpu', type=int, default=0, help='GPUè®¾å¤‡ID (0, 1, 2, 3)')
    parser.add_argument('--seed', type=int, default=0, help='éšæœºç§å­')
    parser.add_argument('--scale', type=float, default=4.0, help='ç¼©æ”¾æ¯”ä¾‹')
    parser.add_argument('--sparse_ratio', type=float, default=2.0, help='ç¨€ç–æ¯”ç‡')
    parser.add_argument('--local_range', type=int, default=11, help='å±€éƒ¨èŒƒå›´')
    parser.add_argument('--max_workers', type=int, default=2, help='å¹¶è¡Œå¤„ç†çš„æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°')
    
    args = parser.parse_args()
    
    log_message("=== FlashVSR GPUè®¾ç½® ===")
    log_message(f"è¯·æ±‚ä½¿ç”¨GPU: {args.gpu}")
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if not torch.cuda.is_available():
        log_message("é”™è¯¯: CUDAä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥CUDAå®‰è£…")
        return
    
    gpu_count = torch.cuda.device_count()
    log_message(f"ç³»ç»Ÿæ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    if args.gpu >= gpu_count:
        log_message(f"é”™è¯¯: GPU {args.gpu} ä¸å­˜åœ¨ï¼Œå¯ç”¨GPU: 0-{gpu_count-1}")
        return
    
    # æç¤ºé¢„å¤„ç†å‚æ•°å·²ç§»é™¤
    if args.preprocess:
        log_message("æ³¨æ„: --preprocess å‚æ•°åŠŸèƒ½å·²ç§»é™¤ï¼Œå°†è·³è¿‡è§†é¢‘é¢„å¤„ç†")
    
    RESULT_ROOT = args.output
    os.makedirs(RESULT_ROOT, exist_ok=True)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•åœ¨è¾“å‡ºç›®å½•ä¸‹
    TEMP_ROOT = os.path.join(RESULT_ROOT, "temp")
    os.makedirs(TEMP_ROOT, exist_ok=True)
    log_message(f"ä¸´æ—¶æ–‡ä»¶ç›®å½•: {TEMP_ROOT}")
    
    # è·å–è¾“å…¥æ–‡ä»¶åˆ—è¡¨
    try:
        input_files = get_input_files(args.input)
    except Exception as e:
        log_message(f"è¾“å…¥æ–‡ä»¶é”™è¯¯: {e}")
        return
    
    if not input_files:
        log_message(f"åœ¨è·¯å¾„ {args.input} ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„è§†é¢‘æ–‡ä»¶æˆ–å›¾åƒåºåˆ—")
        return
    
    log_message(f"æ‰¾åˆ° {len(input_files)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")
    
    try:
        # åˆå§‹åŒ–ç®¡é“
        pipe, device = init_pipeline(args.gpu)
    except Exception as e:
        log_message(f"ç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºçº¿ç¨‹æ± ç”¨äºå¹¶è¡Œå¤„ç†
    executor = ThreadPoolExecutor(max_workers=args.max_workers)
    futures = []
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for i, input_path in enumerate(input_files, 1):
        log_message(f"=== å¤„ç†æ–‡ä»¶ {i}/{len(input_files)} ===")
        log_message(f"è¾“å…¥: {input_path}")
        
        # æ›´æ–°å…¨å±€æ—¥å¿—ä¸Šä¸‹æ–‡
        log_context["current_task"] = i
        log_context["parallel_tasks"] = len(futures) + 1
        
        # æ¸…ç†GPUå†…å­˜
        torch.cuda.empty_cache()
        
        name = os.path.basename(input_path.rstrip('/'))
        if name.startswith('.'):
            continue
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶
        is_video_file = is_video(input_path)
        
        # æ³¨æ„ï¼šFFmpegé¢„å¤„ç†åŠŸèƒ½å·²ç§»é™¤
        
        # ä½¿ç”¨ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯è·å–
        try:
            LQ, th, tw, F, fps, from_video, original_fps, original_duration, original_frame_count, processed_frame_count = prepare_input_tensor(
                input_path, scale=args.scale, dtype=torch.bfloat16, device=device)
        except Exception as e:
            log_message(f"[é”™è¯¯] å‡†å¤‡è¾“å…¥å¼ é‡å¤±è´¥: {e}", i, len(futures)+1)
            continue

        # å¯¹äºè§†é¢‘æ–‡ä»¶ï¼Œæ˜¾ç¤ºä¿¡æ¯
        if is_video_file:
            log_message(f"è§†é¢‘æ–‡ä»¶ä¿¡æ¯: {original_frame_count}å¸§, {original_fps:.6f}fps, {original_duration:.6f}ç§’", i, len(futures)+1)
            log_message(f"å¤„ç†åå¸§æ•°: {processed_frame_count}å¸§", i, len(futures)+1)

        try:
            log_message("å¼€å§‹FlashVSRå¤„ç†...", i, len(futures)+1)
            video = pipe(
                prompt="", 
                negative_prompt="", 
                cfg_scale=1.0, 
                num_inference_steps=1, 
                seed=args.seed,
                LQ_video=LQ, 
                num_frames=F, 
                height=th, 
                width=tw, 
                is_full_block=False, 
                if_buffer=True,
                topk_ratio=args.sparse_ratio*768 * 1280/(th*tw), 
                kv_ratio=3.0,
                local_range=args.local_range,
                color_fix=True,
            )

            # è®¡ç®—å¤„ç†åçš„å®é™…å¸§æ•°ï¼ˆå‡å»å¡«å……çš„å¸§ï¼‰
            processed_frame_count = F - 4
            
            # æ€»æ˜¯ä½¿ç”¨ç›´æ¥æ–¹æ³•åˆ›å»ºè§†é¢‘
            log_message("ä½¿ç”¨ç›´æ¥æ–¹æ³•ï¼šä»å¼ é‡ç›´æ¥åˆ›å»ºè§†é¢‘ï¼ˆè·³è¿‡PNGä¸­è½¬ï¼‰", i, len(futures)+1)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            if os.path.isdir(input_path):
                base_name = os.path.basename(input_path.rstrip('/'))
            else:
                base_name = os.path.splitext(os.path.basename(input_path))[0]
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = tempfile.mkdtemp(dir=TEMP_ROOT, prefix=f"temp_{base_name}_")
            log_message(f"ä¸´æ—¶ç›®å½•: {temp_dir}", i, len(futures)+1)
            
            # å‡†å¤‡æœ€ç»ˆè§†é¢‘è·¯å¾„
            temp_video_path = os.path.join(temp_dir, "temp_video.mp4")
            final_video_filename = f"FlashVSR_v1.1_Tiny_Long_{base_name}_gpu{args.gpu}_seed{args.seed}.mp4"
            final_video_path = os.path.join(RESULT_ROOT, final_video_filename)
            
            # æäº¤å¹¶è¡Œå¤„ç†ä»»åŠ¡
            log_message(f"æäº¤å¹¶è¡Œå¤„ç†ä»»åŠ¡: {os.path.basename(final_video_path)}", i, len(futures)+1)
            future = executor.submit(process_video_finalization, (
                i, len(futures)+1, temp_dir, video, temp_video_path, final_video_path, 
                original_fps, original_frame_count, original_duration, is_video_file, input_path, True
            ))
            futures.append((future, final_video_path, temp_dir, i))
            
            log_message(f"å½“å‰å¹¶è¡Œä»»åŠ¡æ•°: {len(futures)}", i, len(futures)+1)
            
            # å¦‚æœå¹¶è¡Œä»»åŠ¡è¾¾åˆ°ä¸Šé™ï¼Œç­‰å¾…éƒ¨åˆ†ä»»åŠ¡å®Œæˆ
            if len(futures) >= args.max_workers * 2:
                log_message("è¾¾åˆ°å¹¶è¡Œä»»åŠ¡ä¸Šé™ï¼Œç­‰å¾…éƒ¨åˆ†ä»»åŠ¡å®Œæˆ...", i, len(futures)+1)
                completed_count = 0
                for f, path, temp_dir, task_id in futures[:]:
                    if f.done():
                        try:
                            success, result_path = f.result(timeout=1)
                            if success:
                                log_message(f"å¹¶è¡Œä»»åŠ¡å®Œæˆ: {os.path.basename(result_path)}", task_id, len(futures))
                            else:
                                log_message(f"å¹¶è¡Œä»»åŠ¡å¤±è´¥: {os.path.basename(result_path)}", task_id, len(futures))
                            # æ¸…ç†ä¸´æ—¶ç›®å½•
                            try:
                                shutil.rmtree(temp_dir)
                                log_message(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {os.path.basename(temp_dir)}", task_id, len(futures))
                            except:
                                pass
                            futures.remove((f, path, temp_dir, task_id))
                            completed_count += 1
                        except:
                            pass
                
                if completed_count > 0:
                    log_message(f"å·²å®Œæˆ {completed_count} ä¸ªä»»åŠ¡ï¼Œç»§ç»­å¤„ç†...", i, len(futures)+1)
            
        except Exception as e:
            log_message(f"[å¤„ç†é”™è¯¯] {name}: {e}", i, len(futures)+1)
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(temp_dir)
                log_message(f"æ¸…ç†ä¸´æ—¶ç›®å½•ï¼ˆé”™è¯¯æ—¶ï¼‰: {os.path.basename(temp_dir)}", i, len(futures)+1)
            except:
                pass
            continue

    log_message(f"ç­‰å¾…æ‰€æœ‰å¹¶è¡Œä»»åŠ¡å®Œæˆ...")
    
    # ç­‰å¾…æ‰€æœ‰å‰©ä½™ä»»åŠ¡å®Œæˆ
    completed_count = 0
    failed_count = 0
    
    for future, final_video_path, temp_dir, task_id in futures:
        try:
            success, result_path = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
            if success:
                log_message(f"ä»»åŠ¡å®Œæˆ: {os.path.basename(result_path)}", task_id, len(futures))
                completed_count += 1
            else:
                log_message(f"ä»»åŠ¡å¤±è´¥: {os.path.basename(result_path)}", task_id, len(futures))
                failed_count += 1
        except Exception as e:
            log_message(f"ä»»åŠ¡è¶…æ—¶æˆ–å¤±è´¥ {os.path.basename(final_video_path)}: {e}", task_id, len(futures))
            failed_count += 1
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(temp_dir)
                log_message(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {os.path.basename(temp_dir)}", task_id, len(futures))
            except:
                pass
    
    # å…³é—­çº¿ç¨‹æ± 
    executor.shutdown(wait=True)
    
    # å°è¯•æ¸…ç†æ•´ä¸ªä¸´æ—¶ç›®å½•ï¼ˆå¦‚æœä¸ºç©ºï¼‰
    try:
        if os.path.exists(TEMP_ROOT) and not os.listdir(TEMP_ROOT):
            shutil.rmtree(TEMP_ROOT)
            log_message(f"æ¸…ç†ä¸´æ—¶æ ¹ç›®å½•: {TEMP_ROOT}")
    except:
        pass
    
    log_message(f"\n=== æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ ===")
    log_message(f"âœ… æˆåŠŸ: {completed_count} ä¸ªæ–‡ä»¶")
    log_message(f"âŒ å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶")
    log_message(f"ğŸ“ è¾“å‡ºç›®å½•: {RESULT_ROOT}")
    log_message(f"ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
    log_message("ğŸ¯ è¾“å‡ºæ–‡ä»¶ä¸ºçº¯è§†é¢‘æµï¼ˆæ— éŸ³é¢‘ï¼‰")

if __name__ == "__main__":
    main()
