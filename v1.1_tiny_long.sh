#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, re, time, argparse
import numpy as np
from PIL import Image
import imageio
from tqdm import tqdm
import torch
from einops import rearrange
import subprocess
import tempfile
import shutil
import json
import threading
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ  pymediainfo å¯¼å…¥
try:
    from pymediainfo import MediaInfo
    PYMEDIAINFO_AVAILABLE = True
except ImportError:
    print("è­¦å‘Š: æœªå®‰è£… pymediainfoï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
    PYMEDIAINFO_AVAILABLE = False

from diffsynth import ModelManager, FlashVSRTinyLongPipeline
from utils.utils import Causal_LQ4x_Proj
from utils.TCDecoder import build_tcdecoder

def get_video_info_accurate(path):
    """ä½¿ç”¨ pymediainfo è·å–ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯"""
    if not PYMEDIAINFO_AVAILABLE:
        return get_video_info_fallback(path)
    
    try:
        media_info = MediaInfo.parse(path)
        video_track = None
        general_track = None
        
        for track in media_info.tracks:
            if track.track_type == 'Video':
                video_track = track
            elif track.track_type == 'General':
                general_track = track
        
        if not video_track:
            raise ValueError("æœªæ‰¾åˆ°è§†é¢‘æµ")
        
        # è·å–ç²¾ç¡®çš„å¸§ç‡
        frame_rate = None
        if hasattr(video_track, 'frame_rate') and video_track.frame_rate:
            frame_rate_str = str(video_track.frame_rate)
            # å¤„ç†åˆ†æ•°å½¢å¼çš„å¸§ç‡ (å¦‚ 30000/1001)
            if '/' in frame_rate_str:
                try:
                    numerator, denominator = map(float, frame_rate_str.split('/'))
                    frame_rate = numerator / denominator
                except:
                    frame_rate = float(frame_rate_str)
            else:
                frame_rate = float(frame_rate_str)
        
        # è·å–æ€»å¸§æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ç²¾ç¡®ç»Ÿè®¡ï¼‰
        frame_count = None
        if hasattr(video_track, 'frame_count') and video_track.frame_count:
            frame_count = int(video_track.frame_count)
        
        # è·å–æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰- ä¼˜å…ˆä½¿ç”¨è§†é¢‘æµæ—¶é•¿
        duration_ms = None
        if hasattr(video_track, 'duration') and video_track.duration:
            duration_ms = float(video_track.duration)
            print(f"âœ… ä½¿ç”¨è§†é¢‘æµæ—¶é•¿: {duration_ms}ms")
        elif hasattr(general_track, 'duration') and general_track.duration:
            duration_ms = float(general_track.duration)
            print(f"âš ï¸ ä½¿ç”¨å®¹å™¨æ—¶é•¿: {duration_ms}ms")
        
        # è®¡ç®—æ—¶é•¿ï¼ˆç§’ï¼‰
        duration_seconds = duration_ms / 1000.0 if duration_ms else None
        
        # å¦‚æœå¸§æ•°æœªçŸ¥ä½†æ—¶é•¿å’Œå¸§ç‡å·²çŸ¥ï¼Œè®¡ç®—å¸§æ•°
        if frame_count is None and duration_seconds and frame_rate:
            frame_count = int(round(duration_seconds * frame_rate))
        
        # å¦‚æœæ—¶é•¿æœªçŸ¥ä½†å¸§æ•°å’Œå¸§ç‡å·²çŸ¥ï¼Œè®¡ç®—æ—¶é•¿
        if duration_seconds is None and frame_count and frame_rate:
            duration_seconds = frame_count / frame_rate
        
        # é»˜è®¤å€¼
        if frame_rate is None:
            frame_rate = 25.0
        if frame_count is None:
            # ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            return get_video_info_fallback(path)
        if duration_seconds is None:
            duration_seconds = frame_count / frame_rate
        
        # è·å–åˆ†è¾¨ç‡
        width = int(video_track.width) if hasattr(video_track, 'width') else 0
        height = int(video_track.height) if hasattr(video_track, 'height') else 0
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        calculated_frames = int(round(duration_seconds * frame_rate))
        if abs(calculated_frames - frame_count) > 2:  # å…è®¸2å¸§è¯¯å·®
            print(f"âš ï¸ å¸§æ•°ä¸ä¸€è‡´: ç»Ÿè®¡={frame_count}, è®¡ç®—={calculated_frames}, ä½¿ç”¨ç»Ÿè®¡å€¼")
        
        print(f"ğŸ“ŠğŸ“Š pymediainfo ç²¾ç¡®ä¿¡æ¯: {frame_count}å¸§, {frame_rate:.6f}fps, {duration_seconds:.6f}ç§’")
        
        return {
            'frame_count': frame_count,
            'frame_rate': frame_rate,
            'duration': duration_seconds,
            'width': width,
            'height': height,
            'is_accurate': True
        }
        
    except Exception as e:
        print(f"âŒâŒ pymediainfo è§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
        return get_video_info_fallback(path)

def get_video_info_fallback(path):
    """å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨ ffprobe è·å–è§†é¢‘ä¿¡æ¯"""
    try:
        # ä½¿ç”¨ ffprobe è·å–ç²¾ç¡®å¸§æ•°
        frame_count_cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'v:0',
            '-count_frames',
            '-show_entries', 'stream=nb_read_frames',
            '-of', 'csv=p=0',
            path
        ]
        
        result = subprocess.run(frame_count_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            frame_count = int(result.stdout.strip())
        else:
            frame_count = 0
        
        # è·å–æ—¶é•¿å’Œå¸§ç‡
        info_cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'v:0',
            '-show_entries', 'stream=r_frame_rate,duration,width,height',
            '-of', 'json',
            path
        ]
        
        result = subprocess.run(info_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            info = json.loads(result.stdout)
            stream = info['streams'][0] if info['streams'] else {}
            
            # è§£æå¸§ç‡
            frame_rate_str = stream.get('r_frame_rate', '25/1')
            if '/' in frame_rate_str:
                num, den = map(int, frame_rate_str.split('/'))
                frame_rate = num / den
            else:
                frame_rate = float(frame_rate_str)
            
            # è·å–æ—¶é•¿
            duration = float(stream.get('duration', 0))
            
            # å¦‚æœæ—¶é•¿æœªçŸ¥ï¼Œä½¿ç”¨å¸§æ•°å’Œå¸§ç‡è®¡ç®—
            if duration <= 0 and frame_count > 0:
                duration = frame_count / frame_rate
            
            # å¦‚æœå¸§æ•°æœªçŸ¥ï¼Œä½¿ç”¨æ—¶é•·å’Œå¸§ç‡è®¡ç®—
            if frame_count <= 0 and duration > 0:
                frame_count = int(round(duration * frame_rate))
            
            width = int(stream.get('width', 0))
            height = int(stream.get('height', 0))
            
            print(f"ğŸ“ŠğŸ“Š ffprobe ä¿¡æ¯: {frame_count}å¸§, {frame_rate:.6f}fps, {duration:.6f}ç§’")
            
            return {
                'frame_count': frame_count,
                'frame_rate': frame_rate,
                'duration': duration,
                'width': width,
                'height': height,
                'is_accurate': False
            }
    
    except Exception as e:
        print(f"âŒâŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
    
    # æœ€ç»ˆå¤‡ç”¨å€¼
    return {
        'frame_count': 250,  # é»˜è®¤å€¼
        'frame_rate': 25.0,
        'duration': 10.0,
        'width': 720,
        'height': 540,
        'is_accurate': False
    }

def tensor2video(frames):
    frames = rearrange(frames, "C T H W -> T H W C")
    frames = ((frames.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)
    frames = [Image.fromarray(frame) for frame in frames]
    return frames

def natural_key(name: str):
    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'([0-9]+)', os.path.basename(name))]

def list_images_natural(folder: str):
    exts = ('.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG')
    fs = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(exts)]
    fs.sort(key=natural_key)
    return fs

def list_videos_natural(folder: str):
    exts = ('.mp4', '.mov', '.avi', '.mkv', '.MP4', '.MOV', '.AVI', '.MKV')
    fs = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(exts)]
    fs.sort(key=natural_key)
    return fs

def get_input_files(input_path):
    input_files = []
    
    if os.path.isfile(input_path):
        input_files.append(input_path)
    elif os.path.isdir(input_path):
        video_files = list_videos_natural(input_path)
        input_files.extend(video_files)
        
        for item in os.listdir(input_path):
            item_path = os.path.join(input_path, item)
            if os.path.isdir(item_path):
                image_files = list_images_natural(item_path)
                if image_files:
                    input_files.append(item_path)
    else:
        raise ValueError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    return input_files

def largest_8n1_leq(n):
    return 0 if n < 1 else ((n - 1)//8)*8 + 1

def is_video(path):
    return os.path.isfile(path) and path.lower().endswith(('.mp4','.mov','.avi','.mkv'))

def pil_to_tensor_neg1_1(img: Image.Image, dtype=torch.bfloat16, device='cuda'):
    t = torch.from_numpy(np.asarray(img, np.uint8)).to(device=device, dtype=torch.float32)
    t = t.permute(2,0,1) / 255.0 * 2.0 - 1.0
    return t.to(dtype)

def save_frames_as_png(frames, output_dir, base_name="frame"):
    """ä¿å­˜å¸§åºåˆ—ä¸ºPNGå›¾ç‰‡"""
    os.makedirs(output_dir, exist_ok=True)
    saved_paths = []
    
    for i, frame in enumerate(tqdm(frames, desc=f"Saving PNG frames")):
        filename = f"{base_name}_{i:06d}.png"
        filepath = os.path.join(output_dir, filename)
        frame.save(filepath, 'PNG')
        saved_paths.append(filepath)
    
    return saved_paths

def save_video_from_frames(frame_paths, save_path, fps=30, quality=5):
    """ä»å¸§è·¯å¾„åˆ—è¡¨åˆ›å»ºè§†é¢‘"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    w = imageio.get_writer(save_path, fps=fps, quality=quality)
    
    for frame_path in tqdm(frame_paths, desc=f"Creating video {os.path.basename(save_path)}"):
        frame = Image.open(frame_path)
        w.append_data(np.array(frame))
    w.close()

def save_video_directly_from_tensor(frames, save_path, fps=30, quality=5):
    """ç›´æ¥ä»å¼ é‡åˆ›å»ºè§†é¢‘ï¼Œè·³è¿‡PNGä¸­é—´æ­¥éª¤"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    w = imageio.get_writer(save_path, fps=fps, quality=quality)
    
    # å°†å¼ é‡è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶ä¿å­˜
    frames_array = ((frames.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)
    frames_array = rearrange(frames_array, "C T H W -> T H W C")
    
    for i in tqdm(range(frames_array.shape[0]), desc=f"Creating video directly {os.path.basename(save_path)}"):
        frame = frames_array[i]
        w.append_data(frame)
    w.close()

def pad_frames_to_match_original_uniform(processed_frames_dir, original_frame_count, output_dir):
    """
    æ”¹è¿›çš„å¸§å¡«è¡¥æ–¹æ³•ï¼šå°†ç¼ºå¤±å¸§å‡åŒ€æ’å…¥åˆ°è§†é¢‘åºåˆ—ä¸­
    æ–¹æ¡ˆï¼šæ¯é—´éš”Nå¸§æ’å…¥ä¸€å¸§ï¼Œç¡®ä¿æœ€ç»ˆå¸§æ•°ç­‰äºåŸå§‹å¸§æ•°
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–å¤„ç†åçš„å¸§
    processed_frames = [f for f in os.listdir(processed_frames_dir) if f.endswith('.png')]
    processed_frames.sort()
    processed_count = len(processed_frames)
    
    frames_needed = original_frame_count - processed_count
    print(f"ğŸ“ŠğŸ“Š å‡åŒ€å¡«è¡¥: å¤„ç†{processed_count}å¸§, éœ€è¦{original_frame_count}å¸§, éœ€å¡«è¡¥{frames_needed}å¸§")
    
    if frames_needed <= 0:
        # å¦‚æœå¤„ç†åçš„å¸§æ•°å¤šäºæˆ–ç­‰äºåŸå§‹å¸§æ•°ï¼Œç›´æ¥å¤åˆ¶å‰Nå¸§
        for i in range(original_frame_count):
            src_path = os.path.join(processed_frames_dir, processed_frames[i])
            dst_path = os.path.join(output_dir, f"frame_{i:06d}.png")
            shutil.copy2(src_path, dst_path)
        final_count_actual = original_frame_count
    else:
        # === æ ¸å¿ƒæ”¹è¿›ï¼šè®¡ç®—å‡åŒ€æ’å…¥çš„é—´éš” ===
        # è®¡ç®—ç†è®ºæ’å…¥é—´éš”ï¼ˆå‘ä¸‹å–æ•´ï¼‰
        interval = max(1, processed_count // (frames_needed + 1))
        print(f"ğŸ¯ å‡åŒ€å¡«è¡¥: æ¯ {interval} å¸§åæ’å…¥1å¸§ï¼Œå…±éœ€æ’å…¥ {frames_needed} å¸§")
        
        # æ„å»ºæ–°çš„å¸§åºåˆ—
        new_frame_list = []
        processed_idx = 0
        insertions_made = 0
        
        # éå†æ‰€æœ‰å¤„ç†åçš„å¸§
        for i in range(processed_count):
            # æ·»åŠ å½“å‰å¤„ç†å¸§
            src_path = os.path.join(processed_frames_dir, processed_frames[i])
            dst_filename = f"frame_{len(new_frame_list):06d}.png"
            dst_path = os.path.join(output_dir, dst_filename)
            shutil.copy2(src_path, dst_path)
            new_frame_list.append(dst_path)
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦åœ¨æ­¤å¤„æ’å…¥ä¸€å¸§ï¼ˆåœ¨ç‰¹å®šé—´éš”åæ’å…¥ï¼Œä¸”ä¸æ˜¯æœ€åä¸€å¸§ï¼‰
            # æ¡ä»¶ï¼š(i+1)èƒ½è¢«é—´éš”æ•´é™¤ï¼Œè¿˜æœ‰å‰©ä½™å¸§éœ€è¦æ’å…¥ï¼Œä¸”ä¸æ˜¯å¤„ç†åºåˆ—çš„æœ€åä¸€å¸§
            if ((i + 1) % interval == 0 and 
                insertions_made < frames_needed and 
                i < processed_count - 1):
                
                # é€‰æ‹©è¦æ’å…¥çš„å¸§ï¼šä½¿ç”¨å½“å‰å¸§æˆ–å‰ä¸€ä¸ªå¸§ï¼Œä»¥è¾¾åˆ°å¹³æ»‘è¿‡æ¸¡
                # è¿™é‡Œä½¿ç”¨å½“å‰å¸§è¿›è¡Œå¤åˆ¶ï¼ˆæ•ˆæœç±»ä¼¼äºçŸ­æš‚åœç•™ï¼‰
                insert_src_path = os.path.join(processed_frames_dir, processed_frames[i])
                insert_dst_filename = f"frame_{len(new_frame_list):06d}.png"
                insert_dst_path = os.path.join(output_dir, insert_dst_filename)
                shutil.copy2(insert_src_path, insert_dst_path)
                
                new_frame_list.append(insert_dst_path)
                insertions_made += 1
                print(f"  â†’ æ’å…¥ç¬¬ {insertions_made}/{frames_needed} å¸§ï¼Œä½ç½®åœ¨åŸå§‹å¸§ {i+1} ä¹‹å")
        
        # å¦‚æœè¿˜æœ‰æœªæ’å…¥çš„å¸§ï¼ˆé€šå¸¸å› ä¸ºæœ«å°¾ä¸è¶³ä¸€ä¸ªé—´éš”ï¼‰ï¼Œåœ¨æœ«å°¾è¡¥é½
        while insertions_made < frames_needed:
            # ä½¿ç”¨æœ€åä¸€å¸§è¿›è¡Œè¡¥é½
            src_path = os.path.join(processed_frames_dir, processed_frames[-1])
            dst_filename = f"frame_{len(new_frame_list):06d}.png"
            dst_path = os.path.join(output_dir, dst_filename)
            shutil.copy2(src_path, dst_path)
            
            new_frame_list.append(dst_path)
            insertions_made += 1
            print(f"  â†’ æœ«å°¾è¡¥é½ç¬¬ {insertions_made}/{frames_needed} å¸§")
        
        final_count_actual = len(new_frame_list)
    
    # éªŒè¯æœ€ç»ˆå¸§æ•°
    final_frames = [f for f in os.listdir(output_dir) if f.endswith('.png')]
    final_frames.sort()
    final_count_actual = len(final_frames)
    
    if final_count_actual != original_frame_count:
        print(f"âŒâŒ å¸§æ•°éªŒè¯å¤±è´¥: æœŸæœ›{original_frame_count}, å®é™…{final_count_actual}")
        # å¼ºåˆ¶è°ƒæ•´åˆ°æ­£ç¡®å¸§æ•°
        if final_count_actual < original_frame_count:
            # å¦‚æœè¿˜æ˜¯å°‘äº†ï¼Œç”¨æœ€åä¸€å¸§è¡¥é½
            last_frame_path = os.path.join(output_dir, f"frame_{final_count_actual-1:06d}.png")
            for i in range(final_count_actual, original_frame_count):
                dst_path = os.path.join(output_dir, f"frame_{i:06d}.png")
                shutil.copy2(last_frame_path, dst_path)
                final_frames.append(dst_path)
                print(f"  â†’ å¼ºåˆ¶è¡¥é½ç¬¬ {i-final_count_actual+1} å¸§")
            final_count_actual = original_frame_count
    else:
        print(f"âœ… å¸§æ•°éªŒè¯æˆåŠŸ: {final_count_actual}å¸§ï¼Œä½¿ç”¨å‡åŒ€å¡«è¡¥æ³•")
    
    return [os.path.join(output_dir, f) for f in final_frames]

def compute_scaled_and_target_dims(w0: int, h0: int, scale: float = 4.0, multiple: int = 128):
    if w0 <= 0 or h0 <= 0:
        raise ValueError("Invalid original size")
    if scale <= 0:
        raise ValueError("scale must be > 0")

    sW = int(round(w0 * scale))
    sH = int(round(h0 * scale))
    tW = (sW // multiple) * multiple
    tH = (sH // multiple) * multiple

    if tW == 0 or tH == 0:
        raise ValueError(
            f"Scaled size too small ({sW}x{sH}) for multiple={multiple}. "
            f"Increase scale (got {scale})."
        )
    return sW, sH, tW, tH

def upscale_then_center_crop(img: Image.Image, scale: float, tW: int, tH: int) -> Image.Image:
    w0, h0 = img.size
    sW = int(round(w0 * scale))
    sH = int(round(h0 * scale))

    if tW > sW or tH > sH:
        raise ValueError(
            f"Target crop ({tW}x{tH}) exceeds scaled size ({sW}x{sH}). "
            f"Increase scale."
        )

    up = img.resize((sW, sH), Image.BICUBIC)
    l = (sW - tW) // 2
    t = (sH - tH) // 2
    return up.crop((l, t, l + tW, t + tH))

def prepare_input_tensor(path: str, scale: float = 4, dtype=torch.bfloat16, device='cuda'):
    """å‡†å¤‡è¾“å…¥å¼ é‡ï¼Œä½¿ç”¨ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯"""
    # ä½¿ç”¨ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯è·å–
    if is_video(path):
        video_info = get_video_info_accurate(path)
        original_frame_count = video_info['frame_count']
        original_fps = video_info['frame_rate']
        original_duration = video_info['duration']
        w0 = video_info['width']
        h0 = video_info['height']
        
        is_video_input = True
        
        print(f"ğŸ¯ğŸ¯ ç²¾ç¡®è§†é¢‘ä¿¡æ¯: {original_frame_count}å¸§, {original_fps:.6f}fps, {original_duration:.6f}ç§’, {w0}x{h0}")
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        calculated_frames = int(round(original_duration * original_fps))
        if abs(calculated_frames - original_frame_count) > 1:
            print(f"âš ï¸ è­¦å‘Š: å¸§æ•°ä¸ä¸€è‡´ï¼Œä½¿ç”¨ç»Ÿè®¡å€¼ {original_frame_count} è€Œéè®¡ç®—å€¼ {calculated_frames}")
        
    else:
        # å›¾åƒåºåˆ—å¤„ç†ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        paths0 = list_images_natural(path)
        if not paths0:
            raise FileNotFoundError(f"No images in {path}")

        with Image.open(paths0[0]) as _img0:
            w0, h0 = _img0.size
            original_frame_count = len(paths0)
            original_fps = 30.0
            original_duration = original_frame_count / original_fps

        is_video_input = False
        print(f"ğŸ“ğŸ“ å›¾åƒåºåˆ—: {original_frame_count}å¸§, {original_fps}fps, {original_duration:.2f}ç§’, {w0}x{h0}")

    # è®¡ç®—ç›®æ ‡å°ºå¯¸
    sW, sH, tW, tH = compute_scaled_and_target_dims(w0, h0, scale=scale, multiple=128)
    print(f"ğŸ“ğŸ“ ç¼©æ”¾ç›®æ ‡: {w0}x{h0} -> {sW}x{sH} -> {tW}x{tH} (x{scale:.2f})")

    # å¸§å¤„ç†é€»è¾‘
    if is_video(path):
        # è§†é¢‘æ–‡ä»¶å¤„ç†
        rdr = imageio.get_reader(path)
        
        # ä½¿ç”¨ç²¾ç¡®çš„å¸§æ•°
        total = original_frame_count
        
        idx = list(range(total)) + [total-1]*4
        F = largest_8n1_leq(len(idx))
        if F == 0:
            rdr.close()
            raise RuntimeError(f"å¸§æ•°ä¸è¶³: {path}, å¾—åˆ° {len(idx)} å¸§")
        
        idx = idx[:F]
        processed_frame_count = F - 4  # å®é™…å¤„ç†çš„å¸§æ•°ï¼ˆå‡å»å¡«å……ï¼‰
        
        print(f"ğŸ”„ğŸ”„ å¸§å¤„ç†: åŸå§‹{total}å¸§ -> å¡«å……å{F}å¸§ -> å®é™…å¤„ç†{processed_frame_count}å¸§")

        frames = []
        try:
            for i in idx:
                img = Image.fromarray(rdr.get_data(i)).convert('RGB')
                img_out = upscale_then_center_crop(img, scale=scale, tW=tW, tH=tH)
                frames.append(pil_to_tensor_neg1_1(img_out, dtype, 'cpu'))
        finally:
            try: 
                rdr.close()
            except Exception: 
                pass

        vid = torch.stack(frames, 0).permute(1,0,2,3).unsqueeze(0)
        fps = original_fps
        
    else:
        # å›¾åƒåºåˆ—å¤„ç†
        paths0 = list_images_natural(path)
        paths = paths0 + [paths0[-1]] * 4
        F = largest_8n1_leq(len(paths))
        if F == 0:
            raise RuntimeError(f"å¸§æ•°ä¸è¶³: {path}, å¾—åˆ° {len(paths)} å¸§")
        
        paths = paths[:F]
        processed_frame_count = F - 4
        
        print(f"ğŸ”„ğŸ”„ å¸§å¤„ç†: åŸå§‹{len(paths0)}å¸§ -> å¡«å……å{F}å¸§ -> å®é™…å¤„ç†{processed_frame_count}å¸§")

        frames = []
        for p in paths:
            with Image.open(p).convert('RGB') as img:
                img_out = upscale_then_center_crop(img, scale=scale, tW=tW, tH=tH)
                frames.append(pil_to_tensor_neg1_1(img_out, dtype, 'cpu'))
        
        vid = torch.stack(frames, 0).permute(1,0,2,3).unsqueeze(0)
        fps = original_fps

    return (vid, tH, tW, F, fps, is_video_input, original_fps, original_duration, original_frame_count, processed_frame_count)

def init_pipeline(gpu_id=0):
    # é¦–å…ˆæ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        raise RuntimeError("CUDAä¸å¯ç”¨")
    
    # æ£€æŸ¥GPUæ•°é‡
    gpu_count = torch.cuda.device_count()
    print(f"ç³»ç»Ÿæ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    for i in range(gpu_count):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    
    # æ£€æŸ¥è¯·æ±‚çš„GPUæ˜¯å¦å­˜åœ¨
    if gpu_id >= gpu_count:
        raise RuntimeError(f"GPU {gpu_id} ä¸å­˜åœ¨ï¼Œå¯ç”¨GPU: 0-{gpu_count-1}")
    
    # è®¾ç½®å½“å‰è®¾å¤‡
    device = f'cuda:{gpu_id}'
    torch.cuda.set_device(gpu_id)
    
    print(f"æ­£åœ¨ä½¿ç”¨GPU: {gpu_id} ({torch.cuda.get_device_name(gpu_id)})")
    print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(gpu_id).total_memory / 1024**3:.1f} GB")
    
    # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
    mm = ModelManager(torch_dtype=torch.bfloat16, device="cpu")
    mm.load_models([
        "./FlashVSR-v1.1/diffusion_pytorch_model_streaming_dmd.safetensors",
    ])
    
    # åˆ›å»ºç®¡é“
    pipe = FlashVSRTinyLongPipeline.from_model_manager(mm, device=device)
    
    # åŠ è½½LQæŠ•å½±å™¨
    pipe.denoising_model().LQ_proj_in = Causal_LQ4x_Proj(in_dim=3, out_dim=1536, layer_num=1).to(device, dtype=torch.bfloat16)
    LQ_proj_in_path = "./FlashVSR-v1.1/LQ_proj_in.ckpt"
    if os.path.exists(LQ_proj_in_path):
        pipe.denoising_model().LQ_proj_in.load_state_dict(torch.load(LQ_proj_in_path, map_location="cpu"), strict=True)
        pipe.denoising_model().LQ_proj_in.to(device)

    # åŠ è½½TCè§£ç å™¨
    multi_scale_channels = [512, 256, 128, 128]
    pipe.TCDecoder = build_tcdecoder(new_channels=multi_scale_channels, new_latent_channels=16+768)
    mis = pipe.TCDecoder.load_state_dict(torch.load("./FlashVSR-v1.1/TCDecoder.ckpt"), strict=False)
    print("TCè§£ç å™¨åŠ è½½çŠ¶æ€:", mis)

    # å°†ç®¡é“ç§»åŠ¨åˆ°GPU
    pipe.to(device)
    pipe.enable_vram_management(num_persistent_param_in_dit=None)
    pipe.init_cross_kv()
    pipe.load_models_to_device(["dit","vae"])
    
    return pipe, device

def process_video_finalization(args):
    """å¤„ç†è§†é¢‘æœ€ç»ˆåŒ–ä»»åŠ¡ï¼ˆä½¿ç”¨æ”¹è¿›çš„å‡åŒ€å¡«è¡¥æ³•ï¼‰"""
    temp_dir, video_tensor, temp_video_path, final_video_path, original_fps, original_frame_count, original_duration, is_video_file, input_path, use_direct_method = args
    
    try:
        print(f"å¼€å§‹åˆ›å»ºçº¯è§†é¢‘æ–‡ä»¶: {os.path.basename(final_video_path)}")
        print(f"  ä½¿ç”¨å¸§ç‡: {original_fps:.6f} FPS, æœŸæœ›å¸§æ•°: {original_frame_count}")
        
        if use_direct_method:
            # ç›´æ¥æ–¹æ³•ï¼šä»å¼ é‡ç›´æ¥åˆ›å»ºè§†é¢‘ï¼ˆä»…åœ¨å¸§æ•°å®Œå…¨åŒ¹é…æ—¶ä½¿ç”¨ï¼‰
            print("ğŸ¯ ä½¿ç”¨ç›´æ¥æ–¹æ³•ï¼šä»å¼ é‡ç›´æ¥åˆ›å»ºè§†é¢‘ï¼ˆå¸§æ•°å®Œå…¨åŒ¹é…ï¼‰")
            save_video_directly_from_tensor(video_tensor, temp_video_path, fps=original_fps, quality=5)
        else:
            # ä¼ ç»Ÿæ–¹æ³•ï¼šé€šè¿‡PNGåºåˆ—åˆ›å»ºè§†é¢‘ï¼Œä½¿ç”¨å‡åŒ€å¡«è¡¥æ³•
            print("ğŸ“ ä½¿ç”¨æ”¹è¿›æ–¹æ³•ï¼šé€šè¿‡PNGåºåˆ—åˆ›å»ºè§†é¢‘ï¼Œä½¿ç”¨å‡åŒ€å¡«è¡¥æ³•")
            video_frames = tensor2video(video_tensor)
            
            # 1. å…ˆä¿å­˜ä¸ºPNGåºåˆ—å¸§
            processed_frames_dir = os.path.join(temp_dir, "processed_frames")
            saved_frame_paths = save_frames_as_png(video_frames, processed_frames_dir, "frame")
            print(f"âœ“ PNGåºåˆ—å¸§ä¿å­˜å®Œæˆ: {len(saved_frame_paths)}å¸§")
            
            # 2. ä½¿ç”¨å‡åŒ€å¡«è¡¥æ³•å¡«è¡¥åˆ°åŸå§‹è§†é¢‘çš„å¸§æ•°
            final_frames_dir = os.path.join(temp_dir, "final_frames")
            if is_video_file and original_frame_count > 0 and len(saved_frame_paths) < original_frame_count:
                print(f"ğŸ”§ ä½¿ç”¨å‡åŒ€å¡«è¡¥æ³•: {len(saved_frame_paths)} -> {original_frame_count}")
                final_frame_paths = pad_frames_to_match_original_uniform(
                    processed_frames_dir, original_frame_count, final_frames_dir)
            else:
                # å¯¹äºå›¾åƒåºåˆ—æˆ–å¸§æ•°å·²åŒ¹é…çš„æƒ…å†µï¼Œç›´æ¥ä½¿ç”¨å¤„ç†åçš„å¸§
                final_frame_paths = saved_frame_paths
                original_frame_count = len(saved_frame_paths)
            
            # 3. ä»å¸§è·¯å¾„åˆ›å»ºè§†é¢‘
            save_video_from_frames(final_frame_paths, temp_video_path, fps=original_fps, quality=5)
        
        print(f"âœ… è§†é¢‘åˆ›å»ºå®Œæˆ: {os.path.basename(final_video_path)}")
        
        # å¤åˆ¶ä¸´æ—¶è§†é¢‘åˆ°æœ€ç»ˆè·¯å¾„
        shutil.copy(temp_video_path, final_video_path)
        print(f"âœ… å®Œæˆçº¯è§†é¢‘è¾“å‡º: {os.path.basename(final_video_path)}")
        
        # éªŒè¯æœ€ç»ˆæ–‡ä»¶å‚æ•°
        try:
            final_info = get_video_info_accurate(final_video_path)
            print(f"ğŸ“ŠğŸ“Š æœ€ç»ˆè§†é¢‘å‚æ•°:")
            print(f"  å¸§æ•°: {final_info['frame_count']} (åŸå§‹: {original_frame_count})")
            print(f"  å¸§ç‡: {final_info['frame_rate']:.6f} (åŸå§‹: {original_fps:.6f})")
            print(f"  æ—¶é•¿: {final_info['duration']:.6f}ç§’ (åŸå§‹: {original_duration:.6f}ç§’)")
            
            # æ£€æŸ¥å‚æ•°ä¸€è‡´æ€§
            frame_match = abs(final_info['frame_count'] - original_frame_count) <= 1
            fps_match = abs(final_info['frame_rate'] - original_fps) < 0.01
            duration_match = abs(final_info['duration'] - original_duration) < 0.1
            
            if frame_match and fps_match and duration_match:
                print("ğŸ¯ğŸ¯ å‚æ•°ä¸€è‡´æ€§: âœ… å®Œç¾åŒ¹é…")
            else:
                print("âš ï¸ å‚æ•°ä¸€è‡´æ€§: éƒ¨åˆ†å‚æ•°æœ‰å·®å¼‚")
                if not frame_match:
                    print(f"  å¸§æ•°å·®å¼‚: {final_info['frame_count']} vs {original_frame_count}")
                if not fps_match:
                    print(f"  å¸§ç‡å·®å¼‚: {final_info['frame_rate']:.6f} vs {original_fps:.6f}")
                if not duration_match:
                    print(f"  æ—¶é•¿å·®å¼‚: {final_info['duration']:.6f} vs {original_duration:.6f}")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•éªŒè¯æœ€ç»ˆæ–‡ä»¶å‚æ•°: {e}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if os.path.exists(os.path.join(temp_dir, "processed_frames")):
                shutil.rmtree(os.path.join(temp_dir, "processed_frames"))
            if os.path.exists(os.path.join(temp_dir, "final_frames")):
                shutil.rmtree(os.path.join(temp_dir, "final_frames"))
            if os.path.exists(temp_video_path):
                os.remove(temp_video_path)
        except:
            pass
            
        return True, final_video_path
        
    except Exception as e:
        print(f"âŒâŒ è§†é¢‘æœ€ç»ˆåŒ–å¤±è´¥ {os.path.basename(final_video_path)}: {e}")
        return False, final_video_path

def main():
    parser = argparse.ArgumentParser(description='FlashVSRè§†é¢‘è¶…åˆ†è¾¨ç‡å¤„ç†ï¼ˆæ”¹è¿›ç‰ˆå‡åŒ€å¡«è¡¥æ³•ï¼‰')
    parser.add_argument('--input', type=str, required=True, help='è¾“å…¥æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--output', type=str, default='./results', help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--gpu', type=int, default=0, help='GPUè®¾å¤‡ID (0, 1, 2, 3)')
    parser.add_argument('--seed', type=int, default=0, help='éšæœºç§å­')
    parser.add_argument('--scale', type=float, default=4.0, help='ç¼©æ”¾æ¯”ä¾‹')
    parser.add_argument('--sparse_ratio', type=float, default=2.0, help='ç¨€ç–æ¯”ç‡')
    parser.add_argument('--local_range', type=int, default=11, help='å±€éƒ¨èŒƒå›´')
    parser.add_argument('--max_workers', type=int, default=2, help='å¹¶è¡Œå¤„ç†çš„æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°')
    
    args = parser.parse_args()
    
    print("=== FlashVSR GPUè®¾ç½®ï¼ˆæ”¹è¿›ç‰ˆå‡åŒ€å¡«è¡¥æ³•ï¼‰ ===")
    print(f"è¯·æ±‚ä½¿ç”¨GPU: {args.gpu}")
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if not torch.cuda.is_available():
        print("é”™è¯¯: CUDAä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥CUDAå®‰è£…")
        return
    
    gpu_count = torch.cuda.device_count()
    print(f"ç³»ç»Ÿæ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    if args.gpu >= gpu_count:
        print(f"é”™è¯¯: GPU {args.gpu} ä¸å­˜åœ¨ï¼Œå¯ç”¨GPU: 0-{gpu_count-1}")
        return
    
    RESULT_ROOT = args.output
    os.makedirs(RESULT_ROOT, exist_ok=True)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•åœ¨è¾“å‡ºç›®å½•ä¸‹
    TEMP_ROOT = os.path.join(RESULT_ROOT, "temp")
    os.makedirs(TEMP_ROOT, exist_ok=True)
    print(f"ä¸´æ—¶æ–‡ä»¶ç›®å½•: {TEMP_ROOT}")
    
    # è·å–è¾“å…¥æ–‡ä»¶åˆ—è¡¨
    try:
        input_files = get_input_files(args.input)
    except Exception as e:
        print(f"è¾“å…¥æ–‡ä»¶é”™è¯¯: {e}")
        return
    
    if not input_files:
        print(f"åœ¨è·¯å¾„ {args.input} ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„è§†é¢‘æ–‡ä»¶æˆ–å›¾åƒåºåˆ—")
        return
    
    print(f"æ‰¾åˆ° {len(input_files)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")
    
    try:
        # åˆå§‹åŒ–ç®¡é“
        pipe, device = init_pipeline(args.gpu)
    except Exception as e:
        print(f"ç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºçº¿ç¨‹æ± ç”¨äºå¹¶è¡Œå¤„ç†
    executor = ThreadPoolExecutor(max_workers=args.max_workers)
    futures = []
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for i, input_path in enumerate(input_files, 1):
        print(f"\n=== å¤„ç†æ–‡ä»¶ {i}/{len(input_files)} ===")
        print(f"è¾“å…¥: {input_path}")
        
        # æ¸…ç†GPUå†…å­˜
        torch.cuda.empty_cache()
        
        name = os.path.basename(input_path.rstrip('/'))
        if name.startswith('.'):
            continue
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶
        is_video_file = is_video(input_path)
        
        # ä½¿ç”¨ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯è·å–
        try:
            LQ, th, tw, F, fps, from_video, original_fps, original_duration, original_frame_count, processed_frame_count = prepare_input_tensor(
                input_path, scale=args.scale, dtype=torch.bfloat16, device=device)
        except Exception as e:
            print(f"[é”™è¯¯] å‡†å¤‡è¾“å…¥å¼ é‡å¤±è´¥: {e}")
            continue

        # å¯¹äºè§†é¢‘æ–‡ä»¶ï¼Œæ˜¾ç¤ºä¿¡æ¯
        if is_video_file:
            print(f"âœ“ è§†é¢‘æ–‡ä»¶ä¿¡æ¯: {original_frame_count}å¸§, {original_fps:.6f}fps, {original_duration:.6f}ç§’")
            print(f"  å¤„ç†åå¸§æ•°: {processed_frame_count}å¸§ (éœ€è¦å¡«è¡¥ {original_frame_count - processed_frame_count} å¸§)")

        try:
            print("å¼€å§‹FlashVSRå¤„ç†...")
            video = pipe(
                prompt="", 
                negative_prompt="", 
                cfg_scale=1.0, 
                num_inference_steps=1, 
                seed=args.seed,
                LQ_video=LQ, 
                num_frames=F, 
                height=th, 
                width=tw, 
                is_full_block=False, 
                if_buffer=True,
                topk_ratio=args.sparse_ratio*768 * 1280/(th*tw), 
                kv_ratio=3.0,
                local_range=args.local_range,
                color_fix=True,
            )

            # è®¡ç®—å¤„ç†åçš„å®é™…å¸§æ•°ï¼ˆå‡å»å¡«å……çš„å¸§ï¼‰
            processed_frame_count = F - 4
            
            # åˆ¤æ–­æ˜¯å¦å¯ä»¥ä½¿ç”¨ç›´æ¥æ–¹æ³•
            # å¦‚æœå¤„ç†åçš„å¸§æ•°ç­‰äºåŸå§‹å¸§æ•°ï¼Œä½¿ç”¨ç›´æ¥æ–¹æ³•
            use_direct_method = (processed_frame_count == original_frame_count)
            
            if use_direct_method:
                print("ğŸ¯ å¸§æ•°åŒ¹é…ï¼Œä½¿ç”¨ç›´æ¥æ–¹æ³•åˆ›å»ºè§†é¢‘ï¼ˆè·³è¿‡PNGè½¬æ¢ï¼‰")
            else:
                missing_frames = original_frame_count - processed_frame_count
                print(f"ğŸ“ ä½¿ç”¨æ”¹è¿›çš„å‡åŒ€å¡«è¡¥æ³•: å¤„ç†{processed_frame_count}å¸§ï¼Œéœ€è¦{original_frame_count}å¸§ï¼Œå¡«è¡¥{missing_frames}å¸§")
                print(f"  è®¡ç®—æ’å…¥é—´éš”: æ¯ {max(1, processed_frame_count // (missing_frames + 1))} å¸§åæ’å…¥1å¸§")
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            if os.path.isdir(input_path):
                base_name = os.path.basename(input_path.rstrip('/'))
            else:
                base_name = os.path.splitext(os.path.basename(input_path))[0]
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = tempfile.mkdtemp(dir=TEMP_ROOT, prefix=f"temp_{base_name}_")
            print(f"ğŸ“ğŸ“ ä¸´æ—¶ç›®å½•: {temp_dir}")
            
            # å‡†å¤‡æœ€ç»ˆè§†é¢‘è·¯å¾„
            temp_video_path = os.path.join(temp_dir, "temp_video.mp4")
            final_video_filename = f"FlashVSR_v1.1_Tiny_Long_{base_name}_gpu{args.gpu}_seed{args.seed}_uniform.mp4"
            final_video_path = os.path.join(RESULT_ROOT, final_video_filename)
            
            # æäº¤å¹¶è¡Œå¤„ç†ä»»åŠ¡
            print(f"ğŸš€ğŸš€ æäº¤å¹¶è¡Œå¤„ç†ä»»åŠ¡: {os.path.basename(final_video_path)}")
            future = executor.submit(process_video_finalization, (
                temp_dir, video, temp_video_path, final_video_path, 
                original_fps, original_frame_count, original_duration, is_video_file, input_path, use_direct_method
            ))
            futures.append((future, final_video_path, temp_dir))
            
            print(f"ğŸ“ŠğŸ“Š å½“å‰å¹¶è¡Œä»»åŠ¡æ•°: {len(futures)}")
            
            # å¦‚æœå¹¶è¡Œä»»åŠ¡è¾¾åˆ°ä¸Šé™ï¼Œç­‰å¾…éƒ¨åˆ†ä»»åŠ¡å®Œæˆ
            if len(futures) >= args.max_workers * 2:
                print("ğŸ”„ğŸ”„ è¾¾åˆ°å¹¶è¡Œä»»åŠ¡ä¸Šé™ï¼Œç­‰å¾…éƒ¨åˆ†ä»»åŠ¡å®Œæˆ...")
                completed_count = 0
                for f, path, temp_dir in futures[:]:
                    if f.done():
                        try:
                            success, result_path = f.result(timeout=1)
                            if success:
                                print(f"âœ… å¹¶è¡Œä»»åŠ¡å®Œæˆ: {os.path.basename(result_path)}")
                            else:
                                print(f"âŒâŒ å¹¶è¡Œä»»åŠ¡å¤±è´¥: {os.path.basename(result_path)}")
                            # æ¸…ç†ä¸´æ—¶ç›®å½•
                            try:
                                shutil.rmtree(temp_dir)
                                print(f"ğŸ—‘ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•: {os.path.basename(temp_dir)}")
                            except:
                                pass
                            futures.remove((f, path, temp_dir))
                            completed_count += 1
                        except:
                            pass
                
                if completed_count > 0:
                    print(f"ğŸ”„ğŸ”„ å·²å®Œæˆ {completed_count} ä¸ªä»»åŠ¡ï¼Œç»§ç»­å¤„ç†...")
            
        except Exception as e:
            print(f"[å¤„ç†é”™è¯¯] {name}: {e}")
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(temp_dir)
                print(f"ğŸ—‘ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•ï¼ˆé”™è¯¯æ—¶ï¼‰: {os.path.basename(temp_dir)}")
            except:
                pass
            continue

    print(f"\nğŸ”„ğŸ”„ ç­‰å¾…æ‰€æœ‰å¹¶è¡Œä»»åŠ¡å®Œæˆ...")
    
    # ç­‰å¾…æ‰€æœ‰å‰©ä½™ä»»åŠ¡å®Œæˆ
    completed_count = 0
    failed_count = 0
    
    for future, final_video_path, temp_dir in futures:
        try:
            success, result_path = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
            if success:
                print(f"âœ… ä»»åŠ¡å®Œæˆ: {os.path.basename(result_path)}")
                completed_count += 1
            else:
                print(f"âŒâŒ ä»»åŠ¡å¤±è´¥: {os.path.basename(result_path)}")
                failed_count += 1
        except Exception as e:
            print(f"âŒâŒ ä»»åŠ¡è¶…æ—¶æˆ–å¤±è´¥ {os.path.basename(final_video_path)}: {e}")
            failed_count += 1
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(temp_dir)
                print(f"ğŸ—‘ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•: {os.path.basename(temp_dir)}")
            except:
                pass
    
    # å…³é—­çº¿ç¨‹æ± 
    executor.shutdown(wait=True)
    
    # å°è¯•æ¸…ç†æ•´ä¸ªä¸´æ—¶ç›®å½•ï¼ˆå¦‚æœä¸ºç©ºï¼‰
    try:
        if os.path.exists(TEMP_ROOT) and not os.listdir(TEMP_ROOT):
            shutil.rmtree(TEMP_ROOT)
            print(f"ğŸ—‘ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ ¹ç›®å½•: {TEMP_ROOT}")
    except:
        pass
    
    print(f"\n=== æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ ===")
    print(f"âœ… æˆåŠŸ: {completed_count} ä¸ªæ–‡ä»¶")
    print(f"âŒâŒ å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“ğŸ“ è¾“å‡ºç›®å½•: {RESULT_ROOT}")
    print(f"ğŸ—‘ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
    print("ğŸ¯ğŸ¯ è¾“å‡ºæ–‡ä»¶ä¸ºçº¯è§†é¢‘æµï¼ˆæ— éŸ³é¢‘ï¼‰ï¼Œä½¿ç”¨å‡åŒ€å¡«è¡¥æ³•ä¼˜åŒ–å¸§æ•°")

if __name__ == "__main__":
    main()
