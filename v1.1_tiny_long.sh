#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os, re, time, argparse
import numpy as np
from PIL import Image
import imageio
from tqdm import tqdm
import torch
from einops import rearrange
import subprocess
import tempfile
import shutil
import json
import threading
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ  pymediainfo å¯¼å…¥
try:
    from pymediainfo import MediaInfo
    PYMEDIAINFO_AVAILABLE = True
except ImportError:
    print("è­¦å‘Š: æœªå®‰è£… pymediainfoï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
    PYMEDIAINFO_AVAILABLE = False

from diffsynth import ModelManager, FlashVSRTinyLongPipeline
from utils.utils import Causal_LQ4x_Proj
from utils.TCDecoder import build_tcdecoder

def get_video_info_accurate(path):
    """ä½¿ç”¨ pymediainfo è·å–ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯"""
    if not PYMEDIAINFO_AVAILABLE:
        return get_video_info_fallback(path)
    
    try:
        media_info = MediaInfo.parse(path)
        video_track = None
        general_track = None
        
        for track in media_info.tracks:
            if track.track_type == 'Video':
                video_track = track
            elif track.track_type == 'General':
                general_track = track
        
        if not video_track:
            raise ValueError("æœªæ‰¾åˆ°è§†é¢‘æµ")
        
        # è·å–ç²¾ç¡®çš„å¸§ç‡
        frame_rate = None
        if hasattr(video_track, 'frame_rate') and video_track.frame_rate:
            frame_rate_str = str(video_track.frame_rate)
            # å¤„ç†åˆ†æ•°å½¢å¼çš„å¸§ç‡ (å¦‚ 30000/1001)
            if '/' in frame_rate_str:
                try:
                    numerator, denominator = map(float, frame_rate_str.split('/'))
                    frame_rate = numerator / denominator
                except:
                    frame_rate = float(frame_rate_str)
            else:
                frame_rate = float(frame_rate_str)
        
        # è·å–æ€»å¸§æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ç²¾ç¡®ç»Ÿè®¡ï¼‰
        frame_count = None
        if hasattr(video_track, 'frame_count') and video_track.frame_count:
            frame_count = int(video_track.frame_count)
        
        # è·å–æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰- ä¼˜å…ˆä½¿ç”¨è§†é¢‘æµæ—¶é•¿
        duration_ms = None
        if hasattr(video_track, 'duration') and video_track.duration:
            duration_ms = float(video_track.duration)
            print(f"âœ… ä½¿ç”¨è§†é¢‘æµæ—¶é•¿: {duration_ms}ms")
        elif hasattr(general_track, 'duration') and general_track.duration:
            duration_ms = float(general_track.duration)
            print(f"âš ï¸ ä½¿ç”¨å®¹å™¨æ—¶é•¿: {duration_ms}ms")
        
        # è®¡ç®—æ—¶é•¿ï¼ˆç§’ï¼‰
        duration_seconds = duration_ms / 1000.0 if duration_ms else None
        
        # å¦‚æœå¸§æ•°æœªçŸ¥ä½†æ—¶é•¿å’Œå¸§ç‡å·²çŸ¥ï¼Œè®¡ç®—å¸§æ•°
        if frame_count is None and duration_seconds and frame_rate:
            frame_count = int(round(duration_seconds * frame_rate))
        
        # å¦‚æœæ—¶é•¿æœªçŸ¥ä½†å¸§æ•°å’Œå¸§ç‡å·²çŸ¥ï¼Œè®¡ç®—æ—¶é•¿
        if duration_seconds is None and frame_count and frame_rate:
            duration_seconds = frame_count / frame_rate
        
        # é»˜è®¤å€¼
        if frame_rate is None:
            frame_rate = 25.0
        if frame_count is None:
            # ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            return get_video_info_fallback(path)
        if duration_seconds is None:
            duration_seconds = frame_count / frame_rate
        
        # è·å–åˆ†è¾¨ç‡
        width = int(video_track.width) if hasattr(video_track, 'width') else 0
        height = int(video_track.height) if hasattr(video_track, 'height') else 0
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        calculated_frames = int(round(duration_seconds * frame_rate))
        if abs(calculated_frames - frame_count) > 2:  # å…è®¸2å¸§è¯¯å·®
            print(f"âš ï¸ å¸§æ•°ä¸ä¸€è‡´: ç»Ÿè®¡={frame_count}, è®¡ç®—={calculated_frames}, ä½¿ç”¨ç»Ÿè®¡å€¼")
        
        print(f"ğŸ“Š pymediainfo ç²¾ç¡®ä¿¡æ¯: {frame_count}å¸§, {frame_rate:.6f}fps, {duration_seconds:.6f}ç§’")
        
        return {
            'frame_count': frame_count,
            'frame_rate': frame_rate,
            'duration': duration_seconds,
            'width': width,
            'height': height,
            'is_accurate': True
        }
        
    except Exception as e:
        print(f"âŒ pymediainfo è§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
        return get_video_info_fallback(path)

def get_video_info_fallback(path):
    """å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨ ffprobe è·å–è§†é¢‘ä¿¡æ¯"""
    try:
        # ä½¿ç”¨ ffprobe è·å–ç²¾ç¡®å¸§æ•°
        frame_count_cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'v:0',
            '-count_frames',
            '-show_entries', 'stream=nb_read_frames',
            '-of', 'csv=p=0',
            path
        ]
        
        result = subprocess.run(frame_count_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            frame_count = int(result.stdout.strip())
        else:
            frame_count = 0
        
        # è·å–æ—¶é•¿å’Œå¸§ç‡
        info_cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'v:0',
            '-show_entries', 'stream=r_frame_rate,duration,width,height',
            '-of', 'json',
            path
        ]
        
        result = subprocess.run(info_cmd, capture_output=True, text=True)
        if result.returncode == 0:
            info = json.loads(result.stdout)
            stream = info['streams'][0] if info['streams'] else {}
            
            # è§£æå¸§ç‡
            frame_rate_str = stream.get('r_frame_rate', '25/1')
            if '/' in frame_rate_str:
                num, den = map(int, frame_rate_str.split('/'))
                frame_rate = num / den
            else:
                frame_rate = float(frame_rate_str)
            
            # è·å–æ—¶é•¿
            duration = float(stream.get('duration', 0))
            
            # å¦‚æœæ—¶é•¿æœªçŸ¥ï¼Œä½¿ç”¨å¸§æ•°å’Œå¸§ç‡è®¡ç®—
            if duration <= 0 and frame_count > 0:
                duration = frame_count / frame_rate
            
            # å¦‚æœå¸§æ•°æœªçŸ¥ï¼Œä½¿ç”¨æ—¶é•·å’Œå¸§ç‡è®¡ç®—
            if frame_count <= 0 and duration > 0:
                frame_count = int(round(duration * frame_rate))
            
            width = int(stream.get('width', 0))
            height = int(stream.get('height', 0))
            
            print(f"ğŸ“Š ffprobe ä¿¡æ¯: {frame_count}å¸§, {frame_rate:.6f}fps, {duration:.6f}ç§’")
            
            return {
                'frame_count': frame_count,
                'frame_rate': frame_rate,
                'duration': duration,
                'width': width,
                'height': height,
                'is_accurate': False
            }
    
    except Exception as e:
        print(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
    
    # æœ€ç»ˆå¤‡ç”¨å€¼
    return {
        'frame_count': 250,  # é»˜è®¤å€¼
        'frame_rate': 25.0,
        'duration': 10.0,
        'width': 720,
        'height': 540,
        'is_accurate': False
    }

def tensor2video(frames):
    frames = rearrange(frames, "C T H W -> T H W C")
    frames = ((frames.float() + 1) * 127.5).clip(0, 255).cpu().numpy().astype(np.uint8)
    frames = [Image.fromarray(frame) for frame in frames]
    return frames

def natural_key(name: str):
    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'([0-9]+)', os.path.basename(name))]

def list_images_natural(folder: str):
    exts = ('.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG')
    fs = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(exts)]
    fs.sort(key=natural_key)
    return fs

def list_videos_natural(folder: str):
    exts = ('.mp4', '.mov', '.avi', '.mkv', '.MP4', '.MOV', '.AVI', '.MKV')
    fs = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(exts)]
    fs.sort(key=natural_key)
    return fs

def get_input_files(input_path):
    input_files = []
    
    if os.path.isfile(input_path):
        input_files.append(input_path)
    elif os.path.isdir(input_path):
        video_files = list_videos_natural(input_path)
        input_files.extend(video_files)
        
        for item in os.listdir(input_path):
            item_path = os.path.join(input_path, item)
            if os.path.isdir(item_path):
                image_files = list_images_natural(item_path)
                if image_files:
                    input_files.append(item_path)
    else:
        raise ValueError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
    
    return input_files

def largest_8n1_leq(n):
    return 0 if n < 1 else ((n - 1)//8)*8 + 1

def is_video(path):
    return os.path.isfile(path) and path.lower().endswith(('.mp4','.mov','.avi','.mkv'))

def pil_to_tensor_neg1_1(img: Image.Image, dtype=torch.bfloat16, device='cuda'):
    t = torch.from_numpy(np.asarray(img, np.uint8)).to(device=device, dtype=torch.float32)
    t = t.permute(2,0,1) / 255.0 * 2.0 - 1.0
    return t.to(dtype)

def save_frames_as_png(frames, output_dir, base_name="frame"):
    """ä¿å­˜å¸§åºåˆ—ä¸ºPNGå›¾ç‰‡"""
    os.makedirs(output_dir, exist_ok=True)
    saved_paths = []
    
    for i, frame in enumerate(tqdm(frames, desc=f"Saving PNG frames")):
        filename = f"{base_name}_{i:06d}.png"
        filepath = os.path.join(output_dir, filename)
        frame.save(filepath, 'PNG')
        saved_paths.append(filepath)
    
    return saved_paths

def save_video_from_frames(frame_paths, save_path, fps=30, quality=5):
    """ä»å¸§è·¯å¾„åˆ—è¡¨åˆ›å»ºè§†é¢‘"""
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    w = imageio.get_writer(save_path, fps=fps, quality=quality)
    
    for frame_path in tqdm(frame_paths, desc=f"Creating video {os.path.basename(save_path)}"):
        frame = Image.open(frame_path)
        w.append_data(np.array(frame))
    w.close()

def pad_frames_to_match_original(processed_frames_dir, original_frame_count, output_dir):
    """å°†å¤„ç†åçš„å¸§å¡«è¡¥åˆ°åŸå§‹è§†é¢‘çš„å¸§æ•°"""
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–å¤„ç†åçš„å¸§
    processed_frames = [f for f in os.listdir(processed_frames_dir) if f.endswith('.png')]
    processed_frames.sort()
    processed_count = len(processed_frames)
    
    print(f"ğŸ“Š å¡«è¡¥å‰: å¤„ç†{processed_count}å¸§, éœ€è¦{original_frame_count}å¸§")
    
    if processed_count >= original_frame_count:
        # å¦‚æœå¤„ç†åçš„å¸§æ•°å¤šäºæˆ–ç­‰äºåŸå§‹å¸§æ•°ï¼Œç›´æ¥å¤åˆ¶å‰Nå¸§
        for i in range(original_frame_count):
            if i < len(processed_frames):
                src_path = os.path.join(processed_frames_dir, processed_frames[i])
                dst_path = os.path.join(output_dir, f"frame_{i:06d}.png")
                shutil.copy2(src_path, dst_path)
    else:
        # å¦‚æœå¤„ç†åçš„å¸§æ•°å°‘äºåŸå§‹å¸§æ•°ï¼Œè¿›è¡Œå¡«è¡¥
        # å¤åˆ¶å¤„ç†åçš„å¸§
        for i in range(processed_count):
            src_path = os.path.join(processed_frames_dir, processed_frames[i])
            dst_path = os.path.join(output_dir, f"frame_{i:06d}.png")
            shutil.copy2(src_path, dst_path)
        
        # ç”¨æœ€åä¸€å¸§å¡«è¡¥å‰©ä½™å¸§
        last_frame_path = os.path.join(processed_frames_dir, processed_frames[-1])
        for i in range(processed_count, original_frame_count):
            dst_path = os.path.join(output_dir, f"frame_{i:06d}.png")
            shutil.copy2(last_frame_path, dst_path)
    
    # éªŒè¯æœ€ç»ˆå¸§æ•°
    final_frames = [f for f in os.listdir(output_dir) if f.endswith('.png')]
    final_frames.sort()
    final_count_actual = len(final_frames)
    
    if final_count_actual != original_frame_count:
        print(f"âŒ å¸§æ•°éªŒè¯å¤±è´¥: æœŸæœ›{original_frame_count}, å®é™…{final_count_actual}")
    else:
        print(f"âœ… å¸§æ•°éªŒè¯æˆåŠŸ: {final_count_actual}å¸§")
    
    return [os.path.join(output_dir, f) for f in final_frames]

def compute_scaled_and_target_dims(w0: int, h0: int, scale: float = 4.0, multiple: int = 128):
    if w0 <= 0 or h0 <= 0:
        raise ValueError("Invalid original size")
    if scale <= 0:
        raise ValueError("scale must be > 0")

    sW = int(round(w0 * scale))
    sH = int(round(h0 * scale))
    tW = (sW // multiple) * multiple
    tH = (sH // multiple) * multiple

    if tW == 0 or tH == 0:
        raise ValueError(
            f"Scaled size too small ({sW}x{sH}) for multiple={multiple}. "
            f"Increase scale (got {scale})."
        )
    return sW, sH, tW, tH

def upscale_then_center_crop(img: Image.Image, scale: float, tW: int, tH: int) -> Image.Image:
    w0, h0 = img.size
    sW = int(round(w0 * scale))
    sH = int(round(h0 * scale))

    if tW > sW or tH > sH:
        raise ValueError(
            f"Target crop ({tW}x{tH}) exceeds scaled size ({sW}x{sH}). "
            f"Increase scale."
        )

    up = img.resize((sW, sH), Image.BICUBIC)
    l = (sW - tW) // 2
    t = (sH - tH) // 2
    return up.crop((l, t, l + tW, t + tH))

def prepare_input_tensor(path: str, scale: float = 4, dtype=torch.bfloat16, device='cuda'):
    """å‡†å¤‡è¾“å…¥å¼ é‡ï¼Œä½¿ç”¨ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯"""
    # ä½¿ç”¨ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯è·å–
    if is_video(path):
        video_info = get_video_info_accurate(path)
        original_frame_count = video_info['frame_count']
        original_fps = video_info['frame_rate']
        original_duration = video_info['duration']
        w0 = video_info['width']
        h0 = video_info['height']
        
        is_video_input = True
        
        print(f"ğŸ¯ ç²¾ç¡®è§†é¢‘ä¿¡æ¯: {original_frame_count}å¸§, {original_fps:.6f}fps, {original_duration:.6f}ç§’, {w0}x{h0}")
        
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        calculated_frames = int(round(original_duration * original_fps))
        if abs(calculated_frames - original_frame_count) > 1:
            print(f"âš ï¸ è­¦å‘Š: å¸§æ•°ä¸ä¸€è‡´ï¼Œä½¿ç”¨ç»Ÿè®¡å€¼ {original_frame_count} è€Œéè®¡ç®—å€¼ {calculated_frames}")
        
    else:
        # å›¾åƒåºåˆ—å¤„ç†ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        paths0 = list_images_natural(path)
        if not paths0:
            raise FileNotFoundError(f"No images in {path}")

        with Image.open(paths0[0]) as _img0:
            w0, h0 = _img0.size
            original_frame_count = len(paths0)
            original_fps = 30.0
            original_duration = original_frame_count / original_fps

        is_video_input = False
        print(f"ğŸ“ å›¾åƒåºåˆ—: {original_frame_count}å¸§, {original_fps}fps, {original_duration:.2f}ç§’, {w0}x{h0}")

    # è®¡ç®—ç›®æ ‡å°ºå¯¸
    sW, sH, tW, tH = compute_scaled_and_target_dims(w0, h0, scale=scale, multiple=128)
    print(f"ğŸ“ ç¼©æ”¾ç›®æ ‡: {w0}x{h0} -> {sW}x{sH} -> {tW}x{tH} (x{scale:.2f})")

    # å¸§å¤„ç†é€»è¾‘
    if is_video(path):
        # è§†é¢‘æ–‡ä»¶å¤„ç†
        rdr = imageio.get_reader(path)
        
        # ä½¿ç”¨ç²¾ç¡®çš„å¸§æ•°
        total = original_frame_count
        
        idx = list(range(total)) + [total-1]*4
        F = largest_8n1_leq(len(idx))
        if F == 0:
            rdr.close()
            raise RuntimeError(f"å¸§æ•°ä¸è¶³: {path}, å¾—åˆ° {len(idx)} å¸§")
        
        idx = idx[:F]
        processed_frame_count = F - 4  # å®é™…å¤„ç†çš„å¸§æ•°ï¼ˆå‡å»å¡«å……ï¼‰
        
        print(f"ğŸ”„ å¸§å¤„ç†: åŸå§‹{total}å¸§ -> å¡«å……å{F}å¸§ -> å®é™…å¤„ç†{processed_frame_count}å¸§")

        frames = []
        try:
            for i in idx:
                img = Image.fromarray(rdr.get_data(i)).convert('RGB')
                img_out = upscale_then_center_crop(img, scale=scale, tW=tW, tH=tH)
                frames.append(pil_to_tensor_neg1_1(img_out, dtype, 'cpu'))
        finally:
            try: 
                rdr.close()
            except Exception: 
                pass

        vid = torch.stack(frames, 0).permute(1,0,2,3).unsqueeze(0)
        fps = original_fps
        
    else:
        # å›¾åƒåºåˆ—å¤„ç†
        paths0 = list_images_natural(path)
        paths = paths0 + [paths0[-1]] * 4
        F = largest_8n1_leq(len(paths))
        if F == 0:
            raise RuntimeError(f"å¸§æ•°ä¸è¶³: {path}, å¾—åˆ° {len(paths)} å¸§")
        
        paths = paths[:F]
        processed_frame_count = F - 4
        
        print(f"ğŸ”„ å¸§å¤„ç†: åŸå§‹{len(paths0)}å¸§ -> å¡«å……å{F}å¸§ -> å®é™…å¤„ç†{processed_frame_count}å¸§")

        frames = []
        for p in paths:
            with Image.open(p).convert('RGB') as img:
                img_out = upscale_then_center_crop(img, scale=scale, tW=tW, tH=tH)
                frames.append(pil_to_tensor_neg1_1(img_out, dtype, 'cpu'))
        
        vid = torch.stack(frames, 0).permute(1,0,2,3).unsqueeze(0)
        fps = original_fps

    return (vid, tH, tW, F, fps, is_video_input, original_fps, original_duration, original_frame_count)

def init_pipeline(gpu_id=0):
    # é¦–å…ˆæ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        raise RuntimeError("CUDAä¸å¯ç”¨")
    
    # æ£€æŸ¥GPUæ•°é‡
    gpu_count = torch.cuda.device_count()
    print(f"ç³»ç»Ÿæ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    for i in range(gpu_count):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    
    # æ£€æŸ¥è¯·æ±‚çš„GPUæ˜¯å¦å­˜åœ¨
    if gpu_id >= gpu_count:
        raise RuntimeError(f"GPU {gpu_id} ä¸å­˜åœ¨ï¼Œå¯ç”¨GPU: 0-{gpu_count-1}")
    
    # è®¾ç½®å½“å‰è®¾å¤‡
    device = f'cuda:{gpu_id}'
    torch.cuda.set_device(gpu_id)
    
    print(f"æ­£åœ¨ä½¿ç”¨GPU: {gpu_id} ({torch.cuda.get_device_name(gpu_id)})")
    print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(gpu_id).total_memory / 1024**3:.1f} GB")
    
    # åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
    mm = ModelManager(torch_dtype=torch.bfloat16, device="cpu")
    mm.load_models([
        "./FlashVSR-v1.1/diffusion_pytorch_model_streaming_dmd.safetensors",
    ])
    
    # åˆ›å»ºç®¡é“
    pipe = FlashVSRTinyLongPipeline.from_model_manager(mm, device=device)
    
    # åŠ è½½LQæŠ•å½±å™¨
    pipe.denoising_model().LQ_proj_in = Causal_LQ4x_Proj(in_dim=3, out_dim=1536, layer_num=1).to(device, dtype=torch.bfloat16)
    LQ_proj_in_path = "./FlashVSR-v1.1/LQ_proj_in.ckpt"
    if os.path.exists(LQ_proj_in_path):
        pipe.denoising_model().LQ_proj_in.load_state_dict(torch.load(LQ_proj_in_path, map_location="cpu"), strict=True)
        pipe.denoising_model().LQ_proj_in.to(device)

    # åŠ è½½TCè§£ç å™¨
    multi_scale_channels = [512, 256, 128, 128]
    pipe.TCDecoder = build_tcdecoder(new_channels=multi_scale_channels, new_latent_channels=16+768)
    mis = pipe.TCDecoder.load_state_dict(torch.load("./FlashVSR-v1.1/TCDecoder.ckpt"), strict=False)
    print("TCè§£ç å™¨åŠ è½½çŠ¶æ€:", mis)

    # å°†ç®¡é“ç§»åŠ¨åˆ°GPU
    pipe.to(device)
    pipe.enable_vram_management(num_persistent_param_in_dit=None)
    pipe.init_cross_kv()
    pipe.load_models_to_device(["dit","vae"])
    
    return pipe, device

def process_video_finalization(args):
    """å¤„ç†è§†é¢‘æœ€ç»ˆåŒ–ä»»åŠ¡ï¼ˆåªå¤„ç†è§†é¢‘æµï¼Œæ— éŸ³é¢‘ï¼‰"""
    temp_dir, final_frame_paths, temp_video_path, final_video_path, original_fps, original_frame_count, original_duration, is_video_file, input_path = args
    
    try:
        # 1. ä»å¡«è¡¥åçš„å¸§åˆ›å»ºè§†é¢‘ï¼ˆçº¯è§†é¢‘æµï¼‰
        print(f"å¼€å§‹åˆ›å»ºçº¯è§†é¢‘æ–‡ä»¶: {os.path.basename(final_video_path)}")
        print(f"  ä½¿ç”¨å¸§ç‡: {original_fps:.6f} FPS, å¸§æ•°: {len(final_frame_paths)}")
        
        save_video_from_frames(final_frame_paths, temp_video_path, fps=original_fps, quality=5)
        print(f"âœ… è§†é¢‘åˆ›å»ºå®Œæˆ: {os.path.basename(final_video_path)}")
        
        # 2. ç›´æ¥å¤åˆ¶ä¸´æ—¶è§†é¢‘åˆ°æœ€ç»ˆè·¯å¾„ï¼ˆæ— éŸ³é¢‘å¤„ç†ï¼‰
        shutil.copy(temp_video_path, final_video_path)
        print(f"âœ… å®Œæˆçº¯è§†é¢‘è¾“å‡º: {os.path.basename(final_video_path)}")
        
        # 3. éªŒè¯æœ€ç»ˆæ–‡ä»¶å‚æ•°
        try:
            final_info = get_video_info_accurate(final_video_path)
            print(f"ğŸ“Š æœ€ç»ˆè§†é¢‘å‚æ•°:")
            print(f"  å¸§æ•°: {final_info['frame_count']} (åŸå§‹: {original_frame_count})")
            print(f"  å¸§ç‡: {final_info['frame_rate']:.6f} (åŸå§‹: {original_fps:.6f})")
            print(f"  æ—¶é•¿: {final_info['duration']:.6f}ç§’ (åŸå§‹: {original_duration:.6f}ç§’)")
            
            # æ£€æŸ¥å‚æ•°ä¸€è‡´æ€§
            frame_match = abs(final_info['frame_count'] - original_frame_count) <= 1
            fps_match = abs(final_info['frame_rate'] - original_fps) < 0.01
            duration_match = abs(final_info['duration'] - original_duration) < 0.1
            
            if frame_match and fps_match and duration_match:
                print("ğŸ¯ å‚æ•°ä¸€è‡´æ€§: âœ… å®Œç¾åŒ¹é…")
            else:
                print("âš ï¸ å‚æ•°ä¸€è‡´æ€§: éƒ¨åˆ†å‚æ•°æœ‰å·®å¼‚")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•éªŒè¯æœ€ç»ˆæ–‡ä»¶å‚æ•°: {e}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            shutil.rmtree(os.path.join(temp_dir, "processed_frames"))
            shutil.rmtree(os.path.join(temp_dir, "final_frames"))
            if os.path.exists(temp_video_path):
                os.remove(temp_video_path)
        except:
            pass
            
        return True, final_video_path
        
    except Exception as e:
        print(f"âŒ è§†é¢‘æœ€ç»ˆåŒ–å¤±è´¥ {os.path.basename(final_video_path)}: {e}")
        return False, final_video_path

def main():
    parser = argparse.ArgumentParser(description='FlashVSRè§†é¢‘è¶…åˆ†è¾¨ç‡å¤„ç†ï¼ˆçº¯è§†é¢‘æµï¼‰')
    parser.add_argument('--input', type=str, required=True, help='è¾“å…¥æ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--output', type=str, default='./results', help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--gpu', type=int, default=0, help='GPUè®¾å¤‡ID (0, 1, 2, 3)')
    parser.add_argument('--seed', type=int, default=0, help='éšæœºç§å­')
    parser.add_argument('--scale', type=float, default=4.0, help='ç¼©æ”¾æ¯”ä¾‹')
    parser.add_argument('--sparse_ratio', type=float, default=2.0, help='ç¨€ç–æ¯”ç‡')
    parser.add_argument('--local_range', type=int, default=11, help='å±€éƒ¨èŒƒå›´')
    parser.add_argument('--max_workers', type=int, default=2, help='å¹¶è¡Œå¤„ç†çš„æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°')
    
    args = parser.parse_args()
    
    print("=== FlashVSR GPUè®¾ç½®ï¼ˆçº¯è§†é¢‘æµå¤„ç†ï¼‰ ===")
    print(f"è¯·æ±‚ä½¿ç”¨GPU: {args.gpu}")
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if not torch.cuda.is_available():
        print("é”™è¯¯: CUDAä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥CUDAå®‰è£…")
        return
    
    gpu_count = torch.cuda.device_count()
    print(f"ç³»ç»Ÿæ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    if args.gpu >= gpu_count:
        print(f"é”™è¯¯: GPU {args.gpu} ä¸å­˜åœ¨ï¼Œå¯ç”¨GPU: 0-{gpu_count-1}")
        return
    
    RESULT_ROOT = args.output
    os.makedirs(RESULT_ROOT, exist_ok=True)
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•åœ¨è¾“å‡ºç›®å½•ä¸‹
    TEMP_ROOT = os.path.join(RESULT_ROOT, "temp")
    os.makedirs(TEMP_ROOT, exist_ok=True)
    print(f"ä¸´æ—¶æ–‡ä»¶ç›®å½•: {TEMP_ROOT}")
    
    # è·å–è¾“å…¥æ–‡ä»¶åˆ—è¡¨
    try:
        input_files = get_input_files(args.input)
    except Exception as e:
        print(f"è¾“å…¥æ–‡ä»¶é”™è¯¯: {e}")
        return
    
    if not input_files:
        print(f"åœ¨è·¯å¾„ {args.input} ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„è§†é¢‘æ–‡ä»¶æˆ–å›¾åƒåºåˆ—")
        return
    
    print(f"æ‰¾åˆ° {len(input_files)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")
    
    try:
        # åˆå§‹åŒ–ç®¡é“
        pipe, device = init_pipeline(args.gpu)
    except Exception as e:
        print(f"ç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºçº¿ç¨‹æ± ç”¨äºå¹¶è¡Œå¤„ç†
    executor = ThreadPoolExecutor(max_workers=args.max_workers)
    futures = []
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for i, input_path in enumerate(input_files, 1):
        print(f"\n=== å¤„ç†æ–‡ä»¶ {i}/{len(input_files)} ===")
        print(f"è¾“å…¥: {input_path}")
        
        # æ¸…ç†GPUå†…å­˜
        torch.cuda.empty_cache()
        
        name = os.path.basename(input_path.rstrip('/'))
        if name.startswith('.'):
            continue
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶
        is_video_file = is_video(input_path)
        
        # ä½¿ç”¨ç²¾ç¡®çš„è§†é¢‘ä¿¡æ¯è·å–
        try:
            LQ, th, tw, F, fps, from_video, original_fps, original_duration, original_frame_count = prepare_input_tensor(
                input_path, scale=args.scale, dtype=torch.bfloat16, device=device)
        except Exception as e:
            print(f"[é”™è¯¯] å‡†å¤‡è¾“å…¥å¼ é‡å¤±è´¥: {e}")
            continue

        # å¯¹äºè§†é¢‘æ–‡ä»¶ï¼Œæ˜¾ç¤ºä¿¡æ¯ï¼ˆæ— éŸ³é¢‘å¤„ç†ï¼‰
        if is_video_file:
            print(f"âœ“ è§†é¢‘æ–‡ä»¶ä¿¡æ¯: {original_frame_count}å¸§, {original_fps:.6f}fps, {original_duration:.6f}ç§’")
            print("  çº¯è§†é¢‘å¤„ç†æ¨¡å¼ï¼ˆæ— éŸ³é¢‘ï¼‰")

        try:
            print("å¼€å§‹FlashVSRå¤„ç†...")
            video = pipe(
                prompt="", 
                negative_prompt="", 
                cfg_scale=1.0, 
                num_inference_steps=1, 
                seed=args.seed,
                LQ_video=LQ, 
                num_frames=F, 
                height=th, 
                width=tw, 
                is_full_block=False, 
                if_buffer=True,
                topk_ratio=args.sparse_ratio*768 * 1280/(th*tw), 
                kv_ratio=3.0,
                local_range=args.local_range,
                color_fix=True,
            )

            video_frames = tensor2video(video)
            
            # è®¡ç®—å¤„ç†åçš„å®é™…å¸§æ•°ï¼ˆå‡å»å¡«å……çš„å¸§ï¼‰
            processed_frame_count = F - 4
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            if os.path.isdir(input_path):
                base_name = os.path.basename(input_path.rstrip('/'))
            else:
                base_name = os.path.splitext(os.path.basename(input_path))[0]
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ï¼ˆåœ¨è¾“å‡ºç›®å½•ä¸‹çš„tempæ–‡ä»¶å¤¹ä¸­ï¼‰
            temp_dir = tempfile.mkdtemp(dir=TEMP_ROOT, prefix=f"temp_{base_name}_")
            print(f"ğŸ“ ä¸´æ—¶ç›®å½•: {temp_dir}")
            
            # 1. å…ˆä¿å­˜ä¸ºPNGåºåˆ—å¸§
            processed_frames_dir = os.path.join(temp_dir, "processed_frames")
            saved_frame_paths = save_frames_as_png(video_frames, processed_frames_dir, "frame")
            print(f"âœ“ PNGåºåˆ—å¸§ä¿å­˜å®Œæˆ: {len(saved_frame_paths)}å¸§")
            
            # 2. å¡«è¡¥åˆ°åŸå§‹è§†é¢‘çš„å¸§æ•°ï¼ˆå¦‚æœæ˜¯è§†é¢‘æ–‡ä»¶ï¼‰
            final_frames_dir = os.path.join(temp_dir, "final_frames")
            if is_video_file and original_frame_count > 0:
                print(f"å¡«è¡¥å¸§æ•°: {processed_frame_count} -> {original_frame_count}")
                final_frame_paths = pad_frames_to_match_original(
                    processed_frames_dir, original_frame_count, final_frames_dir)
            else:
                # å¯¹äºå›¾åƒåºåˆ—ï¼Œç›´æ¥ä½¿ç”¨å¤„ç†åçš„å¸§
                final_frame_paths = saved_frame_paths
                original_frame_count = processed_frame_count
            
            # 3. å‡†å¤‡æœ€ç»ˆè§†é¢‘è·¯å¾„
            temp_video_path = os.path.join(temp_dir, "temp_video.mp4")
            final_video_filename = f"FlashVSR_v1.1_Tiny_Long_{base_name}_gpu{args.gpu}_seed{args.seed}.mp4"
            final_video_path = os.path.join(RESULT_ROOT, final_video_filename)
            
            # 4. æäº¤å¹¶è¡Œå¤„ç†ä»»åŠ¡ï¼ˆçº¯è§†é¢‘æ¨¡å¼ï¼‰
            print(f"ğŸš€ æäº¤å¹¶è¡Œå¤„ç†ä»»åŠ¡: {os.path.basename(final_video_path)}")
            future = executor.submit(process_video_finalization, (
                temp_dir, final_frame_paths, temp_video_path, final_video_path, 
                original_fps, original_frame_count, original_duration, is_video_file, input_path
            ))
            futures.append((future, final_video_path, temp_dir))
            
            print(f"ğŸ“Š å½“å‰å¹¶è¡Œä»»åŠ¡æ•°: {len(futures)}")
            
            # å¦‚æœå¹¶è¡Œä»»åŠ¡è¾¾åˆ°ä¸Šé™ï¼Œç­‰å¾…éƒ¨åˆ†ä»»åŠ¡å®Œæˆ
            if len(futures) >= args.max_workers * 2:
                print("ğŸ”„ è¾¾åˆ°å¹¶è¡Œä»»åŠ¡ä¸Šé™ï¼Œç­‰å¾…éƒ¨åˆ†ä»»åŠ¡å®Œæˆ...")
                completed_count = 0
                for f, path, temp_dir in futures[:]:
                    if f.done():
                        try:
                            success, result_path = f.result(timeout=1)
                            if success:
                                print(f"âœ… å¹¶è¡Œä»»åŠ¡å®Œæˆ: {os.path.basename(result_path)}")
                            else:
                                print(f"âŒ å¹¶è¡Œä»»åŠ¡å¤±è´¥: {os.path.basename(result_path)}")
                            # æ¸…ç†ä¸´æ—¶ç›®å½•
                            try:
                                shutil.rmtree(temp_dir)
                                print(f"ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•: {os.path.basename(temp_dir)}")
                            except:
                                pass
                            futures.remove((f, path, temp_dir))
                            completed_count += 1
                        except:
                            pass
                
                if completed_count > 0:
                    print(f"ğŸ”„ å·²å®Œæˆ {completed_count} ä¸ªä»»åŠ¡ï¼Œç»§ç»­å¤„ç†...")
            
        except Exception as e:
            print(f"[å¤„ç†é”™è¯¯] {name}: {e}")
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(temp_dir)
                print(f"ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•ï¼ˆé”™è¯¯æ—¶ï¼‰: {os.path.basename(temp_dir)}")
            except:
                pass
            continue

    print(f"\nğŸ”„ ç­‰å¾…æ‰€æœ‰å¹¶è¡Œä»»åŠ¡å®Œæˆ...")
    
    # ç­‰å¾…æ‰€æœ‰å‰©ä½™ä»»åŠ¡å®Œæˆ
    completed_count = 0
    failed_count = 0
    
    for future, final_video_path, temp_dir in futures:
        try:
            success, result_path = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
            if success:
                print(f"âœ… ä»»åŠ¡å®Œæˆ: {os.path.basename(result_path)}")
                completed_count += 1
            else:
                print(f"âŒ ä»»åŠ¡å¤±è´¥: {os.path.basename(result_path)}")
                failed_count += 1
        except Exception as e:
            print(f"âŒ ä»»åŠ¡è¶…æ—¶æˆ–å¤±è´¥ {os.path.basename(final_video_path)}: {e}")
            failed_count += 1
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                shutil.rmtree(temp_dir)
                print(f"ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•: {os.path.basename(temp_dir)}")
            except:
                pass
    
    # å…³é—­çº¿ç¨‹æ± 
    executor.shutdown(wait=True)
    
    # å°è¯•æ¸…ç†æ•´ä¸ªä¸´æ—¶ç›®å½•ï¼ˆå¦‚æœä¸ºç©ºï¼‰
    try:
        if os.path.exists(TEMP_ROOT) and not os.listdir(TEMP_ROOT):
            shutil.rmtree(TEMP_ROOT)
            print(f"ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ ¹ç›®å½•: {TEMP_ROOT}")
    except:
        pass
    
    print(f"\n=== æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ ===")
    print(f"âœ… æˆåŠŸ: {completed_count} ä¸ªæ–‡ä»¶")
    print(f"âŒ å¤±è´¥: {failed_count} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {RESULT_ROOT}")
    print(f"ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
    print("ğŸ¯ è¾“å‡ºæ–‡ä»¶ä¸ºçº¯è§†é¢‘æµï¼ˆæ— éŸ³é¢‘ï¼‰")

if __name__ == "__main__":
    main()
